{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3863402d",
   "metadata": {},
   "source": [
    "GRU Model for nextdayclose price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b90aa325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "19/19 [==============================] - 4s 42ms/step - loss: 543.8387 - val_loss: 473.0701\n",
      "Epoch 2/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 470.1300 - val_loss: 341.4986\n",
      "Epoch 3/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 290.6004 - val_loss: 174.3393\n",
      "Epoch 4/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 174.5751 - val_loss: 117.3610\n",
      "Epoch 5/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 135.0624 - val_loss: 93.5575\n",
      "Epoch 6/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 114.8414 - val_loss: 78.9917\n",
      "Epoch 7/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 99.0729 - val_loss: 68.4293\n",
      "Epoch 8/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 88.6097 - val_loss: 60.6229\n",
      "Epoch 9/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 77.9742 - val_loss: 54.8530\n",
      "Epoch 10/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 72.6374 - val_loss: 50.7117\n",
      "Epoch 11/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 70.8637 - val_loss: 47.6569\n",
      "Epoch 12/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 66.7596 - val_loss: 45.4424\n",
      "Epoch 13/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 63.9619 - val_loss: 43.9465\n",
      "Epoch 14/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 61.3389 - val_loss: 42.9477\n",
      "Epoch 15/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 60.3004 - val_loss: 42.3198\n",
      "Epoch 16/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 58.9525 - val_loss: 41.8642\n",
      "Epoch 17/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 57.3846 - val_loss: 41.6013\n",
      "Epoch 18/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 59.1121 - val_loss: 41.4548\n",
      "Epoch 19/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 57.6601 - val_loss: 41.3354\n",
      "Epoch 20/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 55.7075 - val_loss: 41.2247\n",
      "Epoch 21/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 57.6943 - val_loss: 41.0659\n",
      "Epoch 22/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 56.9845 - val_loss: 40.8436\n",
      "Epoch 23/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 57.1388 - val_loss: 40.5088\n",
      "Epoch 24/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 55.7541 - val_loss: 39.6305\n",
      "Epoch 25/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 55.8825 - val_loss: 38.0092\n",
      "Epoch 26/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 52.3314 - val_loss: 34.7865\n",
      "Epoch 27/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.5758 - val_loss: 30.2992\n",
      "Epoch 28/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 44.8593 - val_loss: 25.8193\n",
      "Epoch 29/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 37.9902 - val_loss: 22.2273\n",
      "Epoch 30/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 34.7783 - val_loss: 20.4399\n",
      "Epoch 31/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 34.2683 - val_loss: 18.3643\n",
      "Epoch 32/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 30.3373 - val_loss: 16.8655\n",
      "Epoch 33/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 29.1158 - val_loss: 15.6131\n",
      "Epoch 34/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 26.9628 - val_loss: 14.2534\n",
      "Epoch 35/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 25.7693 - val_loss: 13.3118\n",
      "Epoch 36/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 23.0378 - val_loss: 12.4188\n",
      "Epoch 37/150\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 22.9532 - val_loss: 11.7972\n",
      "Epoch 38/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 20.2505 - val_loss: 11.1109\n",
      "Epoch 39/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 21.0095 - val_loss: 10.2944\n",
      "Epoch 40/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 20.8124 - val_loss: 9.8080\n",
      "Epoch 41/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 19.0103 - val_loss: 9.1424\n",
      "Epoch 42/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.7371 - val_loss: 9.4240\n",
      "Epoch 43/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 17.8910 - val_loss: 8.2185\n",
      "Epoch 44/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.8508 - val_loss: 7.7845\n",
      "Epoch 45/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 16.6726 - val_loss: 7.4003\n",
      "Epoch 46/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 16.4042 - val_loss: 6.9422\n",
      "Epoch 47/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.7718 - val_loss: 6.5663\n",
      "Epoch 48/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2214 - val_loss: 6.3272\n",
      "Epoch 49/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 14.4980 - val_loss: 6.1249\n",
      "Epoch 50/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 13.7873 - val_loss: 5.6102\n",
      "Epoch 51/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 12.5832 - val_loss: 5.3599\n",
      "Epoch 52/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 11.7256 - val_loss: 5.1130\n",
      "Epoch 53/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 13.1134 - val_loss: 4.8024\n",
      "Epoch 54/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 12.9902 - val_loss: 4.9113\n",
      "Epoch 55/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 12.4530 - val_loss: 4.3474\n",
      "Epoch 56/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 11.4188 - val_loss: 4.3617\n",
      "Epoch 57/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 11.3273 - val_loss: 4.1218\n",
      "Epoch 58/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 11.2333 - val_loss: 3.7316\n",
      "Epoch 59/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10.6260 - val_loss: 3.5969\n",
      "Epoch 60/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10.7523 - val_loss: 3.7905\n",
      "Epoch 61/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.6517 - val_loss: 3.3080\n",
      "Epoch 62/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 10.3332 - val_loss: 3.1037\n",
      "Epoch 63/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.2083 - val_loss: 3.1090\n",
      "Epoch 64/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.8320 - val_loss: 3.0429\n",
      "Epoch 65/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.6997 - val_loss: 2.8325\n",
      "Epoch 66/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.8915 - val_loss: 2.7089\n",
      "Epoch 67/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.0856 - val_loss: 2.5673\n",
      "Epoch 68/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.0355 - val_loss: 2.3527\n",
      "Epoch 69/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 7.7030 - val_loss: 2.2113\n",
      "Epoch 70/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.1581 - val_loss: 2.1645\n",
      "Epoch 71/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.1345 - val_loss: 2.3350\n",
      "Epoch 72/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7.6078 - val_loss: 1.9831\n",
      "Epoch 73/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7.4138 - val_loss: 1.9160\n",
      "Epoch 74/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7.5980 - val_loss: 1.8291\n",
      "Epoch 75/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6.9310 - val_loss: 2.5240\n",
      "Epoch 76/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7.3732 - val_loss: 1.7214\n",
      "Epoch 77/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6.1634 - val_loss: 1.6096\n",
      "Epoch 78/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7.1970 - val_loss: 1.6792\n",
      "Epoch 79/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 6.5641 - val_loss: 1.5493\n",
      "Epoch 80/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7.2726 - val_loss: 1.5467\n",
      "Epoch 81/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.6234 - val_loss: 1.4398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6.5917 - val_loss: 1.3720\n",
      "Epoch 83/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.7920 - val_loss: 1.3599\n",
      "Epoch 84/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6.0584 - val_loss: 1.3050\n",
      "Epoch 85/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.9035 - val_loss: 1.3352\n",
      "Epoch 86/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6.6780 - val_loss: 1.2237\n",
      "Epoch 87/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.8475 - val_loss: 1.5088\n",
      "Epoch 88/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.8482 - val_loss: 1.1626\n",
      "Epoch 89/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.7238 - val_loss: 2.1954\n",
      "Epoch 90/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6.8168 - val_loss: 1.0975\n",
      "Epoch 91/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.5997 - val_loss: 1.1365\n",
      "Epoch 92/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.8212 - val_loss: 1.0636\n",
      "Epoch 93/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.7663 - val_loss: 1.0359\n",
      "Epoch 94/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.4772 - val_loss: 1.1636\n",
      "Epoch 95/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.3203 - val_loss: 1.1005\n",
      "Epoch 96/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.5547 - val_loss: 0.9703\n",
      "Epoch 97/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.4214 - val_loss: 0.9330\n",
      "Epoch 98/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.4876 - val_loss: 1.1850\n",
      "Epoch 99/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 5.3204 - val_loss: 1.0693\n",
      "Epoch 100/150\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 5.0574 - val_loss: 0.9335\n",
      "Epoch 101/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.3547 - val_loss: 0.9312\n",
      "Epoch 102/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.4750 - val_loss: 0.8640\n",
      "Epoch 103/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.3716 - val_loss: 0.8617\n",
      "Epoch 104/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.4210 - val_loss: 0.8390\n",
      "Epoch 105/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.7017 - val_loss: 1.2645\n",
      "Epoch 106/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.6098 - val_loss: 1.0733\n",
      "Epoch 107/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.3273 - val_loss: 0.9193\n",
      "Epoch 108/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.7753 - val_loss: 0.9239\n",
      "Epoch 109/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.0821 - val_loss: 0.8035\n",
      "Epoch 110/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.8556 - val_loss: 1.1372\n",
      "Epoch 111/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.9803 - val_loss: 0.8270\n",
      "Epoch 112/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.9074 - val_loss: 0.8010\n",
      "Epoch 113/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.6420 - val_loss: 0.7665\n",
      "Epoch 114/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.3359 - val_loss: 0.7420\n",
      "Epoch 115/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.2566 - val_loss: 0.7290\n",
      "Epoch 116/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.4528 - val_loss: 0.9697\n",
      "Epoch 117/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.1402 - val_loss: 0.7627\n",
      "Epoch 118/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.4566 - val_loss: 1.1464\n",
      "Epoch 119/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.9224 - val_loss: 1.6820\n",
      "Epoch 120/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.0320 - val_loss: 0.9417\n",
      "Epoch 121/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.7090 - val_loss: 0.9754\n",
      "Epoch 122/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.3207 - val_loss: 0.8455\n",
      "Epoch 123/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.8230 - val_loss: 0.7572\n",
      "Epoch 124/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.5296 - val_loss: 0.7119\n",
      "Epoch 125/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.5822 - val_loss: 0.8173\n",
      "Epoch 126/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.5650 - val_loss: 0.6514\n",
      "Epoch 127/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.3825 - val_loss: 0.7152\n",
      "Epoch 128/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.4152 - val_loss: 0.7189\n",
      "Epoch 129/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.9138 - val_loss: 0.8415\n",
      "Epoch 130/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.7912 - val_loss: 0.6772\n",
      "Epoch 131/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.4889 - val_loss: 0.7063\n",
      "Epoch 132/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.2711 - val_loss: 0.8276\n",
      "Epoch 133/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.8915 - val_loss: 0.6564\n",
      "Epoch 134/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.2738 - val_loss: 1.0488\n",
      "Epoch 135/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.8107 - val_loss: 1.0697\n",
      "Epoch 136/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.3582 - val_loss: 0.6140\n",
      "Epoch 137/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.0985 - val_loss: 0.6190\n",
      "Epoch 138/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.7178 - val_loss: 0.6505\n",
      "Epoch 139/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.6445 - val_loss: 0.8648\n",
      "Epoch 140/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.6704 - val_loss: 0.6283\n",
      "Epoch 141/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.5520 - val_loss: 0.6796\n",
      "Epoch 142/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.9791 - val_loss: 0.5670\n",
      "Epoch 143/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.0805 - val_loss: 0.5934\n",
      "Epoch 144/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.5689 - val_loss: 0.5823\n",
      "Epoch 145/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.7008 - val_loss: 0.6051\n",
      "Epoch 146/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.8426 - val_loss: 0.6809\n",
      "Epoch 147/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.5373 - val_loss: 0.6132\n",
      "Epoch 148/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.3831 - val_loss: 0.5850\n",
      "Epoch 149/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.5809 - val_loss: 0.7338\n",
      "Epoch 150/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.1988 - val_loss: 0.6746\n",
      "7/7 [==============================] - 1s 1ms/step\n",
      "Epoch 1/150\n",
      "19/19 [==============================] - 4s 39ms/step - loss: 37.9590 - val_loss: 37.0192\n",
      "Epoch 2/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 27.0036 - val_loss: 17.0493\n",
      "Epoch 3/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 9.1051 - val_loss: 7.6936\n",
      "Epoch 4/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 7.0462 - val_loss: 6.7740\n",
      "Epoch 5/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 6.0809 - val_loss: 6.0154\n",
      "Epoch 6/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.9748 - val_loss: 4.8789\n",
      "Epoch 7/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.9776 - val_loss: 3.5334\n",
      "Epoch 8/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.6960 - val_loss: 2.0681\n",
      "Epoch 9/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.6478 - val_loss: 1.2090\n",
      "Epoch 10/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.1988 - val_loss: 1.0029\n",
      "Epoch 11/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.1125 - val_loss: 0.9409\n",
      "Epoch 12/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.0050 - val_loss: 0.8715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.9739 - val_loss: 0.8170\n",
      "Epoch 14/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.9990 - val_loss: 0.7713\n",
      "Epoch 15/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.0348 - val_loss: 0.7557\n",
      "Epoch 16/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.0125 - val_loss: 0.6892\n",
      "Epoch 17/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8946 - val_loss: 0.6555\n",
      "Epoch 18/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.9154 - val_loss: 0.6259\n",
      "Epoch 19/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8356 - val_loss: 0.5936\n",
      "Epoch 20/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7615 - val_loss: 0.5641\n",
      "Epoch 21/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8825 - val_loss: 0.5510\n",
      "Epoch 22/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7789 - val_loss: 0.5254\n",
      "Epoch 23/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7198 - val_loss: 0.5163\n",
      "Epoch 24/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7929 - val_loss: 0.5037\n",
      "Epoch 25/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7194 - val_loss: 0.4814\n",
      "Epoch 26/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6170 - val_loss: 0.4667\n",
      "Epoch 27/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6602 - val_loss: 0.4540\n",
      "Epoch 28/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6411 - val_loss: 0.4359\n",
      "Epoch 29/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7638 - val_loss: 0.4297\n",
      "Epoch 30/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7039 - val_loss: 0.4134\n",
      "Epoch 31/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6303 - val_loss: 0.4019\n",
      "Epoch 32/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7016 - val_loss: 0.3897\n",
      "Epoch 33/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5524 - val_loss: 0.3731\n",
      "Epoch 34/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6145 - val_loss: 0.4068\n",
      "Epoch 35/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6039 - val_loss: 0.4147\n",
      "Epoch 36/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6339 - val_loss: 0.3496\n",
      "Epoch 37/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6290 - val_loss: 0.3543\n",
      "Epoch 38/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5702 - val_loss: 0.3685\n",
      "Epoch 39/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4766 - val_loss: 0.3650\n",
      "Epoch 40/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5585 - val_loss: 0.3287\n",
      "Epoch 41/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5399 - val_loss: 0.3449\n",
      "Epoch 42/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5371 - val_loss: 0.3137\n",
      "Epoch 43/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5873 - val_loss: 0.3074\n",
      "Epoch 44/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6195 - val_loss: 0.3002\n",
      "Epoch 45/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5312 - val_loss: 0.2937\n",
      "Epoch 46/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6000 - val_loss: 0.2896\n",
      "Epoch 47/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6566 - val_loss: 0.2910\n",
      "Epoch 48/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5171 - val_loss: 0.2751\n",
      "Epoch 49/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4924 - val_loss: 0.2802\n",
      "Epoch 50/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4757 - val_loss: 0.2743\n",
      "Epoch 51/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5546 - val_loss: 0.2721\n",
      "Epoch 52/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5840 - val_loss: 0.3003\n",
      "Epoch 53/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5274 - val_loss: 0.2616\n",
      "Epoch 54/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4783 - val_loss: 0.2946\n",
      "Epoch 55/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5118 - val_loss: 0.2568\n",
      "Epoch 56/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5067 - val_loss: 0.2653\n",
      "Epoch 57/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5546 - val_loss: 0.2673\n",
      "Epoch 58/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4544 - val_loss: 0.2589\n",
      "Epoch 59/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5337 - val_loss: 0.2531\n",
      "Epoch 60/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4727 - val_loss: 0.2400\n",
      "Epoch 61/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5242 - val_loss: 0.2326\n",
      "Epoch 62/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5389 - val_loss: 0.2369\n",
      "Epoch 63/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5124 - val_loss: 0.2596\n",
      "Epoch 64/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4490 - val_loss: 0.2304\n",
      "Epoch 65/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5457 - val_loss: 0.2251\n",
      "Epoch 66/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4648 - val_loss: 0.2256\n",
      "Epoch 67/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4661 - val_loss: 0.2385\n",
      "Epoch 68/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5359 - val_loss: 0.2248\n",
      "Epoch 69/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4493 - val_loss: 0.2179\n",
      "Epoch 70/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4864 - val_loss: 0.2257\n",
      "Epoch 71/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4391 - val_loss: 0.2345\n",
      "Epoch 72/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4588 - val_loss: 0.2171\n",
      "Epoch 73/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4289 - val_loss: 0.2083\n",
      "Epoch 74/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4838 - val_loss: 0.2041\n",
      "Epoch 75/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4966 - val_loss: 0.2025\n",
      "Epoch 76/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4972 - val_loss: 0.2045\n",
      "Epoch 77/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4407 - val_loss: 0.1982\n",
      "Epoch 78/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5126 - val_loss: 0.2094\n",
      "Epoch 79/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4223 - val_loss: 0.2018\n",
      "Epoch 80/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4412 - val_loss: 0.2004\n",
      "Epoch 81/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4629 - val_loss: 0.2647\n",
      "Epoch 82/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4257 - val_loss: 0.2014\n",
      "Epoch 83/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4857 - val_loss: 0.2088\n",
      "Epoch 84/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4404 - val_loss: 0.2044\n",
      "Epoch 85/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3614 - val_loss: 0.2080\n",
      "Epoch 86/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4272 - val_loss: 0.2008\n",
      "Epoch 87/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4728 - val_loss: 0.2286\n",
      "Epoch 88/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4201 - val_loss: 0.1950\n",
      "Epoch 89/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4328 - val_loss: 0.1876\n",
      "Epoch 90/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4221 - val_loss: 0.1891\n",
      "Epoch 91/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4249 - val_loss: 0.1886\n",
      "Epoch 92/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3979 - val_loss: 0.1829\n",
      "Epoch 93/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4221 - val_loss: 0.1989\n",
      "Epoch 94/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3845 - val_loss: 0.1786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4514 - val_loss: 0.1965\n",
      "Epoch 96/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4835 - val_loss: 0.1918\n",
      "Epoch 97/150\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4757 - val_loss: 0.1881\n",
      "Epoch 98/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3847 - val_loss: 0.1853\n",
      "Epoch 99/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3857 - val_loss: 0.1805\n",
      "Epoch 100/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3846 - val_loss: 0.1759\n",
      "Epoch 101/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4727 - val_loss: 0.1758\n",
      "Epoch 102/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3985 - val_loss: 0.1747\n",
      "Epoch 103/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3693 - val_loss: 0.1760\n",
      "Epoch 104/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3728 - val_loss: 0.1766\n",
      "Epoch 105/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4467 - val_loss: 0.1798\n",
      "Epoch 106/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4544 - val_loss: 0.1805\n",
      "Epoch 107/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5046 - val_loss: 0.1879\n",
      "Epoch 108/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4604 - val_loss: 0.1741\n",
      "Epoch 109/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5139 - val_loss: 0.1695\n",
      "Epoch 110/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4387 - val_loss: 0.1750\n",
      "Epoch 111/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3910 - val_loss: 0.1711\n",
      "Epoch 112/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4701 - val_loss: 0.1661\n",
      "Epoch 113/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4335 - val_loss: 0.1629\n",
      "Epoch 114/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3926 - val_loss: 0.2112\n",
      "Epoch 115/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4110 - val_loss: 0.1779\n",
      "Epoch 116/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3868 - val_loss: 0.1639\n",
      "Epoch 117/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3574 - val_loss: 0.1645\n",
      "Epoch 118/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3961 - val_loss: 0.1688\n",
      "Epoch 119/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4107 - val_loss: 0.1697\n",
      "Epoch 120/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3581 - val_loss: 0.1621\n",
      "Epoch 121/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3459 - val_loss: 0.1614\n",
      "Epoch 122/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3632 - val_loss: 0.1650\n",
      "Epoch 123/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3724 - val_loss: 0.1633\n",
      "Epoch 124/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3880 - val_loss: 0.1816\n",
      "Epoch 125/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4075 - val_loss: 0.1994\n",
      "Epoch 126/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3484 - val_loss: 0.1690\n",
      "Epoch 127/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4976 - val_loss: 0.1557\n",
      "Epoch 128/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4808 - val_loss: 0.1716\n",
      "Epoch 129/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3843 - val_loss: 0.1789\n",
      "Epoch 130/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4032 - val_loss: 0.1574\n",
      "Epoch 131/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4305 - val_loss: 0.1679\n",
      "Epoch 132/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3988 - val_loss: 0.1556\n",
      "Epoch 133/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4149 - val_loss: 0.1591\n",
      "Epoch 134/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3595 - val_loss: 0.1907\n",
      "Epoch 135/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4023 - val_loss: 0.1897\n",
      "Epoch 136/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3785 - val_loss: 0.1476\n",
      "Epoch 137/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3518 - val_loss: 0.1567\n",
      "Epoch 138/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3848 - val_loss: 0.1968\n",
      "Epoch 139/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3967 - val_loss: 0.2133\n",
      "Epoch 140/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3579 - val_loss: 0.1468\n",
      "Epoch 141/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4017 - val_loss: 0.1517\n",
      "Epoch 142/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3621 - val_loss: 0.1543\n",
      "Epoch 143/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3845 - val_loss: 0.1678\n",
      "Epoch 144/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3950 - val_loss: 0.1510\n",
      "Epoch 145/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4106 - val_loss: 0.1896\n",
      "Epoch 146/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4448 - val_loss: 0.1520\n",
      "Epoch 147/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3561 - val_loss: 0.2174\n",
      "Epoch 148/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3991 - val_loss: 0.1949\n",
      "Epoch 149/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4806 - val_loss: 0.1527\n",
      "Epoch 150/150\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 0.4258 - val_loss: 0.1594\n",
      "7/7 [==============================] - 1s 2ms/step\n",
      "Epoch 1/150\n",
      "18/18 [==============================] - 4s 42ms/step - loss: 214.7056 - val_loss: 179.3474\n",
      "Epoch 2/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 185.1888 - val_loss: 127.9360\n",
      "Epoch 3/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 110.9484 - val_loss: 62.9278\n",
      "Epoch 4/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 66.9066 - val_loss: 48.5055\n",
      "Epoch 5/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 57.9456 - val_loss: 47.0022\n",
      "Epoch 6/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 55.3964 - val_loss: 46.4276\n",
      "Epoch 7/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 55.9432 - val_loss: 45.4023\n",
      "Epoch 8/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 53.8412 - val_loss: 43.2427\n",
      "Epoch 9/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 51.2475 - val_loss: 39.7467\n",
      "Epoch 10/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 48.0694 - val_loss: 35.0094\n",
      "Epoch 11/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 41.6879 - val_loss: 28.8692\n",
      "Epoch 12/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 34.6552 - val_loss: 22.8260\n",
      "Epoch 13/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 27.4116 - val_loss: 18.9558\n",
      "Epoch 14/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 24.1665 - val_loss: 16.6695\n",
      "Epoch 15/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 20.9945 - val_loss: 15.1685\n",
      "Epoch 16/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 19.7689 - val_loss: 13.8508\n",
      "Epoch 17/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 18.1006 - val_loss: 12.7289\n",
      "Epoch 18/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 16.9788 - val_loss: 11.7634\n",
      "Epoch 19/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 16.0066 - val_loss: 10.9987\n",
      "Epoch 20/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 15.2806 - val_loss: 10.2418\n",
      "Epoch 21/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 13.9875 - val_loss: 9.5582\n",
      "Epoch 22/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 14.1632 - val_loss: 9.0566\n",
      "Epoch 23/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 12.4613 - val_loss: 8.3974\n",
      "Epoch 24/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.7184 - val_loss: 7.9108\n",
      "Epoch 25/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 10.3276 - val_loss: 7.3908\n",
      "Epoch 26/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 11.3028 - val_loss: 7.0384\n",
      "Epoch 27/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 10.3249 - val_loss: 6.6935\n",
      "Epoch 28/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 9.2439 - val_loss: 6.2343\n",
      "Epoch 29/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.6047 - val_loss: 6.1448\n",
      "Epoch 30/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.5425 - val_loss: 5.5750\n",
      "Epoch 31/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 8.4164 - val_loss: 5.3236\n",
      "Epoch 32/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.8628 - val_loss: 5.0969\n",
      "Epoch 33/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 7.9237 - val_loss: 4.8107\n",
      "Epoch 34/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.1614 - val_loss: 4.6528\n",
      "Epoch 35/150\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 7.3825 - val_loss: 4.3146\n",
      "Epoch 36/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.4556 - val_loss: 4.0892\n",
      "Epoch 37/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9164 - val_loss: 3.9361\n",
      "Epoch 38/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.1118 - val_loss: 3.9746\n",
      "Epoch 39/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.3153 - val_loss: 3.5663\n",
      "Epoch 40/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 6.0936 - val_loss: 3.3868\n",
      "Epoch 41/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8851 - val_loss: 3.2254\n",
      "Epoch 42/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.8617 - val_loss: 3.1283\n",
      "Epoch 43/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 5.1259 - val_loss: 3.0228\n",
      "Epoch 44/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.2487 - val_loss: 2.8566\n",
      "Epoch 45/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.0716 - val_loss: 2.6972\n",
      "Epoch 46/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.4806 - val_loss: 2.5894\n",
      "Epoch 47/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.7693 - val_loss: 2.4924\n",
      "Epoch 48/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.0804 - val_loss: 2.4053\n",
      "Epoch 49/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.8417 - val_loss: 2.3035\n",
      "Epoch 50/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.8563 - val_loss: 2.2092\n",
      "Epoch 51/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.5172 - val_loss: 2.1471\n",
      "Epoch 52/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.4723 - val_loss: 2.0658\n",
      "Epoch 53/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 4.1835 - val_loss: 1.9865\n",
      "Epoch 54/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.4134 - val_loss: 1.9265\n",
      "Epoch 55/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.0516 - val_loss: 2.1020\n",
      "Epoch 56/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.6375 - val_loss: 1.7758\n",
      "Epoch 57/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.5448 - val_loss: 1.7456\n",
      "Epoch 58/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.5984 - val_loss: 1.8565\n",
      "Epoch 59/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.1655 - val_loss: 1.6443\n",
      "Epoch 60/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.4947 - val_loss: 1.8670\n",
      "Epoch 61/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.8648 - val_loss: 1.5431\n",
      "Epoch 62/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.5415 - val_loss: 1.5288\n",
      "Epoch 63/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.3194 - val_loss: 1.7112\n",
      "Epoch 64/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.8916 - val_loss: 1.4478\n",
      "Epoch 65/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3.7740 - val_loss: 1.4112\n",
      "Epoch 66/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.9948 - val_loss: 1.4011\n",
      "Epoch 67/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.5724 - val_loss: 1.3607\n",
      "Epoch 68/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.4931 - val_loss: 1.4488\n",
      "Epoch 69/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.6387 - val_loss: 1.6507\n",
      "Epoch 70/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3.3887 - val_loss: 1.4032\n",
      "Epoch 71/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.1787 - val_loss: 1.2321\n",
      "Epoch 72/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.8983 - val_loss: 1.2238\n",
      "Epoch 73/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.9750 - val_loss: 1.1914\n",
      "Epoch 74/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.3454 - val_loss: 1.1645\n",
      "Epoch 75/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.0068 - val_loss: 1.1261\n",
      "Epoch 76/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.6909 - val_loss: 1.2086\n",
      "Epoch 77/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.7590 - val_loss: 1.1985\n",
      "Epoch 78/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.9071 - val_loss: 1.1949\n",
      "Epoch 79/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.9899 - val_loss: 1.0466\n",
      "Epoch 80/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.8459 - val_loss: 1.2200\n",
      "Epoch 81/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.1012 - val_loss: 1.0886\n",
      "Epoch 82/150\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.5733 - val_loss: 0.9974\n",
      "Epoch 83/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.1353 - val_loss: 1.1198\n",
      "Epoch 84/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.7688 - val_loss: 0.9927\n",
      "Epoch 85/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.8975 - val_loss: 0.9844\n",
      "Epoch 86/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.7599 - val_loss: 1.3300\n",
      "Epoch 87/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.7058 - val_loss: 0.9489\n",
      "Epoch 88/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.6562 - val_loss: 0.9674\n",
      "Epoch 89/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.0257 - val_loss: 1.0476\n",
      "Epoch 90/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.6914 - val_loss: 0.9105\n",
      "Epoch 91/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.0225 - val_loss: 1.0048\n",
      "Epoch 92/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.9766 - val_loss: 1.0760\n",
      "Epoch 93/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.9672 - val_loss: 0.9515\n",
      "Epoch 94/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.6592 - val_loss: 0.8993\n",
      "Epoch 95/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.6624 - val_loss: 0.9766\n",
      "Epoch 96/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.4921 - val_loss: 1.1397\n",
      "Epoch 97/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.0807 - val_loss: 0.8505\n",
      "Epoch 98/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.0430 - val_loss: 1.0204\n",
      "Epoch 99/150\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 3.0036 - val_loss: 0.9868\n",
      "Epoch 100/150\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 2.7244 - val_loss: 0.8398\n",
      "Epoch 101/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3675 - val_loss: 0.8420\n",
      "Epoch 102/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.4951 - val_loss: 0.9148\n",
      "Epoch 103/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.5527 - val_loss: 0.8426\n",
      "Epoch 104/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.2268 - val_loss: 0.7906\n",
      "Epoch 105/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.6475 - val_loss: 0.7708\n",
      "Epoch 106/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.8898 - val_loss: 0.7496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.5547 - val_loss: 0.7702\n",
      "Epoch 108/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.9312 - val_loss: 0.7376\n",
      "Epoch 109/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.3736 - val_loss: 0.8153\n",
      "Epoch 110/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 3.3529 - val_loss: 0.9427\n",
      "Epoch 111/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.9677 - val_loss: 0.7030\n",
      "Epoch 112/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.9622 - val_loss: 0.7044\n",
      "Epoch 113/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.3947 - val_loss: 0.6906\n",
      "Epoch 114/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.1628 - val_loss: 0.6988\n",
      "Epoch 115/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.1820 - val_loss: 0.8036\n",
      "Epoch 116/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.9495 - val_loss: 0.7154\n",
      "Epoch 117/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.6417 - val_loss: 0.7658\n",
      "Epoch 118/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.2459 - val_loss: 0.7220\n",
      "Epoch 119/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.4318 - val_loss: 0.7344\n",
      "Epoch 120/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.5332 - val_loss: 0.7576\n",
      "Epoch 121/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.1370 - val_loss: 0.6618\n",
      "Epoch 122/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.2610 - val_loss: 0.6721\n",
      "Epoch 123/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.9468 - val_loss: 0.7015\n",
      "Epoch 124/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.4619 - val_loss: 0.7625\n",
      "Epoch 125/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3938 - val_loss: 0.6944\n",
      "Epoch 126/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.1840 - val_loss: 0.6573\n",
      "Epoch 127/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.5714 - val_loss: 0.7192\n",
      "Epoch 128/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.5324 - val_loss: 0.6500\n",
      "Epoch 129/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.0994 - val_loss: 0.6722\n",
      "Epoch 130/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.1473 - val_loss: 0.7514\n",
      "Epoch 131/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.6780 - val_loss: 0.6302\n",
      "Epoch 132/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.0922 - val_loss: 0.6500\n",
      "Epoch 133/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.2725 - val_loss: 0.7141\n",
      "Epoch 134/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.1292 - val_loss: 0.5935\n",
      "Epoch 135/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3024 - val_loss: 0.5736\n",
      "Epoch 136/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.5015 - val_loss: 0.5952\n",
      "Epoch 137/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.6272 - val_loss: 0.5925\n",
      "Epoch 138/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.2823 - val_loss: 0.5927\n",
      "Epoch 139/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.1972 - val_loss: 0.6207\n",
      "Epoch 140/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.3486 - val_loss: 0.6291\n",
      "Epoch 141/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 1.7771 - val_loss: 0.6802\n",
      "Epoch 142/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.5319 - val_loss: 0.6006\n",
      "Epoch 143/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.0546 - val_loss: 0.5485\n",
      "Epoch 144/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.2489 - val_loss: 0.5716\n",
      "Epoch 145/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.2286 - val_loss: 0.5890\n",
      "Epoch 146/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.1534 - val_loss: 0.5549\n",
      "Epoch 147/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.0719 - val_loss: 0.5719\n",
      "Epoch 148/150\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 2.1092 - val_loss: 0.5905\n",
      "Epoch 149/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.1828 - val_loss: 0.5603\n",
      "Epoch 150/150\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3663 - val_loss: 0.6181\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Epoch 1/150\n",
      "16/16 [==============================] - 4s 48ms/step - loss: 146.5039 - val_loss: 203.7321\n",
      "Epoch 2/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 132.7650 - val_loss: 172.4670\n",
      "Epoch 3/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 98.7864 - val_loss: 115.3147\n",
      "Epoch 4/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 71.3202 - val_loss: 97.2159\n",
      "Epoch 5/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 67.6804 - val_loss: 90.0682\n",
      "Epoch 6/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 60.6625 - val_loss: 79.8028\n",
      "Epoch 7/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 49.8079 - val_loss: 64.5258\n",
      "Epoch 8/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 36.6832 - val_loss: 50.1030\n",
      "Epoch 9/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 28.6795 - val_loss: 42.4486\n",
      "Epoch 10/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 24.5359 - val_loss: 37.9842\n",
      "Epoch 11/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 22.0803 - val_loss: 34.5079\n",
      "Epoch 12/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 20.0092 - val_loss: 31.8355\n",
      "Epoch 13/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 19.5996 - val_loss: 29.3247\n",
      "Epoch 14/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 17.3601 - val_loss: 27.1312\n",
      "Epoch 15/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 15.0234 - val_loss: 25.1174\n",
      "Epoch 16/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 15.0134 - val_loss: 23.1221\n",
      "Epoch 17/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 13.9820 - val_loss: 21.4892\n",
      "Epoch 18/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12.5987 - val_loss: 20.1206\n",
      "Epoch 19/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12.1614 - val_loss: 18.4548\n",
      "Epoch 20/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 10.8644 - val_loss: 17.4030\n",
      "Epoch 21/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 9.6951 - val_loss: 16.0188\n",
      "Epoch 22/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.5589 - val_loss: 14.9601\n",
      "Epoch 23/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.2318 - val_loss: 13.9452\n",
      "Epoch 24/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.4907 - val_loss: 13.0300\n",
      "Epoch 25/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.4406 - val_loss: 12.1591\n",
      "Epoch 26/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 7.9821 - val_loss: 11.3657\n",
      "Epoch 27/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.5699 - val_loss: 10.7958\n",
      "Epoch 28/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 6.1797 - val_loss: 10.0449\n",
      "Epoch 29/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.6358 - val_loss: 9.4756\n",
      "Epoch 30/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.1993 - val_loss: 8.9933\n",
      "Epoch 31/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.6732 - val_loss: 8.5168\n",
      "Epoch 32/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 5.1464 - val_loss: 8.0009\n",
      "Epoch 33/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.9164 - val_loss: 7.6929\n",
      "Epoch 34/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.3909 - val_loss: 7.2695\n",
      "Epoch 35/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 4.4118 - val_loss: 6.9424\n",
      "Epoch 36/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.1054 - val_loss: 6.5839\n",
      "Epoch 37/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 3.6924 - val_loss: 6.2652\n",
      "Epoch 38/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.9789 - val_loss: 6.1605\n",
      "Epoch 39/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.7045 - val_loss: 5.8072\n",
      "Epoch 40/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.5642 - val_loss: 5.5387\n",
      "Epoch 41/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.3627 - val_loss: 5.3525\n",
      "Epoch 42/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.3943 - val_loss: 5.2085\n",
      "Epoch 43/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.1796 - val_loss: 4.9631\n",
      "Epoch 44/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.6680 - val_loss: 4.8930\n",
      "Epoch 45/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 3.3251 - val_loss: 4.6770\n",
      "Epoch 46/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.9701 - val_loss: 4.5030\n",
      "Epoch 47/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.7149 - val_loss: 4.5562\n",
      "Epoch 48/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.7539 - val_loss: 4.2828\n",
      "Epoch 49/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.6517 - val_loss: 4.1348\n",
      "Epoch 50/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.5027 - val_loss: 4.0151\n",
      "Epoch 51/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.7132 - val_loss: 3.9363\n",
      "Epoch 52/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2733 - val_loss: 4.3021\n",
      "Epoch 53/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.9923 - val_loss: 3.8056\n",
      "Epoch 54/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.8390 - val_loss: 3.6864\n",
      "Epoch 55/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3701 - val_loss: 3.6732\n",
      "Epoch 56/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.6549 - val_loss: 3.5409\n",
      "Epoch 57/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.9380 - val_loss: 3.4909\n",
      "Epoch 58/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2081 - val_loss: 3.4690\n",
      "Epoch 59/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.6713 - val_loss: 3.4345\n",
      "Epoch 60/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.7972 - val_loss: 3.2882\n",
      "Epoch 61/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.5144 - val_loss: 3.3397\n",
      "Epoch 62/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.6723 - val_loss: 3.2064\n",
      "Epoch 63/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2345 - val_loss: 3.1534\n",
      "Epoch 64/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2630 - val_loss: 3.1323\n",
      "Epoch 65/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.3616 - val_loss: 3.1124\n",
      "Epoch 66/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.4497 - val_loss: 2.9870\n",
      "Epoch 67/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.6137 - val_loss: 2.9250\n",
      "Epoch 68/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.6072 - val_loss: 2.9305\n",
      "Epoch 69/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2530 - val_loss: 2.8443\n",
      "Epoch 70/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3601 - val_loss: 2.8290\n",
      "Epoch 71/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.2215 - val_loss: 2.7850\n",
      "Epoch 72/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1146 - val_loss: 2.8014\n",
      "Epoch 73/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.3559 - val_loss: 2.7135\n",
      "Epoch 74/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7728 - val_loss: 2.6740\n",
      "Epoch 75/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0928 - val_loss: 2.6669\n",
      "Epoch 76/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0637 - val_loss: 2.6123\n",
      "Epoch 77/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.6283 - val_loss: 2.6156\n",
      "Epoch 78/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8717 - val_loss: 2.6809\n",
      "Epoch 79/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.1165 - val_loss: 2.5769\n",
      "Epoch 80/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0524 - val_loss: 2.5400\n",
      "Epoch 81/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6701 - val_loss: 2.4664\n",
      "Epoch 82/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.1234 - val_loss: 2.6042\n",
      "Epoch 83/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.0708 - val_loss: 2.4460\n",
      "Epoch 84/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0757 - val_loss: 2.4362\n",
      "Epoch 85/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3564 - val_loss: 2.5098\n",
      "Epoch 86/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.2918 - val_loss: 2.3440\n",
      "Epoch 87/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9512 - val_loss: 2.4298\n",
      "Epoch 88/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7658 - val_loss: 2.4323\n",
      "Epoch 89/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1070 - val_loss: 2.3136\n",
      "Epoch 90/150\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 2.2817 - val_loss: 2.2176\n",
      "Epoch 91/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1346 - val_loss: 2.1853\n",
      "Epoch 92/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6103 - val_loss: 2.2236\n",
      "Epoch 93/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7711 - val_loss: 2.1797\n",
      "Epoch 94/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8644 - val_loss: 2.1655\n",
      "Epoch 95/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1468 - val_loss: 2.1929\n",
      "Epoch 96/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0646 - val_loss: 2.2225\n",
      "Epoch 97/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7821 - val_loss: 2.1232\n",
      "Epoch 98/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8585 - val_loss: 2.0574\n",
      "Epoch 99/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8287 - val_loss: 2.0619\n",
      "Epoch 100/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9153 - val_loss: 2.0765\n",
      "Epoch 101/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.9743 - val_loss: 2.0632\n",
      "Epoch 102/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7411 - val_loss: 1.9764\n",
      "Epoch 103/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3030 - val_loss: 2.0316\n",
      "Epoch 104/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8732 - val_loss: 2.0871\n",
      "Epoch 105/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8161 - val_loss: 2.0160\n",
      "Epoch 106/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.1060 - val_loss: 1.9011\n",
      "Epoch 107/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4965 - val_loss: 1.9336\n",
      "Epoch 108/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4885 - val_loss: 1.9195\n",
      "Epoch 109/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6357 - val_loss: 1.8537\n",
      "Epoch 110/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1355 - val_loss: 1.8838\n",
      "Epoch 111/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6379 - val_loss: 1.9440\n",
      "Epoch 112/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7506 - val_loss: 1.8391\n",
      "Epoch 113/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9095 - val_loss: 1.8042\n",
      "Epoch 114/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7258 - val_loss: 1.9529\n",
      "Epoch 115/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7097 - val_loss: 1.8065\n",
      "Epoch 116/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0085 - val_loss: 1.8388\n",
      "Epoch 117/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3546 - val_loss: 1.7928\n",
      "Epoch 118/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5569 - val_loss: 1.8351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7891 - val_loss: 1.8405\n",
      "Epoch 120/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8875 - val_loss: 1.8337\n",
      "Epoch 121/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7015 - val_loss: 1.9915\n",
      "Epoch 122/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7142 - val_loss: 1.7730\n",
      "Epoch 123/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.3198 - val_loss: 1.8378\n",
      "Epoch 124/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7971 - val_loss: 1.7175\n",
      "Epoch 125/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9548 - val_loss: 1.9328\n",
      "Epoch 126/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9229 - val_loss: 1.6778\n",
      "Epoch 127/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.0178 - val_loss: 1.6742\n",
      "Epoch 128/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5738 - val_loss: 1.6502\n",
      "Epoch 129/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5692 - val_loss: 1.6601\n",
      "Epoch 130/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6135 - val_loss: 1.7173\n",
      "Epoch 131/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7444 - val_loss: 1.6048\n",
      "Epoch 132/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9573 - val_loss: 1.6364\n",
      "Epoch 133/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.8017 - val_loss: 1.6575\n",
      "Epoch 134/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5852 - val_loss: 1.7641\n",
      "Epoch 135/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8401 - val_loss: 1.6824\n",
      "Epoch 136/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5735 - val_loss: 1.6994\n",
      "Epoch 137/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.7093 - val_loss: 1.5704\n",
      "Epoch 138/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.6749 - val_loss: 1.6247\n",
      "Epoch 139/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8430 - val_loss: 1.5952\n",
      "Epoch 140/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6901 - val_loss: 1.6968\n",
      "Epoch 141/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.1539 - val_loss: 1.6965\n",
      "Epoch 142/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4446 - val_loss: 1.5868\n",
      "Epoch 143/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 2.0875 - val_loss: 1.5684\n",
      "Epoch 144/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5141 - val_loss: 1.5158\n",
      "Epoch 145/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.4240 - val_loss: 1.4828\n",
      "Epoch 146/150\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.2695 - val_loss: 1.5201\n",
      "Epoch 147/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7401 - val_loss: 1.4613\n",
      "Epoch 148/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5648 - val_loss: 1.4536\n",
      "Epoch 149/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6901 - val_loss: 1.5270\n",
      "Epoch 150/150\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3153 - val_loss: 1.4885\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Epoch 1/150\n",
      "19/19 [==============================] - 4s 39ms/step - loss: 85.2282 - val_loss: 73.1760\n",
      "Epoch 2/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 63.0606 - val_loss: 34.3740\n",
      "Epoch 3/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 17.7690 - val_loss: 3.6822\n",
      "Epoch 4/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.3046 - val_loss: 4.5042\n",
      "Epoch 5/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.6061 - val_loss: 3.5416\n",
      "Epoch 6/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.0682 - val_loss: 3.2589\n",
      "Epoch 7/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.8382 - val_loss: 2.9886\n",
      "Epoch 8/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.4177 - val_loss: 2.6008\n",
      "Epoch 9/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.7459 - val_loss: 2.1053\n",
      "Epoch 10/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.3722 - val_loss: 1.5772\n",
      "Epoch 11/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.8418 - val_loss: 1.1222\n",
      "Epoch 12/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.5198 - val_loss: 0.7865\n",
      "Epoch 13/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.9871 - val_loss: 0.7128\n",
      "Epoch 14/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.0087 - val_loss: 0.6211\n",
      "Epoch 15/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.7094 - val_loss: 0.5777\n",
      "Epoch 16/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.6952 - val_loss: 0.5605\n",
      "Epoch 17/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.5995 - val_loss: 0.5319\n",
      "Epoch 18/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.6233 - val_loss: 0.5133\n",
      "Epoch 19/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.5785 - val_loss: 0.4677\n",
      "Epoch 20/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.4512 - val_loss: 0.4447\n",
      "Epoch 21/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5951 - val_loss: 0.4092\n",
      "Epoch 22/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.4478 - val_loss: 0.3969\n",
      "Epoch 23/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.4054 - val_loss: 0.3717\n",
      "Epoch 24/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.2997 - val_loss: 0.4129\n",
      "Epoch 25/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.4506 - val_loss: 0.3704\n",
      "Epoch 26/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.2349 - val_loss: 0.3223\n",
      "Epoch 27/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.3294 - val_loss: 0.3133\n",
      "Epoch 28/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.3645 - val_loss: 0.3018\n",
      "Epoch 29/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.2107 - val_loss: 0.2778\n",
      "Epoch 30/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.2284 - val_loss: 0.2598\n",
      "Epoch 31/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.1662 - val_loss: 0.2770\n",
      "Epoch 32/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.1922 - val_loss: 0.2321\n",
      "Epoch 33/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.1937 - val_loss: 0.2164\n",
      "Epoch 34/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.1898 - val_loss: 0.2449\n",
      "Epoch 35/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.0092 - val_loss: 0.2448\n",
      "Epoch 36/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.1713 - val_loss: 0.2118\n",
      "Epoch 37/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.1129 - val_loss: 0.1967\n",
      "Epoch 38/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.9577 - val_loss: 0.1893\n",
      "Epoch 39/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.9434 - val_loss: 0.1769\n",
      "Epoch 40/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.0362 - val_loss: 0.1625\n",
      "Epoch 41/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8979 - val_loss: 0.1585\n",
      "Epoch 42/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.1453 - val_loss: 0.1588\n",
      "Epoch 43/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.1621 - val_loss: 0.1725\n",
      "Epoch 44/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.0308 - val_loss: 0.2296\n",
      "Epoch 45/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.9847 - val_loss: 0.1709\n",
      "Epoch 46/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.0126 - val_loss: 0.1694\n",
      "Epoch 47/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.9283 - val_loss: 0.1438\n",
      "Epoch 48/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.9515 - val_loss: 0.1618\n",
      "Epoch 49/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.0519 - val_loss: 0.1316\n",
      "Epoch 50/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8629 - val_loss: 0.2006\n",
      "Epoch 51/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.9227 - val_loss: 0.1509\n",
      "Epoch 52/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.0478 - val_loss: 0.1681\n",
      "Epoch 53/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8728 - val_loss: 0.1891\n",
      "Epoch 54/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9438 - val_loss: 0.1623\n",
      "Epoch 55/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.9671 - val_loss: 0.1570\n",
      "Epoch 56/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8845 - val_loss: 0.1106\n",
      "Epoch 57/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7798 - val_loss: 0.1203\n",
      "Epoch 58/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7875 - val_loss: 0.1078\n",
      "Epoch 59/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8536 - val_loss: 0.1077\n",
      "Epoch 60/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8974 - val_loss: 0.1054\n",
      "Epoch 61/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8536 - val_loss: 0.1055\n",
      "Epoch 62/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.9089 - val_loss: 0.1595\n",
      "Epoch 63/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8184 - val_loss: 0.1174\n",
      "Epoch 64/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7959 - val_loss: 0.1052\n",
      "Epoch 65/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7425 - val_loss: 0.1032\n",
      "Epoch 66/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8988 - val_loss: 0.1018\n",
      "Epoch 67/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7815 - val_loss: 0.1433\n",
      "Epoch 68/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7929 - val_loss: 0.0964\n",
      "Epoch 69/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8846 - val_loss: 0.0963\n",
      "Epoch 70/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7374 - val_loss: 0.0995\n",
      "Epoch 71/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8750 - val_loss: 0.0986\n",
      "Epoch 72/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8031 - val_loss: 0.1207\n",
      "Epoch 73/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7641 - val_loss: 0.0965\n",
      "Epoch 74/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8696 - val_loss: 0.0922\n",
      "Epoch 75/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8145 - val_loss: 0.0863\n",
      "Epoch 76/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8337 - val_loss: 0.0838\n",
      "Epoch 77/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7787 - val_loss: 0.1002\n",
      "Epoch 78/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7823 - val_loss: 0.0816\n",
      "Epoch 79/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7909 - val_loss: 0.1562\n",
      "Epoch 80/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7971 - val_loss: 0.0810\n",
      "Epoch 81/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6611 - val_loss: 0.1000\n",
      "Epoch 82/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8409 - val_loss: 0.1330\n",
      "Epoch 83/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8014 - val_loss: 0.0813\n",
      "Epoch 84/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8042 - val_loss: 0.0802\n",
      "Epoch 85/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8104 - val_loss: 0.1011\n",
      "Epoch 86/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7811 - val_loss: 0.0791\n",
      "Epoch 87/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7279 - val_loss: 0.0843\n",
      "Epoch 88/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7948 - val_loss: 0.0859\n",
      "Epoch 89/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8343 - val_loss: 0.1213\n",
      "Epoch 90/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6948 - val_loss: 0.0877\n",
      "Epoch 91/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6453 - val_loss: 0.0745\n",
      "Epoch 92/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6596 - val_loss: 0.0761\n",
      "Epoch 93/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7322 - val_loss: 0.0737\n",
      "Epoch 94/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7783 - val_loss: 0.0832\n",
      "Epoch 95/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8181 - val_loss: 0.0742\n",
      "Epoch 96/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7110 - val_loss: 0.0746\n",
      "Epoch 97/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7109 - val_loss: 0.0781\n",
      "Epoch 98/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7963 - val_loss: 0.0768\n",
      "Epoch 99/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7575 - val_loss: 0.0778\n",
      "Epoch 100/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7037 - val_loss: 0.0739\n",
      "Epoch 101/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6937 - val_loss: 0.0727\n",
      "Epoch 102/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7517 - val_loss: 0.1025\n",
      "Epoch 103/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7166 - val_loss: 0.0822\n",
      "Epoch 104/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7408 - val_loss: 0.0711\n",
      "Epoch 105/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7531 - val_loss: 0.0790\n",
      "Epoch 106/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7378 - val_loss: 0.0673\n",
      "Epoch 107/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7131 - val_loss: 0.0742\n",
      "Epoch 108/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6399 - val_loss: 0.0942\n",
      "Epoch 109/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7042 - val_loss: 0.0705\n",
      "Epoch 110/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7574 - val_loss: 0.0777\n",
      "Epoch 111/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6572 - val_loss: 0.0690\n",
      "Epoch 112/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6755 - val_loss: 0.0815\n",
      "Epoch 113/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7589 - val_loss: 0.0948\n",
      "Epoch 114/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7250 - val_loss: 0.0855\n",
      "Epoch 115/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7830 - val_loss: 0.1305\n",
      "Epoch 116/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6726 - val_loss: 0.0919\n",
      "Epoch 117/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6851 - val_loss: 0.0857\n",
      "Epoch 118/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6583 - val_loss: 0.0727\n",
      "Epoch 119/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6775 - val_loss: 0.0674\n",
      "Epoch 120/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6986 - val_loss: 0.0807\n",
      "Epoch 121/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7255 - val_loss: 0.0706\n",
      "Epoch 122/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6476 - val_loss: 0.0685\n",
      "Epoch 123/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7020 - val_loss: 0.0651\n",
      "Epoch 124/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6569 - val_loss: 0.0753\n",
      "Epoch 125/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5924 - val_loss: 0.0695\n",
      "Epoch 126/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8102 - val_loss: 0.0989\n",
      "Epoch 127/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7237 - val_loss: 0.0672\n",
      "Epoch 128/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6597 - val_loss: 0.0912\n",
      "Epoch 129/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.0649\n",
      "Epoch 130/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7104 - val_loss: 0.1184\n",
      "Epoch 131/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6344 - val_loss: 0.0734\n",
      "Epoch 132/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7087 - val_loss: 0.0718\n",
      "Epoch 133/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6901 - val_loss: 0.0637\n",
      "Epoch 134/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7373 - val_loss: 0.0646\n",
      "Epoch 135/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7179 - val_loss: 0.0693\n",
      "Epoch 136/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6242 - val_loss: 0.0694\n",
      "Epoch 137/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6954 - val_loss: 0.0804\n",
      "Epoch 138/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6942 - val_loss: 0.0717\n",
      "Epoch 139/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6588 - val_loss: 0.0717\n",
      "Epoch 140/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6329 - val_loss: 0.0800\n",
      "Epoch 141/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6702 - val_loss: 0.0798\n",
      "Epoch 142/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6080 - val_loss: 0.0827\n",
      "Epoch 143/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6283 - val_loss: 0.0635\n",
      "Epoch 144/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6004 - val_loss: 0.0642\n",
      "Epoch 145/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5895 - val_loss: 0.0630\n",
      "Epoch 146/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7228 - val_loss: 0.0619\n",
      "Epoch 147/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6546 - val_loss: 0.0705\n",
      "Epoch 148/150\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7071 - val_loss: 0.0732\n",
      "Epoch 149/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6549 - val_loss: 0.0658\n",
      "Epoch 150/150\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5959 - val_loss: 0.0998\n",
      "7/7 [==============================] - 1s 2ms/step\n",
      "Evaluation results for SAVE:\n",
      "Mean Squared Error: 0.8823872577481033\n",
      "Mean Absolute Error: 0.6348024766836594\n",
      "R-squared: 0.9839090854553615\n",
      "\n",
      "Evaluation results for CLNE:\n",
      "Mean Squared Error: 0.1376029547748952\n",
      "Mean Absolute Error: 0.22526699630775263\n",
      "R-squared: 0.9872196200893496\n",
      "\n",
      "Evaluation results for LAZR:\n",
      "Mean Squared Error: 0.47693247642515396\n",
      "Mean Absolute Error: 0.49712300797303527\n",
      "R-squared: 0.9921070410941283\n",
      "\n",
      "Evaluation results for AMWL:\n",
      "Mean Squared Error: 0.4393887310662142\n",
      "Mean Absolute Error: 0.43696425119078314\n",
      "R-squared: 0.9951544531487766\n",
      "\n",
      "Evaluation results for GEO:\n",
      "Mean Squared Error: 0.12463275452301417\n",
      "Mean Absolute Error: 0.25578045251950693\n",
      "R-squared: 0.9777798615342843\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('dataset.csv').dropna()\n",
    "\n",
    "# List of ticker symbols\n",
    "tickers = df['level_0'].unique()\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "evaluation_results_nextday = {}\n",
    "\n",
    "# Loop through each ticker\n",
    "for ticker in tickers:\n",
    "    # Filter data for the current ticker\n",
    "    ticker_df = df[df['level_0'] == ticker]\n",
    "    \n",
    "    # Extract features and target variable\n",
    "    X = ticker_df[['Open', 'High', 'Low', 'Close', 'Volume','Daily Returns','Volatility','RSI', '%K', '%D','Sentiment Score','Movement','PreviousDayClose']].values\n",
    "    y = ticker_df['NextDayClose'].values\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split dataset into training plus validation, and testing sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Split training plus validation set into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "    # Reshape input data for GRU (samples, time steps, features)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], 1, X_val.shape[1]))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "    \n",
    "    # Define the GRU model\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(units=50))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=1, validation_data=(X_val, y_val))\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    # Store evaluation results\n",
    "    evaluation_results_nextday[ticker] = {'Mean Squared Error': mse, 'Mean Absolute Error': mae, 'R-squared': r2}\n",
    "\n",
    "# Display evaluation results\n",
    "for ticker, results in evaluation_results_nextday.items():\n",
    "    print(f'Evaluation results for {ticker}:')\n",
    "    for metric, value in results.items():\n",
    "        print(f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot of actual vs. predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, predictions, color='red', alpha=0.5, label='Actual')  # Actual values in red\n",
    "plt.scatter(y_test, predictions, color='blue', alpha=0.5, label='Predicted')  # Predicted values in blue\n",
    "plt.title('Actual vs. Predicted Stock Prices')\n",
    "plt.xlabel('Actual Next Day Close Price')\n",
    "plt.ylabel('Predicted Next Day Close Price')\n",
    "plt.legend()  # Show legend to differentiate between actual and predicted\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6cd6ebbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Score Weight: [-0.37049764]\n"
     ]
    }
   ],
   "source": [
    "# Extract the sentiment score weights from the dense layer\n",
    "sentiment_score_weights = model.layers[-1].get_weights()[0][-1]\n",
    "\n",
    "# Interpret the sentiment score weights\n",
    "print(\"Sentiment Score Weight:\", sentiment_score_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcc6e8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Aggregate stock prices based on sentiment scores\n",
    "sentiment_price_avg = ticker_df.groupby('Sentiment Score')['PreviousDayClose'].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the line plot\n",
    "plt.plot(sentiment_price_avg.index, sentiment_price_avg.values, marker='o', linestyle='-')\n",
    "plt.title('Average Stock Price vs. Sentiment Score')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Average Previous Day Close Price')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c0d890",
   "metadata": {},
   "source": [
    "GRU Model for previousday close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd4c27b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "26/26 [==============================] - 4s 28ms/step - loss: 532.7128 - val_loss: 504.2236\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 403.4807 - val_loss: 269.4649\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 203.3699 - val_loss: 157.4692\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 137.4109 - val_loss: 122.1678\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 109.9990 - val_loss: 100.7522\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 92.6651 - val_loss: 86.9058\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 81.3005 - val_loss: 76.2894\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 72.3304 - val_loss: 69.3717\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 67.0012 - val_loss: 64.2593\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 63.7890 - val_loss: 60.5470\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 60.3772 - val_loss: 58.0527\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 57.6591 - val_loss: 56.4983\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 57.3997 - val_loss: 55.4457\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 56.3179 - val_loss: 54.7907\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 56.0051 - val_loss: 54.2809\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 55.2054 - val_loss: 53.9096\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 54.8789 - val_loss: 53.6234\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 55.1125 - val_loss: 53.4007\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 53.7629 - val_loss: 53.1287\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 54.3850 - val_loss: 52.7731\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 53.2214 - val_loss: 52.1676\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 53.5767 - val_loss: 50.6927\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 51.8998 - val_loss: 47.3023\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 45.6141 - val_loss: 39.6361\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 38.2057 - val_loss: 31.7129\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 32.3515 - val_loss: 27.8545\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 30.2795 - val_loss: 25.0957\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 27.2341 - val_loss: 22.4979\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 24.9160 - val_loss: 20.3178\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 24.4906 - val_loss: 18.6685\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 21.9430 - val_loss: 17.1762\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 20.8898 - val_loss: 15.7913\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 19.9942 - val_loss: 14.2080\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 17.3771 - val_loss: 13.1408\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 16.8896 - val_loss: 12.1258\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 16.7672 - val_loss: 11.5832\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 16.4896 - val_loss: 10.5070\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 14.8774 - val_loss: 9.7288\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 16.8049 - val_loss: 8.9468\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 14.6210 - val_loss: 8.2331\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 13.1054 - val_loss: 7.6816\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 11.7449 - val_loss: 7.2555\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 10.6920 - val_loss: 6.6262\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 11.5759 - val_loss: 6.5674\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 11.1919 - val_loss: 6.2022\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 10.7311 - val_loss: 5.3524\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 9.6291 - val_loss: 4.9928\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 9.7497 - val_loss: 4.5981\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 8.9207 - val_loss: 4.3016\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 8.8050 - val_loss: 3.9679\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 7.9461 - val_loss: 4.2705\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 9.0088 - val_loss: 3.5941\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 8.4782 - val_loss: 3.2053\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 7.6214 - val_loss: 2.9721\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 6.6541 - val_loss: 2.8041\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 7.5376 - val_loss: 2.5845\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 6.8409 - val_loss: 2.4283\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 6.5919 - val_loss: 2.3266\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 6.9194 - val_loss: 2.2444\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 6.3857 - val_loss: 2.0438\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 6.5644 - val_loss: 1.9109\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 6.1093 - val_loss: 1.7759\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 6.6310 - val_loss: 2.1814\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.0173 - val_loss: 1.5759\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 5.8618 - val_loss: 1.9638\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.6700 - val_loss: 1.4122\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 5.0074 - val_loss: 2.0449\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 4.9963 - val_loss: 1.3315\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.9220 - val_loss: 1.2221\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 4.9196 - val_loss: 1.2247\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 5.7262 - val_loss: 1.1308\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 5.6782 - val_loss: 1.1529\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 5.1677 - val_loss: 1.0935\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 5.3904 - val_loss: 0.9928\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.8877 - val_loss: 0.9559\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 5.4060 - val_loss: 1.0057\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 4.6054 - val_loss: 0.9115\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 4.4506 - val_loss: 1.2025\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 4.7894 - val_loss: 0.8981\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.6064 - val_loss: 0.9784\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 4.9653 - val_loss: 0.7802\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 5ms/step - loss: 4.5115 - val_loss: 0.7760\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 4.6344 - val_loss: 0.7552\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.9766 - val_loss: 0.6898\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 4.2388 - val_loss: 0.7485\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 4.2212 - val_loss: 0.6778\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 4.8472 - val_loss: 0.6523\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.0611 - val_loss: 0.6226\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.2768 - val_loss: 0.7623\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.7551 - val_loss: 0.5865\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.1355 - val_loss: 0.5998\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.1714 - val_loss: 0.5787\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 4.0862 - val_loss: 0.5633\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.9542 - val_loss: 0.9711\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.9711 - val_loss: 0.6022\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 4.0156 - val_loss: 0.5648\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.2121 - val_loss: 0.6006\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 4.1772 - val_loss: 0.5409\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.9454 - val_loss: 0.7333\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.9086 - val_loss: 0.8059\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.6957 - val_loss: 0.4753\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.7312 - val_loss: 0.6274\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.6328 - val_loss: 0.5860\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.5162 - val_loss: 0.4603\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.8561 - val_loss: 0.4655\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.6879 - val_loss: 0.6044\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.0020 - val_loss: 0.5998\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.2241 - val_loss: 0.5490\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.7736 - val_loss: 0.4118\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 4.0531 - val_loss: 0.5291\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.6370 - val_loss: 0.3971\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.4618 - val_loss: 0.3773\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.8883 - val_loss: 0.3892\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.9738 - val_loss: 0.4192\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.7849 - val_loss: 0.4463\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.7939 - val_loss: 0.5777\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.5229 - val_loss: 0.4152\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.8499 - val_loss: 0.5499\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.5469 - val_loss: 0.4071\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.6782 - val_loss: 0.3944\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.9212 - val_loss: 0.5453\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.7071 - val_loss: 0.4163\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.8138 - val_loss: 0.3683\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.7063 - val_loss: 0.3129\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2564 - val_loss: 0.4110\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.6276 - val_loss: 0.3756\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.8204 - val_loss: 0.4292\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.8819 - val_loss: 0.5244\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.5054 - val_loss: 0.7972\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.6982 - val_loss: 0.3316\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.0166 - val_loss: 0.6392\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.4743 - val_loss: 0.4593\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.5585 - val_loss: 0.3930\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.1922 - val_loss: 0.2989\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.5332 - val_loss: 0.3153\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.6878 - val_loss: 0.3616\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.2370 - val_loss: 0.2728\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.1697 - val_loss: 0.3161\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.8121 - val_loss: 0.4051\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 2.9888 - val_loss: 0.4230\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.7337 - val_loss: 0.2910\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.3554 - val_loss: 0.2947\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.2277 - val_loss: 0.2961\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.7041 - val_loss: 0.2783\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.4765 - val_loss: 0.2791\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2891 - val_loss: 0.2711\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.6209 - val_loss: 0.2338\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 3.3334 - val_loss: 0.3793\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.2434 - val_loss: 0.2433\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.0693 - val_loss: 0.2435\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.5785 - val_loss: 0.2666\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.1096 - val_loss: 0.3168\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.6364 - val_loss: 0.4149\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.0127 - val_loss: 0.2789\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 2.7593 - val_loss: 0.2845\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 3.2949 - val_loss: 0.2607\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.3190 - val_loss: 0.2641\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.2406 - val_loss: 0.2527\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.9157 - val_loss: 0.7983\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 2.7923 - val_loss: 0.2244\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2376 - val_loss: 0.5874\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.7729 - val_loss: 0.2313\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 5ms/step - loss: 3.1433 - val_loss: 0.2046\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 2.9512 - val_loss: 0.2033\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.1990 - val_loss: 0.2210\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2779 - val_loss: 0.2341\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.1466 - val_loss: 0.2929\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.2150 - val_loss: 0.1970\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.5487 - val_loss: 0.4127\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2271 - val_loss: 0.7818\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.1434 - val_loss: 0.2811\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 2.8870 - val_loss: 0.2261\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.1592 - val_loss: 0.2358\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.4248 - val_loss: 0.4583\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2589 - val_loss: 0.3464\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.6491 - val_loss: 0.3045\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.4668 - val_loss: 0.4173\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.7197 - val_loss: 0.3148\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.1210 - val_loss: 0.1878\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2035 - val_loss: 0.3428\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.3602 - val_loss: 0.1706\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.1671 - val_loss: 0.1507\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2581 - val_loss: 0.1837\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.3963 - val_loss: 0.1813\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.0854 - val_loss: 0.5590\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.1445 - val_loss: 0.3302\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 2.9825 - val_loss: 0.3702\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2966 - val_loss: 0.1642\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 2.7248 - val_loss: 0.3033\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.6505 - val_loss: 0.2471\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.5509 - val_loss: 0.2251\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2371 - val_loss: 0.1861\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2788 - val_loss: 0.1763\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.5865 - val_loss: 0.3514\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.3984 - val_loss: 0.2515\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2168 - val_loss: 0.1513\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.1386 - val_loss: 0.3963\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.0252 - val_loss: 0.2483\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.3712 - val_loss: 0.2394\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 3.2377 - val_loss: 0.1865\n",
      "7/7 [==============================] - 1s 2ms/step\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 4s 30ms/step - loss: 37.4753 - val_loss: 33.9626\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 16.9682 - val_loss: 7.4634\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 7.5069 - val_loss: 6.7257\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 6.0203 - val_loss: 5.2105\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.5404 - val_loss: 3.1527\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 2.6254 - val_loss: 1.3570\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.5448 - val_loss: 0.8203\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.3134 - val_loss: 0.6802\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.2166 - val_loss: 0.5779\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.0862 - val_loss: 0.5136\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.9951 - val_loss: 0.4727\n",
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.0288 - val_loss: 0.4335\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.9318 - val_loss: 0.3667\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.8184 - val_loss: 0.3479\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.7962 - val_loss: 0.3103\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.8080 - val_loss: 0.2656\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.8476 - val_loss: 0.2519\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.7246 - val_loss: 0.2300\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.7958 - val_loss: 0.2146\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6868 - val_loss: 0.2256\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.7518 - val_loss: 0.1820\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6604 - val_loss: 0.1641\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.7285 - val_loss: 0.1479\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6086 - val_loss: 0.1374\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6296 - val_loss: 0.1253\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6895 - val_loss: 0.1359\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6330 - val_loss: 0.1472\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5459 - val_loss: 0.1366\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5450 - val_loss: 0.1221\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5509 - val_loss: 0.1003\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6238 - val_loss: 0.1062\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5619 - val_loss: 0.1910\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5429 - val_loss: 0.0935\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5334 - val_loss: 0.0862\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4957 - val_loss: 0.0952\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5288 - val_loss: 0.1217\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5224 - val_loss: 0.0800\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5280 - val_loss: 0.0812\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4302 - val_loss: 0.0865\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4535 - val_loss: 0.1065\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4445 - val_loss: 0.1086\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5400 - val_loss: 0.0879\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3937 - val_loss: 0.0747\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4353 - val_loss: 0.0744\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4240 - val_loss: 0.0751\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4444 - val_loss: 0.1180\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3995 - val_loss: 0.1460\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4633 - val_loss: 0.0916\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4144 - val_loss: 0.1034\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4404 - val_loss: 0.0779\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3902 - val_loss: 0.0767\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4603 - val_loss: 0.0746\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4741 - val_loss: 0.0704\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4034 - val_loss: 0.0777\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3926 - val_loss: 0.1001\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3276 - val_loss: 0.0726\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4130 - val_loss: 0.0638\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4635 - val_loss: 0.0767\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3771 - val_loss: 0.0754\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4366 - val_loss: 0.0650\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4293 - val_loss: 0.0851\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3939 - val_loss: 0.1451\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4106 - val_loss: 0.1689\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4514 - val_loss: 0.0624\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4366 - val_loss: 0.0703\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3948 - val_loss: 0.0565\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3435 - val_loss: 0.0594\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4068 - val_loss: 0.0908\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3875 - val_loss: 0.0546\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3974 - val_loss: 0.0758\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3625 - val_loss: 0.0557\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4485 - val_loss: 0.1555\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4364 - val_loss: 0.2756\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4306 - val_loss: 0.1115\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4452 - val_loss: 0.0669\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3697 - val_loss: 0.0813\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4138 - val_loss: 0.0896\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4042 - val_loss: 0.0708\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3463 - val_loss: 0.0690\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3846 - val_loss: 0.0667\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3514 - val_loss: 0.0577\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3267 - val_loss: 0.0637\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4516 - val_loss: 0.0592\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3286 - val_loss: 0.0682\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3203 - val_loss: 0.0514\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3176 - val_loss: 0.1171\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3678 - val_loss: 0.0867\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3586 - val_loss: 0.0637\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3157 - val_loss: 0.0696\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3922 - val_loss: 0.0800\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3753 - val_loss: 0.0708\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3162 - val_loss: 0.0542\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3227 - val_loss: 0.0570\n",
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3613 - val_loss: 0.0567\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3334 - val_loss: 0.0532\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3750 - val_loss: 0.0525\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3511 - val_loss: 0.0721\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3271 - val_loss: 0.0506\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3207 - val_loss: 0.0642\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3213 - val_loss: 0.0507\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3126 - val_loss: 0.0868\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3299 - val_loss: 0.0449\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3250 - val_loss: 0.0616\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3323 - val_loss: 0.0424\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3114 - val_loss: 0.0467\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3373 - val_loss: 0.0436\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3120 - val_loss: 0.0428\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3487 - val_loss: 0.0449\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3235 - val_loss: 0.0491\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3310 - val_loss: 0.0498\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3385 - val_loss: 0.0577\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3306 - val_loss: 0.0457\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3252 - val_loss: 0.0460\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3436 - val_loss: 0.0492\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2683 - val_loss: 0.0448\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3074 - val_loss: 0.0500\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2876 - val_loss: 0.0464\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4005 - val_loss: 0.0612\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3225 - val_loss: 0.0473\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3092 - val_loss: 0.0387\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3294 - val_loss: 0.0648\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3649 - val_loss: 0.0539\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3050 - val_loss: 0.0588\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2995 - val_loss: 0.0735\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3432 - val_loss: 0.0436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.3162 - val_loss: 0.0691\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3247 - val_loss: 0.0606\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3191 - val_loss: 0.0405\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2866 - val_loss: 0.0466\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3153 - val_loss: 0.0483\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.3091 - val_loss: 0.0575\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2978 - val_loss: 0.0555\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3121 - val_loss: 0.0449\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3212 - val_loss: 0.0327\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3073 - val_loss: 0.0521\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2710 - val_loss: 0.0422\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3590 - val_loss: 0.0629\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3011 - val_loss: 0.0428\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3024 - val_loss: 0.0778\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3627 - val_loss: 0.0435\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3048 - val_loss: 0.0764\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3031 - val_loss: 0.0905\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3103 - val_loss: 0.0605\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3217 - val_loss: 0.0460\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3203 - val_loss: 0.0522\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2923 - val_loss: 0.0316\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3002 - val_loss: 0.0390\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2970 - val_loss: 0.0516\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2609 - val_loss: 0.0552\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2967 - val_loss: 0.0595\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3102 - val_loss: 0.0272\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2837 - val_loss: 0.0312\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2891 - val_loss: 0.0326\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2871 - val_loss: 0.0875\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3456 - val_loss: 0.0316\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2481 - val_loss: 0.0325\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2545 - val_loss: 0.0644\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2984 - val_loss: 0.0385\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3244 - val_loss: 0.0563\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2913 - val_loss: 0.0917\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2843 - val_loss: 0.0663\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3052 - val_loss: 0.0655\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2753 - val_loss: 0.0319\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2603 - val_loss: 0.0442\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2825 - val_loss: 0.0365\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2689 - val_loss: 0.0312\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3292 - val_loss: 0.0961\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3151 - val_loss: 0.0529\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3446 - val_loss: 0.0607\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3227 - val_loss: 0.0599\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3097 - val_loss: 0.0355\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3597 - val_loss: 0.0421\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2767 - val_loss: 0.0339\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2903 - val_loss: 0.0455\n",
      "Epoch 175/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2962 - val_loss: 0.0621\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2893 - val_loss: 0.0772\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2924 - val_loss: 0.0533\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2763 - val_loss: 0.0663\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2834 - val_loss: 0.0301\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2296 - val_loss: 0.0295\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2713 - val_loss: 0.0439\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2756 - val_loss: 0.0263\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3234 - val_loss: 0.0299\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2525 - val_loss: 0.0280\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2629 - val_loss: 0.0481\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2973 - val_loss: 0.0289\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3035 - val_loss: 0.0329\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2826 - val_loss: 0.0426\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.2579 - val_loss: 0.0296\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2915 - val_loss: 0.0435\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2649 - val_loss: 0.0245\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2330 - val_loss: 0.0242\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.3095 - val_loss: 0.0243\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2624 - val_loss: 0.0388\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2693 - val_loss: 0.0773\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2862 - val_loss: 0.0315\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2907 - val_loss: 0.0758\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2559 - val_loss: 0.0426\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2568 - val_loss: 0.0413\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.2603 - val_loss: 0.0251\n",
      "7/7 [==============================] - 1s 2ms/step\n",
      "Epoch 1/200\n",
      "24/24 [==============================] - 4s 31ms/step - loss: 204.6965 - val_loss: 193.5753\n",
      "Epoch 2/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 142.5322 - val_loss: 90.0900\n",
      "Epoch 3/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 65.5457 - val_loss: 58.4231\n",
      "Epoch 4/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 53.5672 - val_loss: 56.6857\n",
      "Epoch 5/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 52.5519 - val_loss: 54.6871\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step - loss: 49.5412 - val_loss: 50.8777\n",
      "Epoch 7/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 45.6253 - val_loss: 42.9655\n",
      "Epoch 8/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 36.7640 - val_loss: 30.9724\n",
      "Epoch 9/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 27.9934 - val_loss: 22.2763\n",
      "Epoch 10/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 21.8796 - val_loss: 18.3397\n",
      "Epoch 11/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 19.8381 - val_loss: 15.8436\n",
      "Epoch 12/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 16.7998 - val_loss: 13.9069\n",
      "Epoch 13/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 16.0422 - val_loss: 12.4469\n",
      "Epoch 14/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 13.9954 - val_loss: 11.1400\n",
      "Epoch 15/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 13.0492 - val_loss: 10.0475\n",
      "Epoch 16/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 12.1410 - val_loss: 9.0679\n",
      "Epoch 17/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 10.7699 - val_loss: 8.2217\n",
      "Epoch 18/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 10.7918 - val_loss: 7.3778\n",
      "Epoch 19/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 9.2937 - val_loss: 6.8882\n",
      "Epoch 20/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.4047 - val_loss: 6.1921\n",
      "Epoch 21/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1894 - val_loss: 5.7010\n",
      "Epoch 22/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 8.1975 - val_loss: 5.1952\n",
      "Epoch 23/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 7.0762 - val_loss: 4.7338\n",
      "Epoch 24/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.8031 - val_loss: 4.4656\n",
      "Epoch 25/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.1760 - val_loss: 4.0746\n",
      "Epoch 26/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8726 - val_loss: 3.7668\n",
      "Epoch 27/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 6.5407 - val_loss: 3.4843\n",
      "Epoch 28/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.8600 - val_loss: 3.3699\n",
      "Epoch 29/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.2471 - val_loss: 3.0540\n",
      "Epoch 30/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.3747 - val_loss: 2.8079\n",
      "Epoch 31/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 5.1466 - val_loss: 2.5904\n",
      "Epoch 32/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.5266 - val_loss: 2.4667\n",
      "Epoch 33/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.7993 - val_loss: 2.4960\n",
      "Epoch 34/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.5776 - val_loss: 2.1287\n",
      "Epoch 35/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.9677 - val_loss: 2.1579\n",
      "Epoch 36/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 4.0646 - val_loss: 1.9119\n",
      "Epoch 37/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.8426 - val_loss: 1.8326\n",
      "Epoch 38/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.7027 - val_loss: 1.7267\n",
      "Epoch 39/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.4527 - val_loss: 1.7019\n",
      "Epoch 40/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.1910 - val_loss: 1.5256\n",
      "Epoch 41/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.3792 - val_loss: 1.5914\n",
      "Epoch 42/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.0625 - val_loss: 1.5872\n",
      "Epoch 43/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.1075 - val_loss: 1.3637\n",
      "Epoch 44/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.4134 - val_loss: 1.3732\n",
      "Epoch 45/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.0578 - val_loss: 1.2350\n",
      "Epoch 46/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.8975 - val_loss: 1.1967\n",
      "Epoch 47/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.7358 - val_loss: 1.1826\n",
      "Epoch 48/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.5204 - val_loss: 1.1085\n",
      "Epoch 49/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.9908 - val_loss: 1.0431\n",
      "Epoch 50/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.6678 - val_loss: 1.0015\n",
      "Epoch 51/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.8045 - val_loss: 0.9879\n",
      "Epoch 52/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.5221 - val_loss: 0.9590\n",
      "Epoch 53/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.7915 - val_loss: 0.9909\n",
      "Epoch 54/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 3.0661 - val_loss: 0.9931\n",
      "Epoch 55/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.4861 - val_loss: 0.9078\n",
      "Epoch 56/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 2.6831 - val_loss: 0.8715\n",
      "Epoch 57/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.5213 - val_loss: 0.8398\n",
      "Epoch 58/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.9150 - val_loss: 0.9889\n",
      "Epoch 59/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.6835 - val_loss: 0.7745\n",
      "Epoch 60/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.7498 - val_loss: 0.7419\n",
      "Epoch 61/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.7500 - val_loss: 1.0513\n",
      "Epoch 62/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.1582 - val_loss: 0.7286\n",
      "Epoch 63/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.3263 - val_loss: 0.7281\n",
      "Epoch 64/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.2723 - val_loss: 0.7463\n",
      "Epoch 65/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.3435 - val_loss: 0.6875\n",
      "Epoch 66/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.1482 - val_loss: 0.6627\n",
      "Epoch 67/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.4122 - val_loss: 0.6610\n",
      "Epoch 68/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.2414 - val_loss: 0.8287\n",
      "Epoch 69/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.4288 - val_loss: 0.6169\n",
      "Epoch 70/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.3510 - val_loss: 0.6364\n",
      "Epoch 71/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.2049 - val_loss: 0.7601\n",
      "Epoch 72/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.1885 - val_loss: 0.6242\n",
      "Epoch 73/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.2738 - val_loss: 0.5420\n",
      "Epoch 74/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9032 - val_loss: 0.5466\n",
      "Epoch 75/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.3534 - val_loss: 0.5350\n",
      "Epoch 76/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.2206 - val_loss: 0.5146\n",
      "Epoch 77/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9940 - val_loss: 0.5020\n",
      "Epoch 78/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.1623 - val_loss: 0.4990\n",
      "Epoch 79/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.3553 - val_loss: 0.5150\n",
      "Epoch 80/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9856 - val_loss: 0.6025\n",
      "Epoch 81/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9770 - val_loss: 0.4905\n",
      "Epoch 82/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8786 - val_loss: 0.5322\n",
      "Epoch 83/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.1488 - val_loss: 0.4604\n",
      "Epoch 84/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9997 - val_loss: 0.6017\n",
      "Epoch 85/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9335 - val_loss: 0.4768\n",
      "Epoch 86/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8811 - val_loss: 0.4186\n",
      "Epoch 87/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9637 - val_loss: 0.4360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9312 - val_loss: 0.5810\n",
      "Epoch 89/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.1945 - val_loss: 0.4852\n",
      "Epoch 90/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9400 - val_loss: 0.4000\n",
      "Epoch 91/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7833 - val_loss: 0.4078\n",
      "Epoch 92/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.2261 - val_loss: 0.4351\n",
      "Epoch 93/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9295 - val_loss: 0.4202\n",
      "Epoch 94/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8447 - val_loss: 0.4162\n",
      "Epoch 95/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7644 - val_loss: 0.3972\n",
      "Epoch 96/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9116 - val_loss: 0.3312\n",
      "Epoch 97/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7005 - val_loss: 0.3778\n",
      "Epoch 98/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9925 - val_loss: 0.5967\n",
      "Epoch 99/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.1116 - val_loss: 0.3319\n",
      "Epoch 100/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9171 - val_loss: 0.4199\n",
      "Epoch 101/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8971 - val_loss: 0.3332\n",
      "Epoch 102/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6965 - val_loss: 0.5520\n",
      "Epoch 103/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9662 - val_loss: 0.3316\n",
      "Epoch 104/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6841 - val_loss: 0.3403\n",
      "Epoch 105/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7116 - val_loss: 0.3220\n",
      "Epoch 106/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9650 - val_loss: 0.3971\n",
      "Epoch 107/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.1725 - val_loss: 0.6732\n",
      "Epoch 108/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.2585 - val_loss: 0.3611\n",
      "Epoch 109/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8094 - val_loss: 0.2745\n",
      "Epoch 110/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8286 - val_loss: 0.2664\n",
      "Epoch 111/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 2.1020 - val_loss: 0.5078\n",
      "Epoch 112/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8126 - val_loss: 0.3235\n",
      "Epoch 113/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9255 - val_loss: 0.3352\n",
      "Epoch 114/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7958 - val_loss: 0.2647\n",
      "Epoch 115/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8716 - val_loss: 0.4075\n",
      "Epoch 116/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8540 - val_loss: 0.2482\n",
      "Epoch 117/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.6613 - val_loss: 0.2215\n",
      "Epoch 118/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5231 - val_loss: 0.2097\n",
      "Epoch 119/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9913 - val_loss: 0.2340\n",
      "Epoch 120/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6278 - val_loss: 0.2669\n",
      "Epoch 121/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.4413 - val_loss: 0.2181\n",
      "Epoch 122/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8303 - val_loss: 0.2820\n",
      "Epoch 123/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8028 - val_loss: 0.2205\n",
      "Epoch 124/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8021 - val_loss: 0.2604\n",
      "Epoch 125/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6333 - val_loss: 0.2246\n",
      "Epoch 126/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6123 - val_loss: 0.3393\n",
      "Epoch 127/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.4699 - val_loss: 0.1985\n",
      "Epoch 128/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7215 - val_loss: 0.2569\n",
      "Epoch 129/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5912 - val_loss: 0.1962\n",
      "Epoch 130/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7178 - val_loss: 0.2258\n",
      "Epoch 131/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6373 - val_loss: 0.4659\n",
      "Epoch 132/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5710 - val_loss: 0.2030\n",
      "Epoch 133/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7893 - val_loss: 0.1810\n",
      "Epoch 134/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6858 - val_loss: 0.1993\n",
      "Epoch 135/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7720 - val_loss: 0.3169\n",
      "Epoch 136/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8404 - val_loss: 0.2120\n",
      "Epoch 137/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7757 - val_loss: 0.1662\n",
      "Epoch 138/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6785 - val_loss: 0.1997\n",
      "Epoch 139/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.9023 - val_loss: 0.2217\n",
      "Epoch 140/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8616 - val_loss: 0.1773\n",
      "Epoch 141/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6475 - val_loss: 0.3014\n",
      "Epoch 142/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.4765 - val_loss: 0.1747\n",
      "Epoch 143/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7053 - val_loss: 0.2417\n",
      "Epoch 144/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5714 - val_loss: 0.1655\n",
      "Epoch 145/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5225 - val_loss: 0.1728\n",
      "Epoch 146/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5843 - val_loss: 0.1294\n",
      "Epoch 147/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6505 - val_loss: 0.1422\n",
      "Epoch 148/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5890 - val_loss: 0.1428\n",
      "Epoch 149/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7000 - val_loss: 0.1211\n",
      "Epoch 150/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6553 - val_loss: 0.2263\n",
      "Epoch 151/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.4906 - val_loss: 0.3502\n",
      "Epoch 152/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5113 - val_loss: 0.1798\n",
      "Epoch 153/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5641 - val_loss: 0.1810\n",
      "Epoch 154/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7000 - val_loss: 0.1465\n",
      "Epoch 155/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7482 - val_loss: 0.2636\n",
      "Epoch 156/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5851 - val_loss: 0.1791\n",
      "Epoch 157/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.3531 - val_loss: 0.1308\n",
      "Epoch 158/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7871 - val_loss: 0.1398\n",
      "Epoch 159/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7328 - val_loss: 0.2925\n",
      "Epoch 160/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7526 - val_loss: 0.1771\n",
      "Epoch 161/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8102 - val_loss: 0.2028\n",
      "Epoch 162/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.3344 - val_loss: 0.1167\n",
      "Epoch 163/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5095 - val_loss: 0.2175\n",
      "Epoch 164/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.4758 - val_loss: 0.1196\n",
      "Epoch 165/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.4585 - val_loss: 0.1241\n",
      "Epoch 166/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.3950 - val_loss: 0.1202\n",
      "Epoch 167/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8865 - val_loss: 0.5584\n",
      "Epoch 168/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5875 - val_loss: 0.1733\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7754 - val_loss: 0.1954\n",
      "Epoch 170/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7849 - val_loss: 0.4344\n",
      "Epoch 171/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.4501 - val_loss: 0.1260\n",
      "Epoch 172/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.3602 - val_loss: 0.1417\n",
      "Epoch 173/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.8076 - val_loss: 0.1248\n",
      "Epoch 174/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7310 - val_loss: 0.1344\n",
      "Epoch 175/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.4208 - val_loss: 0.1233\n",
      "Epoch 176/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6861 - val_loss: 0.1359\n",
      "Epoch 177/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5842 - val_loss: 0.0935\n",
      "Epoch 178/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.7997 - val_loss: 0.1729\n",
      "Epoch 179/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.4918 - val_loss: 0.1146\n",
      "Epoch 180/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.4702 - val_loss: 0.1282\n",
      "Epoch 181/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5813 - val_loss: 0.2135\n",
      "Epoch 182/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.4254 - val_loss: 0.1551\n",
      "Epoch 183/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6509 - val_loss: 0.1444\n",
      "Epoch 184/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7471 - val_loss: 0.1048\n",
      "Epoch 185/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5495 - val_loss: 0.1116\n",
      "Epoch 186/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6460 - val_loss: 0.2247\n",
      "Epoch 187/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5516 - val_loss: 0.1558\n",
      "Epoch 188/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6328 - val_loss: 0.1919\n",
      "Epoch 189/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6395 - val_loss: 0.3333\n",
      "Epoch 190/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5778 - val_loss: 0.1499\n",
      "Epoch 191/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.4423 - val_loss: 0.3202\n",
      "Epoch 192/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5543 - val_loss: 0.1307\n",
      "Epoch 193/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.4794 - val_loss: 0.0991\n",
      "Epoch 194/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.3647 - val_loss: 0.1433\n",
      "Epoch 195/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.3150 - val_loss: 0.1012\n",
      "Epoch 196/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.7555 - val_loss: 0.1134\n",
      "Epoch 197/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.5970 - val_loss: 0.1244\n",
      "Epoch 198/200\n",
      "24/24 [==============================] - 0s 5ms/step - loss: 1.6477 - val_loss: 0.1178\n",
      "Epoch 199/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6321 - val_loss: 0.2091\n",
      "Epoch 200/200\n",
      "24/24 [==============================] - 0s 4ms/step - loss: 1.6572 - val_loss: 0.1364\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Epoch 1/200\n",
      "21/21 [==============================] - 4s 35ms/step - loss: 162.5443 - val_loss: 163.0129\n",
      "Epoch 2/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 138.6496 - val_loss: 118.3434\n",
      "Epoch 3/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 93.8938 - val_loss: 85.2668\n",
      "Epoch 4/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 80.5994 - val_loss: 80.5602\n",
      "Epoch 5/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 73.4963 - val_loss: 71.0363\n",
      "Epoch 6/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 61.7533 - val_loss: 54.4894\n",
      "Epoch 7/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 46.0448 - val_loss: 39.6929\n",
      "Epoch 8/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 35.0810 - val_loss: 32.0373\n",
      "Epoch 9/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 30.1713 - val_loss: 27.4251\n",
      "Epoch 10/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 25.9753 - val_loss: 24.0515\n",
      "Epoch 11/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 24.5319 - val_loss: 21.1657\n",
      "Epoch 12/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 20.7981 - val_loss: 18.5988\n",
      "Epoch 13/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 18.7268 - val_loss: 16.3733\n",
      "Epoch 14/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 17.3350 - val_loss: 14.4918\n",
      "Epoch 15/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 15.5242 - val_loss: 12.7444\n",
      "Epoch 16/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 14.5620 - val_loss: 11.2379\n",
      "Epoch 17/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 12.7070 - val_loss: 9.8711\n",
      "Epoch 18/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.9872 - val_loss: 8.9049\n",
      "Epoch 19/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 10.4120 - val_loss: 7.8204\n",
      "Epoch 20/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.8677 - val_loss: 6.9690\n",
      "Epoch 21/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 9.0525 - val_loss: 6.2336\n",
      "Epoch 22/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 8.8133 - val_loss: 5.5064\n",
      "Epoch 23/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.4580 - val_loss: 4.9185\n",
      "Epoch 24/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 7.2369 - val_loss: 4.6383\n",
      "Epoch 25/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 6.6244 - val_loss: 3.9656\n",
      "Epoch 26/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.6100 - val_loss: 3.4754\n",
      "Epoch 27/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.6702 - val_loss: 3.1673\n",
      "Epoch 28/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 5.1278 - val_loss: 2.8969\n",
      "Epoch 29/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 4.7595 - val_loss: 2.6343\n",
      "Epoch 30/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.1688 - val_loss: 2.4873\n",
      "Epoch 31/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.9807 - val_loss: 2.3571\n",
      "Epoch 32/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 4.7277 - val_loss: 2.1501\n",
      "Epoch 33/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.8765 - val_loss: 1.9922\n",
      "Epoch 34/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.8623 - val_loss: 1.8952\n",
      "Epoch 35/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.8287 - val_loss: 1.7815\n",
      "Epoch 36/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 3.7027 - val_loss: 1.6990\n",
      "Epoch 37/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.2775 - val_loss: 1.6269\n",
      "Epoch 38/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.6009 - val_loss: 1.6278\n",
      "Epoch 39/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.3974 - val_loss: 1.5115\n",
      "Epoch 40/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.0315 - val_loss: 1.4478\n",
      "Epoch 41/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.0713 - val_loss: 1.4496\n",
      "Epoch 42/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.8737 - val_loss: 1.3629\n",
      "Epoch 43/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.2970 - val_loss: 1.3850\n",
      "Epoch 44/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.8465 - val_loss: 1.2698\n",
      "Epoch 45/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.4254 - val_loss: 1.2427\n",
      "Epoch 46/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.7743 - val_loss: 1.2366\n",
      "Epoch 47/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.7188 - val_loss: 1.1933\n",
      "Epoch 48/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 3.0521 - val_loss: 1.1682\n",
      "Epoch 49/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.9126 - val_loss: 1.0804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.6340 - val_loss: 1.0374\n",
      "Epoch 51/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.8330 - val_loss: 1.1593\n",
      "Epoch 52/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.8777 - val_loss: 1.0335\n",
      "Epoch 53/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.5038 - val_loss: 0.9701\n",
      "Epoch 54/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.6361 - val_loss: 0.9743\n",
      "Epoch 55/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.5210 - val_loss: 0.9031\n",
      "Epoch 56/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.8442 - val_loss: 0.9063\n",
      "Epoch 57/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.0631 - val_loss: 0.8709\n",
      "Epoch 58/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.4917 - val_loss: 0.9018\n",
      "Epoch 59/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.6552 - val_loss: 0.8535\n",
      "Epoch 60/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.4528 - val_loss: 0.9268\n",
      "Epoch 61/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.0125 - val_loss: 0.8066\n",
      "Epoch 62/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.7511 - val_loss: 0.8697\n",
      "Epoch 63/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.2334 - val_loss: 0.7539\n",
      "Epoch 64/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.2450 - val_loss: 0.8525\n",
      "Epoch 65/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.9053 - val_loss: 0.7359\n",
      "Epoch 66/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.3934 - val_loss: 0.7133\n",
      "Epoch 67/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.0881 - val_loss: 0.7476\n",
      "Epoch 68/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.0409 - val_loss: 0.6737\n",
      "Epoch 69/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.3054 - val_loss: 0.9181\n",
      "Epoch 70/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.0294 - val_loss: 0.6864\n",
      "Epoch 71/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.1798 - val_loss: 0.6434\n",
      "Epoch 72/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.2944 - val_loss: 0.6216\n",
      "Epoch 73/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.0938 - val_loss: 0.7472\n",
      "Epoch 74/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.4808 - val_loss: 0.6754\n",
      "Epoch 75/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.2343 - val_loss: 0.6041\n",
      "Epoch 76/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.2693 - val_loss: 0.8710\n",
      "Epoch 77/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.1829 - val_loss: 0.6076\n",
      "Epoch 78/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.1821 - val_loss: 0.6016\n",
      "Epoch 79/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.1274 - val_loss: 0.6537\n",
      "Epoch 80/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.0840 - val_loss: 0.7405\n",
      "Epoch 81/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7389 - val_loss: 0.5527\n",
      "Epoch 82/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.9994 - val_loss: 0.5683\n",
      "Epoch 83/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.3930 - val_loss: 0.5429\n",
      "Epoch 84/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6989 - val_loss: 0.5666\n",
      "Epoch 85/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.1307 - val_loss: 0.5416\n",
      "Epoch 86/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.2935 - val_loss: 0.4610\n",
      "Epoch 87/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.0050 - val_loss: 0.5007\n",
      "Epoch 88/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.0376 - val_loss: 0.5220\n",
      "Epoch 89/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8711 - val_loss: 0.5330\n",
      "Epoch 90/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8592 - val_loss: 0.5178\n",
      "Epoch 91/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.9332 - val_loss: 0.4172\n",
      "Epoch 92/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.9691 - val_loss: 0.4191\n",
      "Epoch 93/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.6023 - val_loss: 0.3995\n",
      "Epoch 94/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.0299 - val_loss: 0.7755\n",
      "Epoch 95/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.4332 - val_loss: 0.5672\n",
      "Epoch 96/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 2.0904 - val_loss: 0.4650\n",
      "Epoch 97/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.1295 - val_loss: 0.4581\n",
      "Epoch 98/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.0697 - val_loss: 0.4416\n",
      "Epoch 99/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7600 - val_loss: 0.3574\n",
      "Epoch 100/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8298 - val_loss: 0.3964\n",
      "Epoch 101/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.7970 - val_loss: 0.3487\n",
      "Epoch 102/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4263 - val_loss: 0.4582\n",
      "Epoch 103/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6707 - val_loss: 0.4871\n",
      "Epoch 104/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8858 - val_loss: 0.3526\n",
      "Epoch 105/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7660 - val_loss: 0.3925\n",
      "Epoch 106/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6790 - val_loss: 0.3464\n",
      "Epoch 107/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.6738 - val_loss: 0.2774\n",
      "Epoch 108/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6361 - val_loss: 0.2871\n",
      "Epoch 109/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8511 - val_loss: 0.2885\n",
      "Epoch 110/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8969 - val_loss: 0.3518\n",
      "Epoch 111/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.0066 - val_loss: 0.3558\n",
      "Epoch 112/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5605 - val_loss: 0.3520\n",
      "Epoch 113/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5662 - val_loss: 0.2903\n",
      "Epoch 114/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4229 - val_loss: 0.3769\n",
      "Epoch 115/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6270 - val_loss: 0.3424\n",
      "Epoch 116/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8740 - val_loss: 0.2908\n",
      "Epoch 117/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7361 - val_loss: 0.4877\n",
      "Epoch 118/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7125 - val_loss: 0.4415\n",
      "Epoch 119/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5195 - val_loss: 0.3659\n",
      "Epoch 120/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.9815 - val_loss: 0.3087\n",
      "Epoch 121/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.9028 - val_loss: 0.2352\n",
      "Epoch 122/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6139 - val_loss: 0.2483\n",
      "Epoch 123/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5341 - val_loss: 0.2316\n",
      "Epoch 124/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7723 - val_loss: 0.2637\n",
      "Epoch 125/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3521 - val_loss: 0.1850\n",
      "Epoch 126/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8652 - val_loss: 0.2949\n",
      "Epoch 127/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8027 - val_loss: 0.2221\n",
      "Epoch 128/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6530 - val_loss: 0.3534\n",
      "Epoch 129/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2426 - val_loss: 0.1792\n",
      "Epoch 130/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.9001 - val_loss: 0.3944\n",
      "Epoch 131/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7348 - val_loss: 0.3774\n",
      "Epoch 132/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3128 - val_loss: 0.2566\n",
      "Epoch 133/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.9850 - val_loss: 0.2473\n",
      "Epoch 134/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6008 - val_loss: 0.2252\n",
      "Epoch 135/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4319 - val_loss: 0.2299\n",
      "Epoch 136/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3035 - val_loss: 0.2112\n",
      "Epoch 137/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 2.1081 - val_loss: 0.3017\n",
      "Epoch 138/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.6478 - val_loss: 0.1979\n",
      "Epoch 139/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.7430 - val_loss: 0.2064\n",
      "Epoch 140/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4854 - val_loss: 0.2000\n",
      "Epoch 141/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4391 - val_loss: 0.4003\n",
      "Epoch 142/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7231 - val_loss: 0.1933\n",
      "Epoch 143/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.4308 - val_loss: 0.2273\n",
      "Epoch 144/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8466 - val_loss: 0.3325\n",
      "Epoch 145/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5507 - val_loss: 0.1611\n",
      "Epoch 146/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7425 - val_loss: 0.2458\n",
      "Epoch 147/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6005 - val_loss: 0.2124\n",
      "Epoch 148/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.6777 - val_loss: 0.1991\n",
      "Epoch 149/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7412 - val_loss: 0.2889\n",
      "Epoch 150/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.5775 - val_loss: 0.1410\n",
      "Epoch 151/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.1374 - val_loss: 0.2441\n",
      "Epoch 152/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5494 - val_loss: 0.1636\n",
      "Epoch 153/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3672 - val_loss: 0.1430\n",
      "Epoch 154/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.4952 - val_loss: 0.1876\n",
      "Epoch 155/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2217 - val_loss: 0.2340\n",
      "Epoch 156/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3733 - val_loss: 0.1516\n",
      "Epoch 157/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5380 - val_loss: 0.2361\n",
      "Epoch 158/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6608 - val_loss: 0.2444\n",
      "Epoch 159/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.2535 - val_loss: 0.1060\n",
      "Epoch 160/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2814 - val_loss: 0.1871\n",
      "Epoch 161/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.5391 - val_loss: 0.2364\n",
      "Epoch 162/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5977 - val_loss: 0.2455\n",
      "Epoch 163/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6367 - val_loss: 0.1453\n",
      "Epoch 164/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.4682 - val_loss: 0.1817\n",
      "Epoch 165/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2901 - val_loss: 0.2193\n",
      "Epoch 166/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4711 - val_loss: 0.1445\n",
      "Epoch 167/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3683 - val_loss: 0.1357\n",
      "Epoch 168/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3169 - val_loss: 0.1600\n",
      "Epoch 169/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.8721 - val_loss: 0.1504\n",
      "Epoch 170/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4402 - val_loss: 0.5113\n",
      "Epoch 171/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.5231 - val_loss: 0.2542\n",
      "Epoch 172/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3711 - val_loss: 0.1013\n",
      "Epoch 173/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4613 - val_loss: 0.1252\n",
      "Epoch 174/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4214 - val_loss: 0.1351\n",
      "Epoch 175/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.7071 - val_loss: 0.2786\n",
      "Epoch 176/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7506 - val_loss: 0.2442\n",
      "Epoch 177/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6489 - val_loss: 0.5254\n",
      "Epoch 178/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.9769 - val_loss: 0.2360\n",
      "Epoch 179/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.8030 - val_loss: 0.1263\n",
      "Epoch 180/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6114 - val_loss: 0.1171\n",
      "Epoch 181/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.3426 - val_loss: 0.2641\n",
      "Epoch 182/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.5199 - val_loss: 0.3129\n",
      "Epoch 183/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5648 - val_loss: 0.2321\n",
      "Epoch 184/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2739 - val_loss: 0.1273\n",
      "Epoch 185/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3887 - val_loss: 0.0841\n",
      "Epoch 186/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.1732 - val_loss: 0.0871\n",
      "Epoch 187/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.7529 - val_loss: 0.1685\n",
      "Epoch 188/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4096 - val_loss: 0.1194\n",
      "Epoch 189/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5296 - val_loss: 0.2861\n",
      "Epoch 190/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6221 - val_loss: 0.2031\n",
      "Epoch 191/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.4178 - val_loss: 0.0937\n",
      "Epoch 192/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.4410 - val_loss: 0.1840\n",
      "Epoch 193/200\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 1.4387 - val_loss: 0.2014\n",
      "Epoch 194/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3358 - val_loss: 0.1108\n",
      "Epoch 195/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2615 - val_loss: 0.1932\n",
      "Epoch 196/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5228 - val_loss: 0.1056\n",
      "Epoch 197/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.5455 - val_loss: 0.1078\n",
      "Epoch 198/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.6233 - val_loss: 0.0762\n",
      "Epoch 199/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.2234 - val_loss: 0.0756\n",
      "Epoch 200/200\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 1.3125 - val_loss: 0.1370\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Epoch 1/200\n",
      "26/26 [==============================] - 4s 33ms/step - loss: 80.6654 - val_loss: 59.8017\n",
      "Epoch 2/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 34.4674 - val_loss: 5.2289\n",
      "Epoch 3/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 5.8023 - val_loss: 5.2663\n",
      "Epoch 4/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 5.5601 - val_loss: 4.2220\n",
      "Epoch 5/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 5.2218 - val_loss: 3.8754\n",
      "Epoch 6/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 5.0680 - val_loss: 3.2884\n",
      "Epoch 7/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 4.2232 - val_loss: 2.5304\n",
      "Epoch 8/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 3.1714 - val_loss: 1.6721\n",
      "Epoch 9/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 2.4198 - val_loss: 1.0672\n",
      "Epoch 10/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.9251 - val_loss: 0.7659\n",
      "Epoch 11/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.7389 - val_loss: 0.6636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.6672 - val_loss: 0.6131\n",
      "Epoch 13/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.6758 - val_loss: 0.5631\n",
      "Epoch 14/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.6353 - val_loss: 0.5036\n",
      "Epoch 15/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.4949 - val_loss: 0.4646\n",
      "Epoch 16/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.6010 - val_loss: 0.4320\n",
      "Epoch 17/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.2273 - val_loss: 0.3954\n",
      "Epoch 18/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 1.4024 - val_loss: 0.3936\n",
      "Epoch 19/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.2735 - val_loss: 0.3592\n",
      "Epoch 20/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.2899 - val_loss: 0.3268\n",
      "Epoch 21/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.3248 - val_loss: 0.2959\n",
      "Epoch 22/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.1734 - val_loss: 0.3226\n",
      "Epoch 23/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.2757 - val_loss: 0.2567\n",
      "Epoch 24/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.2098 - val_loss: 0.2388\n",
      "Epoch 25/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.2856 - val_loss: 0.2189\n",
      "Epoch 26/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.0816 - val_loss: 0.2106\n",
      "Epoch 27/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.0413 - val_loss: 0.2243\n",
      "Epoch 28/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.0450 - val_loss: 0.1827\n",
      "Epoch 29/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.1157 - val_loss: 0.1877\n",
      "Epoch 30/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.9794 - val_loss: 0.1846\n",
      "Epoch 31/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.0619 - val_loss: 0.1779\n",
      "Epoch 32/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.0646 - val_loss: 0.1815\n",
      "Epoch 33/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.0734 - val_loss: 0.1403\n",
      "Epoch 34/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 1.0177 - val_loss: 0.1284\n",
      "Epoch 35/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.8479 - val_loss: 0.1090\n",
      "Epoch 36/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.8728 - val_loss: 0.1234\n",
      "Epoch 37/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.9176 - val_loss: 0.1471\n",
      "Epoch 38/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.8458 - val_loss: 0.0901\n",
      "Epoch 39/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.9072 - val_loss: 0.0984\n",
      "Epoch 40/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.8189 - val_loss: 0.1003\n",
      "Epoch 41/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.9205 - val_loss: 0.0772\n",
      "Epoch 42/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.8521 - val_loss: 0.0801\n",
      "Epoch 43/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.8716 - val_loss: 0.0869\n",
      "Epoch 44/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7686 - val_loss: 0.0599\n",
      "Epoch 45/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8255 - val_loss: 0.0566\n",
      "Epoch 46/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7609 - val_loss: 0.0645\n",
      "Epoch 47/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.8973 - val_loss: 0.0647\n",
      "Epoch 48/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7935 - val_loss: 0.0814\n",
      "Epoch 49/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7457 - val_loss: 0.0478\n",
      "Epoch 50/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.7489 - val_loss: 0.0572\n",
      "Epoch 51/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6725 - val_loss: 0.0411\n",
      "Epoch 52/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6999 - val_loss: 0.0660\n",
      "Epoch 53/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.7001 - val_loss: 0.0451\n",
      "Epoch 54/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.7193 - val_loss: 0.0476\n",
      "Epoch 55/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6732 - val_loss: 0.0531\n",
      "Epoch 56/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6999 - val_loss: 0.0396\n",
      "Epoch 57/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.7223 - val_loss: 0.0424\n",
      "Epoch 58/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6847 - val_loss: 0.0373\n",
      "Epoch 59/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.7551 - val_loss: 0.0366\n",
      "Epoch 60/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6413 - val_loss: 0.0620\n",
      "Epoch 61/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6906 - val_loss: 0.0414\n",
      "Epoch 62/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6603 - val_loss: 0.0310\n",
      "Epoch 63/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6903 - val_loss: 0.0755\n",
      "Epoch 64/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.7187 - val_loss: 0.0493\n",
      "Epoch 65/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6983 - val_loss: 0.0276\n",
      "Epoch 66/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5951 - val_loss: 0.0340\n",
      "Epoch 67/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6096 - val_loss: 0.0230\n",
      "Epoch 68/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.7228 - val_loss: 0.0257\n",
      "Epoch 69/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6869 - val_loss: 0.0293\n",
      "Epoch 70/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6840 - val_loss: 0.0215\n",
      "Epoch 71/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6240 - val_loss: 0.0329\n",
      "Epoch 72/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6493 - val_loss: 0.0895\n",
      "Epoch 73/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6435 - val_loss: 0.0332\n",
      "Epoch 74/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6542 - val_loss: 0.0400\n",
      "Epoch 75/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6251 - val_loss: 0.0197\n",
      "Epoch 76/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6315 - val_loss: 0.0279\n",
      "Epoch 77/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6737 - val_loss: 0.0280\n",
      "Epoch 78/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6036 - val_loss: 0.0246\n",
      "Epoch 79/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5562 - val_loss: 0.0420\n",
      "Epoch 80/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6270 - val_loss: 0.0230\n",
      "Epoch 81/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6441 - val_loss: 0.0251\n",
      "Epoch 82/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6593 - val_loss: 0.0183\n",
      "Epoch 83/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5969 - val_loss: 0.0942\n",
      "Epoch 84/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5711 - val_loss: 0.0225\n",
      "Epoch 85/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6197 - val_loss: 0.0298\n",
      "Epoch 86/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6200 - val_loss: 0.0292\n",
      "Epoch 87/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6088 - val_loss: 0.0214\n",
      "Epoch 88/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6124 - val_loss: 0.0253\n",
      "Epoch 89/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6448 - val_loss: 0.0329\n",
      "Epoch 90/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5965 - val_loss: 0.0620\n",
      "Epoch 91/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5778 - val_loss: 0.0400\n",
      "Epoch 92/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6549 - val_loss: 0.0423\n",
      "Epoch 93/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5500 - val_loss: 0.0411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5649 - val_loss: 0.0189\n",
      "Epoch 95/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5860 - val_loss: 0.0336\n",
      "Epoch 96/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5414 - val_loss: 0.0343\n",
      "Epoch 97/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6243 - val_loss: 0.0204\n",
      "Epoch 98/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5933 - val_loss: 0.0522\n",
      "Epoch 99/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5773 - val_loss: 0.0295\n",
      "Epoch 100/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5421 - val_loss: 0.0195\n",
      "Epoch 101/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5265 - val_loss: 0.0192\n",
      "Epoch 102/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5605 - val_loss: 0.0427\n",
      "Epoch 103/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5369 - val_loss: 0.0332\n",
      "Epoch 104/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6106 - val_loss: 0.0211\n",
      "Epoch 105/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5220 - val_loss: 0.0506\n",
      "Epoch 106/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5520 - val_loss: 0.0278\n",
      "Epoch 107/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5888 - val_loss: 0.0319\n",
      "Epoch 108/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5279 - val_loss: 0.0198\n",
      "Epoch 109/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5547 - val_loss: 0.0154\n",
      "Epoch 110/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5703 - val_loss: 0.0231\n",
      "Epoch 111/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5908 - val_loss: 0.0376\n",
      "Epoch 112/200\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.5744 - val_loss: 0.0201\n",
      "Epoch 113/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5599 - val_loss: 0.0602\n",
      "Epoch 114/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5083 - val_loss: 0.0208\n",
      "Epoch 115/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5247 - val_loss: 0.0188\n",
      "Epoch 116/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6001 - val_loss: 0.0178\n",
      "Epoch 117/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5438 - val_loss: 0.0179\n",
      "Epoch 118/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5155 - val_loss: 0.0154\n",
      "Epoch 119/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5050 - val_loss: 0.0206\n",
      "Epoch 120/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5529 - val_loss: 0.0191\n",
      "Epoch 121/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6081 - val_loss: 0.0338\n",
      "Epoch 122/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5856 - val_loss: 0.0192\n",
      "Epoch 123/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5588 - val_loss: 0.0217\n",
      "Epoch 124/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5649 - val_loss: 0.0350\n",
      "Epoch 125/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5118 - val_loss: 0.0224\n",
      "Epoch 126/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6036 - val_loss: 0.0450\n",
      "Epoch 127/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6055 - val_loss: 0.0582\n",
      "Epoch 128/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5555 - val_loss: 0.0371\n",
      "Epoch 129/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4871 - val_loss: 0.0344\n",
      "Epoch 130/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5140 - val_loss: 0.0180\n",
      "Epoch 131/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5195 - val_loss: 0.0365\n",
      "Epoch 132/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4978 - val_loss: 0.0261\n",
      "Epoch 133/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5174 - val_loss: 0.0161\n",
      "Epoch 134/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5624 - val_loss: 0.0158\n",
      "Epoch 135/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5803 - val_loss: 0.0131\n",
      "Epoch 136/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5777 - val_loss: 0.0532\n",
      "Epoch 137/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5012 - val_loss: 0.0238\n",
      "Epoch 138/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4542 - val_loss: 0.0280\n",
      "Epoch 139/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5345 - val_loss: 0.0173\n",
      "Epoch 140/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5648 - val_loss: 0.0225\n",
      "Epoch 141/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5639 - val_loss: 0.0335\n",
      "Epoch 142/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4630 - val_loss: 0.0191\n",
      "Epoch 143/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5235 - val_loss: 0.0155\n",
      "Epoch 144/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4515 - val_loss: 0.0377\n",
      "Epoch 145/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4943 - val_loss: 0.0311\n",
      "Epoch 146/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5200 - val_loss: 0.0214\n",
      "Epoch 147/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5051 - val_loss: 0.0443\n",
      "Epoch 148/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5007 - val_loss: 0.0222\n",
      "Epoch 149/200\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.5297 - val_loss: 0.0241\n",
      "Epoch 150/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5564 - val_loss: 0.0482\n",
      "Epoch 151/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4932 - val_loss: 0.0157\n",
      "Epoch 152/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5494 - val_loss: 0.0470\n",
      "Epoch 153/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4863 - val_loss: 0.0363\n",
      "Epoch 154/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4949 - val_loss: 0.0261\n",
      "Epoch 155/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5117 - val_loss: 0.0148\n",
      "Epoch 156/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5405 - val_loss: 0.0213\n",
      "Epoch 157/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4939 - val_loss: 0.0430\n",
      "Epoch 158/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5307 - val_loss: 0.0356\n",
      "Epoch 159/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5059 - val_loss: 0.0186\n",
      "Epoch 160/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4800 - val_loss: 0.0189\n",
      "Epoch 161/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5899 - val_loss: 0.0137\n",
      "Epoch 162/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5547 - val_loss: 0.0429\n",
      "Epoch 163/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4803 - val_loss: 0.0136\n",
      "Epoch 164/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4676 - val_loss: 0.0218\n",
      "Epoch 165/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4879 - val_loss: 0.0131\n",
      "Epoch 166/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - val_loss: 0.0431\n",
      "Epoch 167/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5653 - val_loss: 0.0120\n",
      "Epoch 168/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4974 - val_loss: 0.0289\n",
      "Epoch 169/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5240 - val_loss: 0.0151\n",
      "Epoch 170/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4768 - val_loss: 0.0178\n",
      "Epoch 171/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4725 - val_loss: 0.0739\n",
      "Epoch 172/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5202 - val_loss: 0.0154\n",
      "Epoch 173/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4731 - val_loss: 0.0298\n",
      "Epoch 174/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4839 - val_loss: 0.0122\n",
      "Epoch 175/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4898 - val_loss: 0.0124\n",
      "Epoch 176/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4710 - val_loss: 0.0362\n",
      "Epoch 177/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4720 - val_loss: 0.0111\n",
      "Epoch 178/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5153 - val_loss: 0.0152\n",
      "Epoch 179/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4667 - val_loss: 0.0168\n",
      "Epoch 180/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5042 - val_loss: 0.0579\n",
      "Epoch 181/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5158 - val_loss: 0.0207\n",
      "Epoch 182/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5337 - val_loss: 0.0237\n",
      "Epoch 183/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4903 - val_loss: 0.0124\n",
      "Epoch 184/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4689 - val_loss: 0.0128\n",
      "Epoch 185/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4688 - val_loss: 0.0295\n",
      "Epoch 186/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4372 - val_loss: 0.0378\n",
      "Epoch 187/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5222 - val_loss: 0.0133\n",
      "Epoch 188/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4377 - val_loss: 0.0297\n",
      "Epoch 189/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4999 - val_loss: 0.0154\n",
      "Epoch 190/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4607 - val_loss: 0.0117\n",
      "Epoch 191/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4803 - val_loss: 0.0218\n",
      "Epoch 192/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4738 - val_loss: 0.0142\n",
      "Epoch 193/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4496 - val_loss: 0.0183\n",
      "Epoch 194/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4986 - val_loss: 0.0334\n",
      "Epoch 195/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4883 - val_loss: 0.0517\n",
      "Epoch 196/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5119 - val_loss: 0.0118\n",
      "Epoch 197/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4710 - val_loss: 0.0124\n",
      "Epoch 198/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4766 - val_loss: 0.0306\n",
      "Epoch 199/200\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5193 - val_loss: 0.0481\n",
      "Epoch 200/200\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4304 - val_loss: 0.0397\n",
      "7/7 [==============================] - 1s 2ms/step\n",
      "Evaluation results for SAVE:\n",
      "Mean Squared Error: 0.18647932831422478\n",
      "Mean Absolute Error: 0.3098508967689021\n",
      "R-squared: 0.996533096181295\n",
      "\n",
      "Evaluation results for CLNE:\n",
      "Mean Squared Error: 0.02508457907610289\n",
      "Mean Absolute Error: 0.0894041488419718\n",
      "R-squared: 0.9974899815727353\n",
      "\n",
      "Evaluation results for LAZR:\n",
      "Mean Squared Error: 0.1364125480457251\n",
      "Mean Absolute Error: 0.2255986991027991\n",
      "R-squared: 0.9977785124305983\n",
      "\n",
      "Evaluation results for AMWL:\n",
      "Mean Squared Error: 0.13703454301917686\n",
      "Mean Absolute Error: 0.264073325926999\n",
      "R-squared: 0.9984964104738414\n",
      "\n",
      "Evaluation results for GEO:\n",
      "Mean Squared Error: 0.03968989704867796\n",
      "Mean Absolute Error: 0.171506948138944\n",
      "R-squared: 0.9931744671571681\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('dataset.csv').dropna()\n",
    "\n",
    "# List of ticker symbols\n",
    "tickers = df['level_0'].unique()\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "evaluation_results_previousday = {}\n",
    "\n",
    "# Loop through each ticker\n",
    "for ticker in tickers:\n",
    "    # Filter data for the current ticker\n",
    "    ticker_df = df[df['level_0'] == ticker]\n",
    "    \n",
    "    # Extract features and target variable\n",
    "    X = ticker_df[['Open', 'High', 'Low', 'Close', 'Volume','Daily Returns','Volatility','RSI', '%K', '%D','Movement','Sentiment Score']].values\n",
    "    y = ticker_df['PreviousDayClose'].values\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Reshape input data for GRU (samples, time steps, features)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "    \n",
    "    # Define the GRU model\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(units=50))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1, validation_data=(X_test, y_test))\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    # Store evaluation results\n",
    "    evaluation_results_previousday[ticker] = {'Mean Squared Error': mse, 'Mean Absolute Error': mae, 'R-squared': r2}\n",
    "\n",
    "# Display evaluation results\n",
    "for ticker, results in evaluation_results_previousday.items():\n",
    "    print(f'Evaluation results for {ticker}:')\n",
    "    for metric, value in results.items():\n",
    "        print(f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, predictions, color='red', alpha=0.5, label='Actual')  # Actual values in blue\n",
    "plt.scatter(y_test, predictions, color='blue', alpha=0.5, label='Predicted')  # Predicted values in red\n",
    "plt.title('Actual vs. Predicted Stock Prices')\n",
    "plt.xlabel('Actual Previous Day Close Price')\n",
    "plt.ylabel('Predicted Previous Day Close Price')\n",
    "plt.legend()  # Show legend to differentiate between actual and predicted\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a4a3bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Score Weight: [-0.5084823]\n"
     ]
    }
   ],
   "source": [
    "# Extract the sentiment score weights from the dense layer\n",
    "sentiment_score_weights = model.layers[-1].get_weights()[0][-1]\n",
    "\n",
    "# Interpret the sentiment score weights\n",
    "print(\"Sentiment Score Weight:\", sentiment_score_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07b8e0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Aggregate stock prices based on sentiment scores\n",
    "sentiment_price_avg = ticker_df.groupby('Sentiment Score')['PreviousDayClose'].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the line plot\n",
    "plt.plot(sentiment_price_avg.index, sentiment_price_avg.values, marker='o', linestyle='-')\n",
    "plt.title('Average Stock Price vs. Sentiment Score')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Average Previous Day Close Price')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c0ce3",
   "metadata": {},
   "source": [
    "GRU Model for current close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef1473d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "19/19 [==============================] - 4s 40ms/step - loss: 548.8023 - val_loss: 477.4264\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 486.3529 - val_loss: 362.0395\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 318.0382 - val_loss: 196.4858\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 199.8349 - val_loss: 133.1352\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 151.6988 - val_loss: 106.3432\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 128.5123 - val_loss: 89.2220\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 114.2193 - val_loss: 76.4453\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 97.6304 - val_loss: 66.9403\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 89.1907 - val_loss: 59.5948\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 81.3519 - val_loss: 54.0307\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 74.7509 - val_loss: 49.9933\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 71.2029 - val_loss: 46.8526\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 68.1549 - val_loss: 44.6497\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 64.4545 - val_loss: 43.1635\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 61.7255 - val_loss: 42.0713\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 62.9002 - val_loss: 41.3035\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 60.3121 - val_loss: 40.8169\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 60.1452 - val_loss: 40.5017\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 59.4802 - val_loss: 40.3457\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 59.2096 - val_loss: 40.2560\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 60.0116 - val_loss: 40.1953\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 58.6864 - val_loss: 40.1556\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 56.2827 - val_loss: 40.0641\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 55.1843 - val_loss: 39.9707\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 56.8552 - val_loss: 39.7993\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 57.7726 - val_loss: 39.4188\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 56.9043 - val_loss: 38.5711\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 55.5877 - val_loss: 36.6923\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 51.5424 - val_loss: 32.0000\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 47.2630 - val_loss: 26.2248\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 40.2747 - val_loss: 22.8383\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 36.6035 - val_loss: 20.0357\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 35.8543 - val_loss: 18.5151\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 32.0537 - val_loss: 16.9076\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 29.0971 - val_loss: 15.6253\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 29.1600 - val_loss: 14.3516\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 26.2619 - val_loss: 13.2174\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 25.5229 - val_loss: 12.4215\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 25.3828 - val_loss: 11.6506\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 24.1320 - val_loss: 11.1203\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 21.3771 - val_loss: 10.1969\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 18.6913 - val_loss: 10.0516\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 18.5819 - val_loss: 8.9440\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 10ms/step - loss: 18.6696 - val_loss: 8.3781\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 17.5176 - val_loss: 8.4644\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 16.3578 - val_loss: 7.7429\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 17.2412 - val_loss: 7.1418\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 16.0966 - val_loss: 6.8620\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.7468 - val_loss: 6.6391\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.5237 - val_loss: 6.0191\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 15.2441 - val_loss: 5.6954\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 13.2793 - val_loss: 5.6788\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 13.1095 - val_loss: 5.0469\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 13.4932 - val_loss: 5.0030\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 11.2943 - val_loss: 5.1080\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 11.9486 - val_loss: 4.2921\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 11.0090 - val_loss: 4.0705\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 10.6524 - val_loss: 3.8972\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 10.5011 - val_loss: 3.7291\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 11.3072 - val_loss: 3.4476\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 11.2174 - val_loss: 3.4665\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.5245 - val_loss: 3.1577\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.0534 - val_loss: 2.9529\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.7614 - val_loss: 3.0715\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.6525 - val_loss: 2.6834\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 9.4604 - val_loss: 2.5454\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.8836 - val_loss: 2.4160\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7.9735 - val_loss: 2.2946\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.2955 - val_loss: 2.2775\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 7.9285 - val_loss: 2.0031\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 8.0054 - val_loss: 1.9645\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7.3822 - val_loss: 1.8753\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 6.8902 - val_loss: 1.8845\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 6.3399 - val_loss: 1.7548\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 7.6223 - val_loss: 1.5875\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 7.5768 - val_loss: 1.4666\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6.8184 - val_loss: 1.4813\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 6.2133 - val_loss: 1.4111\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 6.7385 - val_loss: 1.2807\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 6.0507 - val_loss: 1.2303\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6.0915 - val_loss: 1.1753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.8506 - val_loss: 1.1229\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 6.9284 - val_loss: 1.0020\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.9346 - val_loss: 1.0623\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.8175 - val_loss: 0.9823\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.9716 - val_loss: 1.0101\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.8554 - val_loss: 0.8835\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.6901 - val_loss: 1.2412\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.4227 - val_loss: 1.5995\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 6.1627 - val_loss: 0.9250\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.7204 - val_loss: 0.8767\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 5.2856 - val_loss: 0.7077\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.1927 - val_loss: 1.0444\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.1737 - val_loss: 0.7892\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4.4716 - val_loss: 0.8133\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4.8790 - val_loss: 0.7197\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 5.1726 - val_loss: 0.6169\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.4195 - val_loss: 0.6105\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.6667 - val_loss: 0.7326\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.1972 - val_loss: 0.6227\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.2317 - val_loss: 0.6113\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.3876 - val_loss: 0.6870\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.0833 - val_loss: 0.5517\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.5795 - val_loss: 0.5590\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.4720 - val_loss: 0.5553\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.8939 - val_loss: 0.5451\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.1341 - val_loss: 0.4390\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.6143 - val_loss: 0.5728\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.3002 - val_loss: 0.5430\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4.4765 - val_loss: 0.4559\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.7303 - val_loss: 0.4305\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.0081 - val_loss: 0.4047\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.1836 - val_loss: 0.4559\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.2632 - val_loss: 0.4762\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4.8388 - val_loss: 0.4003\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.7746 - val_loss: 0.6090\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.2935 - val_loss: 0.3724\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 4.2464 - val_loss: 0.4771\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.5365 - val_loss: 0.3882\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.5067 - val_loss: 0.3300\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.1020 - val_loss: 0.3866\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.9816 - val_loss: 0.3573\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.2347 - val_loss: 0.4885\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.7559 - val_loss: 0.4187\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.9181 - val_loss: 0.3281\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.1821 - val_loss: 0.2982\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.7731 - val_loss: 0.2995\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.2377 - val_loss: 0.5326\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.3870 - val_loss: 0.4202\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.7814 - val_loss: 0.4293\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.5833 - val_loss: 0.4262\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.5264 - val_loss: 0.3399\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 4.1729 - val_loss: 0.2817\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3.8937 - val_loss: 0.2528\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 7ms/step - loss: 3.8616 - val_loss: 0.2767\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.9573 - val_loss: 0.2777\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.9708 - val_loss: 0.2784\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.3611 - val_loss: 0.3376\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.5978 - val_loss: 0.2575\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3.7244 - val_loss: 0.2346\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.2306 - val_loss: 0.2556\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.5923 - val_loss: 0.2273\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.6707 - val_loss: 0.2221\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.7624 - val_loss: 1.1033\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.0397 - val_loss: 0.2818\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.1217 - val_loss: 0.2830\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.2322 - val_loss: 0.2944\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.5160 - val_loss: 0.2098\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.3913 - val_loss: 0.1936\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.6054 - val_loss: 0.2312\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.1743 - val_loss: 0.6746\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.7680 - val_loss: 0.2108\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.7236 - val_loss: 0.2054\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.5237 - val_loss: 0.2537\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.0195 - val_loss: 0.1776\n",
      "Epoch 156/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.6115 - val_loss: 0.1990\n",
      "Epoch 157/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.6815 - val_loss: 0.1699\n",
      "Epoch 158/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 3.3649 - val_loss: 0.2961\n",
      "Epoch 159/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.5934 - val_loss: 0.1727\n",
      "Epoch 160/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.7972 - val_loss: 0.1747\n",
      "Epoch 161/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.6463 - val_loss: 0.1788\n",
      "Epoch 162/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.5553 - val_loss: 0.1458\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 5ms/step - loss: 4.1786 - val_loss: 0.2295\n",
      "Epoch 164/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.1561 - val_loss: 0.2196\n",
      "Epoch 165/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.7455 - val_loss: 0.3129\n",
      "Epoch 166/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.8035 - val_loss: 0.2129\n",
      "Epoch 167/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.0401 - val_loss: 0.1749\n",
      "Epoch 168/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.3803 - val_loss: 0.3563\n",
      "Epoch 169/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.6490 - val_loss: 0.2383\n",
      "Epoch 170/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.7852 - val_loss: 0.1691\n",
      "Epoch 171/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.4610 - val_loss: 0.1426\n",
      "Epoch 172/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.3251 - val_loss: 0.1402\n",
      "Epoch 173/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.4895 - val_loss: 0.2264\n",
      "Epoch 174/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.7750 - val_loss: 0.1457\n",
      "Epoch 175/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.5491 - val_loss: 0.1782\n",
      "Epoch 176/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.4630 - val_loss: 0.2227\n",
      "Epoch 177/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.0892 - val_loss: 0.2086\n",
      "Epoch 178/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.9934 - val_loss: 0.1438\n",
      "Epoch 179/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.5741 - val_loss: 0.1722\n",
      "Epoch 180/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.2386 - val_loss: 0.1912\n",
      "Epoch 181/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.7335 - val_loss: 0.2750\n",
      "Epoch 182/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.3558 - val_loss: 0.1488\n",
      "Epoch 183/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.1457 - val_loss: 0.2048\n",
      "Epoch 184/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.8955 - val_loss: 0.4093\n",
      "Epoch 185/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.4329 - val_loss: 0.2785\n",
      "Epoch 186/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.1740 - val_loss: 0.1503\n",
      "Epoch 187/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.3408 - val_loss: 0.1523\n",
      "Epoch 188/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.2084 - val_loss: 0.2593\n",
      "Epoch 189/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.3174 - val_loss: 0.1876\n",
      "Epoch 190/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.0129 - val_loss: 0.1422\n",
      "Epoch 191/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.2775 - val_loss: 0.2222\n",
      "Epoch 192/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.0814 - val_loss: 0.2334\n",
      "Epoch 193/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.0313 - val_loss: 0.1271\n",
      "Epoch 194/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.3463 - val_loss: 0.1517\n",
      "Epoch 195/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.4522 - val_loss: 0.1507\n",
      "Epoch 196/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.3848 - val_loss: 0.1348\n",
      "Epoch 197/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.3913 - val_loss: 0.1217\n",
      "Epoch 198/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.3299 - val_loss: 0.2125\n",
      "Epoch 199/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.3815 - val_loss: 0.1053\n",
      "Epoch 200/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.4643 - val_loss: 0.3422\n",
      "7/7 [==============================] - 1s 2ms/step\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 5s 44ms/step - loss: 37.3197 - val_loss: 36.2226\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 24.9746 - val_loss: 14.6509\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 8.2969 - val_loss: 7.8566\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 6.4195 - val_loss: 6.5672\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 5.4411 - val_loss: 5.4248\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 4.5215 - val_loss: 3.9582\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 3.0407 - val_loss: 2.4333\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 2.0131 - val_loss: 1.2880\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.3166 - val_loss: 0.8894\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.1148 - val_loss: 0.7488\n",
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9397 - val_loss: 0.6830\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8175 - val_loss: 0.6327\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8361 - val_loss: 0.5913\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.8269 - val_loss: 0.5593\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8102 - val_loss: 0.5222\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7860 - val_loss: 0.5004\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.7978 - val_loss: 0.4985\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7875 - val_loss: 0.4556\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6926 - val_loss: 0.4495\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6864 - val_loss: 0.4186\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7648 - val_loss: 0.3969\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6577 - val_loss: 0.3856\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6700 - val_loss: 0.3775\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6716 - val_loss: 0.3527\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6669 - val_loss: 0.3365\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7402 - val_loss: 0.3319\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6059 - val_loss: 0.3091\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6923 - val_loss: 0.3229\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6389 - val_loss: 0.2884\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5748 - val_loss: 0.2816\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5455 - val_loss: 0.2718\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5517 - val_loss: 0.2694\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5736 - val_loss: 0.2619\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5507 - val_loss: 0.2445\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5270 - val_loss: 0.2719\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5515 - val_loss: 0.2494\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.6137 - val_loss: 0.2452\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5759 - val_loss: 0.2228\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4871 - val_loss: 0.2177\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4820 - val_loss: 0.2121\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5080 - val_loss: 0.2043\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4873 - val_loss: 0.2056\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4696 - val_loss: 0.2171\n",
      "Epoch 44/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4764 - val_loss: 0.1940\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5367 - val_loss: 0.1840\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4100 - val_loss: 0.1775\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4523 - val_loss: 0.2048\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4241 - val_loss: 0.1916\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4541 - val_loss: 0.1807\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5349 - val_loss: 0.1749\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4816 - val_loss: 0.1634\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4389 - val_loss: 0.1658\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5000 - val_loss: 0.1597\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5199 - val_loss: 0.1541\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5534 - val_loss: 0.2936\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4557 - val_loss: 0.1924\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4461 - val_loss: 0.2558\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 8ms/step - loss: 0.4417 - val_loss: 0.1565\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4121 - val_loss: 0.1493\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4288 - val_loss: 0.1443\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3965 - val_loss: 0.1359\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4114 - val_loss: 0.1421\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3900 - val_loss: 0.1424\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4244 - val_loss: 0.1591\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4052 - val_loss: 0.1374\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3578 - val_loss: 0.1566\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4109 - val_loss: 0.1548\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4487 - val_loss: 0.1289\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3942 - val_loss: 0.1350\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3774 - val_loss: 0.1393\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4234 - val_loss: 0.1226\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4044 - val_loss: 0.1559\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4145 - val_loss: 0.1240\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4000 - val_loss: 0.1220\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3696 - val_loss: 0.1195\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3649 - val_loss: 0.1240\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4010 - val_loss: 0.1273\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3309 - val_loss: 0.1255\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3805 - val_loss: 0.1101\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4264 - val_loss: 0.1234\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3905 - val_loss: 0.1189\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3858 - val_loss: 0.1317\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3636 - val_loss: 0.1061\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3796 - val_loss: 0.1071\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3812 - val_loss: 0.1050\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3787 - val_loss: 0.1018\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3609 - val_loss: 0.1066\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3344 - val_loss: 0.0976\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3436 - val_loss: 0.1331\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3652 - val_loss: 0.1476\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3240 - val_loss: 0.1018\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3185 - val_loss: 0.0925\n",
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4421 - val_loss: 0.0985\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4304 - val_loss: 0.1124\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3454 - val_loss: 0.0968\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3302 - val_loss: 0.0901\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3571 - val_loss: 0.0995\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3360 - val_loss: 0.0959\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3544 - val_loss: 0.0923\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3527 - val_loss: 0.0837\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3311 - val_loss: 0.0806\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3711 - val_loss: 0.1209\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3269 - val_loss: 0.0856\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.4032 - val_loss: 0.1206\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3056 - val_loss: 0.0870\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2917 - val_loss: 0.0828\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3041 - val_loss: 0.0825\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3483 - val_loss: 0.1012\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2900 - val_loss: 0.0879\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2794 - val_loss: 0.0900\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3225 - val_loss: 0.0937\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3261 - val_loss: 0.0737\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3820 - val_loss: 0.0702\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3492 - val_loss: 0.0942\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3284 - val_loss: 0.0716\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3206 - val_loss: 0.0785\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3261 - val_loss: 0.0779\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2818 - val_loss: 0.0856\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3139 - val_loss: 0.0675\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3152 - val_loss: 0.0749\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3055 - val_loss: 0.0679\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3269 - val_loss: 0.0776\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.3065 - val_loss: 0.0865\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2754 - val_loss: 0.0801\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2748 - val_loss: 0.0782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3042 - val_loss: 0.0943\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3355 - val_loss: 0.0649\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3473 - val_loss: 0.0773\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.2740 - val_loss: 0.0643\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3851 - val_loss: 0.0857\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3235 - val_loss: 0.0869\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2675 - val_loss: 0.0663\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2777 - val_loss: 0.0662\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3180 - val_loss: 0.0768\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2846 - val_loss: 0.0617\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2779 - val_loss: 0.0613\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2925 - val_loss: 0.1069\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3722 - val_loss: 0.0585\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3179 - val_loss: 0.0564\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3142 - val_loss: 0.0799\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3014 - val_loss: 0.0700\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2821 - val_loss: 0.0723\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3530 - val_loss: 0.0700\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3294 - val_loss: 0.0772\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2864 - val_loss: 0.0647\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3627 - val_loss: 0.0749\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2925 - val_loss: 0.0742\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2749 - val_loss: 0.0772\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2747 - val_loss: 0.0665\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3145 - val_loss: 0.0655\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2566 - val_loss: 0.0590\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2727 - val_loss: 0.0534\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2727 - val_loss: 0.0814\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3032 - val_loss: 0.0874\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3083 - val_loss: 0.0855\n",
      "Epoch 156/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2907 - val_loss: 0.0596\n",
      "Epoch 157/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3109 - val_loss: 0.0634\n",
      "Epoch 158/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2819 - val_loss: 0.0662\n",
      "Epoch 159/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2791 - val_loss: 0.1012\n",
      "Epoch 160/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2871 - val_loss: 0.0820\n",
      "Epoch 161/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2602 - val_loss: 0.0762\n",
      "Epoch 162/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3174 - val_loss: 0.0600\n",
      "Epoch 163/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3105 - val_loss: 0.0876\n",
      "Epoch 164/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2842 - val_loss: 0.0659\n",
      "Epoch 165/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3105 - val_loss: 0.0713\n",
      "Epoch 166/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2772 - val_loss: 0.0495\n",
      "Epoch 167/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2427 - val_loss: 0.0588\n",
      "Epoch 168/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2956 - val_loss: 0.0648\n",
      "Epoch 169/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2911 - val_loss: 0.0759\n",
      "Epoch 170/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3161 - val_loss: 0.0663\n",
      "Epoch 171/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2922 - val_loss: 0.0762\n",
      "Epoch 172/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2793 - val_loss: 0.0576\n",
      "Epoch 173/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3087 - val_loss: 0.0465\n",
      "Epoch 174/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2876 - val_loss: 0.0503\n",
      "Epoch 175/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2709 - val_loss: 0.0495\n",
      "Epoch 176/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3005 - val_loss: 0.0494\n",
      "Epoch 177/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2381 - val_loss: 0.0477\n",
      "Epoch 178/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2523 - val_loss: 0.0739\n",
      "Epoch 179/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3057 - val_loss: 0.0715\n",
      "Epoch 180/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2614 - val_loss: 0.0535\n",
      "Epoch 181/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2669 - val_loss: 0.0517\n",
      "Epoch 182/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2458 - val_loss: 0.0722\n",
      "Epoch 183/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2747 - val_loss: 0.0578\n",
      "Epoch 184/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2756 - val_loss: 0.0528\n",
      "Epoch 185/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2901 - val_loss: 0.0693\n",
      "Epoch 186/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3522 - val_loss: 0.0615\n",
      "Epoch 187/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.3271 - val_loss: 0.0552\n",
      "Epoch 188/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2837 - val_loss: 0.0443\n",
      "Epoch 189/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.3071 - val_loss: 0.0460\n",
      "Epoch 190/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2635 - val_loss: 0.0442\n",
      "Epoch 191/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2869 - val_loss: 0.0448\n",
      "Epoch 192/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2518 - val_loss: 0.0537\n",
      "Epoch 193/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2621 - val_loss: 0.0422\n",
      "Epoch 194/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2513 - val_loss: 0.0522\n",
      "Epoch 195/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2370 - val_loss: 0.0523\n",
      "Epoch 196/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2243 - val_loss: 0.0468\n",
      "Epoch 197/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2263 - val_loss: 0.0538\n",
      "Epoch 198/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.2780 - val_loss: 0.0533\n",
      "Epoch 199/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2885 - val_loss: 0.0467\n",
      "Epoch 200/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.2783 - val_loss: 0.0466\n",
      "7/7 [==============================] - 1s 2ms/step\n",
      "Epoch 1/200\n",
      "18/18 [==============================] - 5s 61ms/step - loss: 215.5908 - val_loss: 174.4409\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 184.6871 - val_loss: 122.8458\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 110.0583 - val_loss: 55.6434\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 62.3561 - val_loss: 44.1814\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 56.7470 - val_loss: 44.3485\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 55.3727 - val_loss: 43.8036\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 53.1815 - val_loss: 42.0595\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 51.2402 - val_loss: 39.4562\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 49.3838 - val_loss: 35.6065\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 43.6057 - val_loss: 30.5658\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 37.4725 - val_loss: 23.6508\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 30.9231 - val_loss: 17.8881\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 23.9913 - val_loss: 14.4321\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 20.5631 - val_loss: 12.7260\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 18.8067 - val_loss: 11.4143\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 17.9588 - val_loss: 10.4601\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 16.5698 - val_loss: 9.4916\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 14.2019 - val_loss: 8.7928\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 14.4917 - val_loss: 8.1076\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 12.2741 - val_loss: 7.5587\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 12.2528 - val_loss: 7.0372\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 11.9817 - val_loss: 6.5729\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 12.0461 - val_loss: 6.1244\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10.2732 - val_loss: 5.6597\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 10.0575 - val_loss: 5.2812\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 9.6122 - val_loss: 4.9743\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.9169 - val_loss: 4.6146\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.7993 - val_loss: 4.3185\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.6246 - val_loss: 4.0284\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 8.1608 - val_loss: 3.7731\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2167 - val_loss: 3.5783\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.3126 - val_loss: 3.3414\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.9526 - val_loss: 3.1294\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.8121 - val_loss: 2.9725\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 7.2307 - val_loss: 3.0132\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.4003 - val_loss: 2.8097\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 6.0999 - val_loss: 2.4758\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.7657 - val_loss: 2.3814\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.6243 - val_loss: 2.1469\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.0674 - val_loss: 2.0339\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.9497 - val_loss: 1.9988\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.3602 - val_loss: 1.8223\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 5.5076 - val_loss: 1.7668\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.9334 - val_loss: 1.6413\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.6455 - val_loss: 1.6167\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.3305 - val_loss: 1.5159\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.3229 - val_loss: 1.3990\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.3603 - val_loss: 1.3066\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.1587 - val_loss: 1.2482\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.1435 - val_loss: 1.4828\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 4.1841 - val_loss: 1.1388\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.2825 - val_loss: 1.0621\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.6027 - val_loss: 1.0393\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.2807 - val_loss: 1.0701\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.1321 - val_loss: 1.1491\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.2912 - val_loss: 0.9438\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.2412 - val_loss: 1.0137\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.2344 - val_loss: 0.9699\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.4532 - val_loss: 0.8055\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.5369 - val_loss: 0.9735\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.2077 - val_loss: 0.7499\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.3181 - val_loss: 0.7691\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.1421 - val_loss: 0.8305\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.0196 - val_loss: 0.6587\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.4655 - val_loss: 0.6907\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.1222 - val_loss: 0.9772\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.1296 - val_loss: 0.5976\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.9663 - val_loss: 0.6035\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.7453 - val_loss: 0.8239\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.0359 - val_loss: 0.6360\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 3.2244 - val_loss: 0.5725\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.5962 - val_loss: 0.5794\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.8286 - val_loss: 0.5010\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.5852 - val_loss: 0.7845\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.7980 - val_loss: 0.4784\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.4453 - val_loss: 0.4701\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.5137 - val_loss: 0.5536\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.5076 - val_loss: 0.4881\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.4502 - val_loss: 0.4686\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3683 - val_loss: 0.5201\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.5571 - val_loss: 0.4906\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.6089 - val_loss: 0.4777\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.2246 - val_loss: 0.4267\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.7339 - val_loss: 0.4924\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.5196 - val_loss: 0.3806\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3185 - val_loss: 0.3881\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3722 - val_loss: 0.4940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.4414 - val_loss: 0.4452\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.5612 - val_loss: 0.3907\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.5187 - val_loss: 0.3732\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.1804 - val_loss: 0.4950\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.1462 - val_loss: 0.3439\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3557 - val_loss: 0.3430\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.6704 - val_loss: 0.3643\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.0451 - val_loss: 0.3622\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3965 - val_loss: 0.3934\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.1315 - val_loss: 0.3547\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.2393 - val_loss: 0.3853\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.0730 - val_loss: 0.3399\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3797 - val_loss: 0.3421\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.5626 - val_loss: 0.3024\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.0081 - val_loss: 0.3668\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3859 - val_loss: 0.3838\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3343 - val_loss: 0.2811\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.9644 - val_loss: 0.2677\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8190 - val_loss: 0.3136\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.1543 - val_loss: 0.3250\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3430 - val_loss: 0.2434\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.2134 - val_loss: 0.2793\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.4265 - val_loss: 0.3428\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8190 - val_loss: 0.3788\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.1621 - val_loss: 0.2858\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7701 - val_loss: 0.4817\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7771 - val_loss: 0.3120\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.2066 - val_loss: 0.2722\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.2426 - val_loss: 0.4200\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.8231 - val_loss: 0.2219\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.9130 - val_loss: 0.2870\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.9380 - val_loss: 0.2328\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.2712 - val_loss: 0.2394\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.8320 - val_loss: 0.2142\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.9747 - val_loss: 0.3316\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.9107 - val_loss: 0.2094\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7177 - val_loss: 0.1917\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.8771 - val_loss: 0.1804\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8651 - val_loss: 0.2607\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.9926 - val_loss: 0.2120\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.9135 - val_loss: 0.1776\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8837 - val_loss: 0.2886\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.9562 - val_loss: 0.2056\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.2026 - val_loss: 0.1789\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7232 - val_loss: 0.1854\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7973 - val_loss: 0.1997\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.9817 - val_loss: 0.1907\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6914 - val_loss: 0.2475\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.9611 - val_loss: 0.1780\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.2540 - val_loss: 0.1621\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8849 - val_loss: 0.1779\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7253 - val_loss: 0.1413\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7931 - val_loss: 0.1977\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6809 - val_loss: 0.1767\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.8868 - val_loss: 0.1926\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7245 - val_loss: 0.2119\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.3053 - val_loss: 0.1525\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.0232 - val_loss: 0.1612\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.9243 - val_loss: 0.1581\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.9696 - val_loss: 0.2497\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8164 - val_loss: 0.1674\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.0485 - val_loss: 0.1522\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.9223 - val_loss: 0.1619\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8270 - val_loss: 0.2102\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8136 - val_loss: 0.1359\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8192 - val_loss: 0.1662\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.2802 - val_loss: 0.1045\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.6559 - val_loss: 0.1023\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7514 - val_loss: 0.1225\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8912 - val_loss: 0.1092\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.8802 - val_loss: 0.1734\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6991 - val_loss: 0.1166\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.6252 - val_loss: 0.1102\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 2.1240 - val_loss: 0.1446\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8521 - val_loss: 0.1602\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8908 - val_loss: 0.1839\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.5807 - val_loss: 0.1251\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.4532 - val_loss: 0.1593\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.9223 - val_loss: 0.1228\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6358 - val_loss: 0.2060\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8494 - val_loss: 0.0963\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 1.7208 - val_loss: 0.1094\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8870 - val_loss: 0.1354\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8423 - val_loss: 0.0922\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8572 - val_loss: 0.1180\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7571 - val_loss: 0.0798\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7086 - val_loss: 0.0885\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.1430 - val_loss: 0.0825\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.7677 - val_loss: 0.1321\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8214 - val_loss: 0.0958\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.0465 - val_loss: 0.1435\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6535 - val_loss: 0.1008\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.4745 - val_loss: 0.2171\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 1.7030 - val_loss: 0.1105\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6456 - val_loss: 0.1210\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.4021 - val_loss: 0.1145\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.9956 - val_loss: 0.1775\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6681 - val_loss: 0.0754\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6472 - val_loss: 0.2648\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7961 - val_loss: 0.0740\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7114 - val_loss: 0.1175\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7394 - val_loss: 0.0842\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7591 - val_loss: 0.2190\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7219 - val_loss: 0.1396\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8413 - val_loss: 0.2670\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6899 - val_loss: 0.0690\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.7434 - val_loss: 0.0960\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.2277 - val_loss: 0.1239\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.8489 - val_loss: 0.1148\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 2.0162 - val_loss: 0.5133\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6539 - val_loss: 0.1284\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.5207 - val_loss: 0.0831\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 1.6635 - val_loss: 0.1371\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Epoch 1/200\n",
      "16/16 [==============================] - 5s 51ms/step - loss: 149.0300 - val_loss: 204.1411\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 136.5130 - val_loss: 174.3544\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 101.9794 - val_loss: 118.4377\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 76.3144 - val_loss: 99.3418\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 71.8611 - val_loss: 94.4074\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 65.5504 - val_loss: 87.1651\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 57.9515 - val_loss: 74.5131\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 46.3577 - val_loss: 59.4883\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 36.4167 - val_loss: 48.7399\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 29.1426 - val_loss: 41.7242\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 25.7034 - val_loss: 37.2317\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 24.9434 - val_loss: 33.8089\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 21.3029 - val_loss: 31.0357\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 20.7599 - val_loss: 28.6152\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 18.0989 - val_loss: 26.2145\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 16.6874 - val_loss: 24.3655\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 15.4884 - val_loss: 22.4726\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 14.6382 - val_loss: 20.7875\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 13.8568 - val_loss: 19.2003\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 12.3614 - val_loss: 17.8330\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10.9634 - val_loss: 16.5668\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 11.0572 - val_loss: 15.3635\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 10.1889 - val_loss: 14.4032\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 9.5819 - val_loss: 13.4879\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 8.5841 - val_loss: 12.4609\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.6570 - val_loss: 11.5908\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 7.7455 - val_loss: 11.0021\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.4772 - val_loss: 10.2428\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.4509 - val_loss: 9.5551\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 6.3008 - val_loss: 9.0056\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.9746 - val_loss: 8.5177\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.4166 - val_loss: 8.0162\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.5819 - val_loss: 7.5216\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 5.8953 - val_loss: 7.0594\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 5.5456 - val_loss: 6.6639\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.7826 - val_loss: 6.3309\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.1390 - val_loss: 5.9592\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 4.0770 - val_loss: 5.6849\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 4.2870 - val_loss: 5.4472\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.8300 - val_loss: 5.2996\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.2069 - val_loss: 5.0190\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5763 - val_loss: 4.7657\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.9091 - val_loss: 4.5784\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.5323 - val_loss: 4.5599\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.4213 - val_loss: 4.2197\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 3.4994 - val_loss: 4.0906\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3186 - val_loss: 3.9557\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.1059 - val_loss: 3.8078\n",
      "Epoch 49/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 2.8791 - val_loss: 3.6911\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.3916 - val_loss: 3.7437\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.9492 - val_loss: 3.5965\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.0656 - val_loss: 3.4040\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.0512 - val_loss: 3.4406\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 3.0022 - val_loss: 3.2132\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.6601 - val_loss: 3.1804\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.8598 - val_loss: 3.0464\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.6642 - val_loss: 3.0101\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.7899 - val_loss: 2.9076\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.6610 - val_loss: 2.8832\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0842 - val_loss: 2.7924\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.4768 - val_loss: 2.8227\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.3232 - val_loss: 2.8354\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.5313 - val_loss: 2.6612\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.6205 - val_loss: 2.6206\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.6302 - val_loss: 2.5382\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.8636 - val_loss: 2.4645\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.2895 - val_loss: 2.4339\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.3819 - val_loss: 2.3651\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.2264 - val_loss: 2.3530\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0015 - val_loss: 2.3243\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.5430 - val_loss: 2.2872\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.3210 - val_loss: 2.2706\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.2238 - val_loss: 2.1644\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8259 - val_loss: 2.1487\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.2116 - val_loss: 2.1407\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0699 - val_loss: 2.0827\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0546 - val_loss: 2.0804\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.4047 - val_loss: 2.0184\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9490 - val_loss: 2.0084\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0644 - val_loss: 1.9886\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.1352 - val_loss: 2.0008\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0095 - val_loss: 1.9516\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.1799 - val_loss: 1.9521\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8613 - val_loss: 1.8861\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5341 - val_loss: 2.0047\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.1539 - val_loss: 1.8388\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0178 - val_loss: 1.7751\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8107 - val_loss: 1.7938\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0280 - val_loss: 1.7740\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7870 - val_loss: 1.7393\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.1905 - val_loss: 1.7566\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0749 - val_loss: 1.7740\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7866 - val_loss: 1.6538\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0952 - val_loss: 1.6645\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6049 - val_loss: 1.6361\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.2488 - val_loss: 1.7407\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.1069 - val_loss: 1.6499\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9059 - val_loss: 1.5899\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7539 - val_loss: 1.5896\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8371 - val_loss: 1.5349\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5954 - val_loss: 1.6307\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.2847 - val_loss: 1.5604\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9490 - val_loss: 1.5443\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9668 - val_loss: 1.5739\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5445 - val_loss: 1.4915\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4824 - val_loss: 1.5281\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8784 - val_loss: 1.5112\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9768 - val_loss: 1.4497\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0229 - val_loss: 1.4815\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7691 - val_loss: 1.5101\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4622 - val_loss: 1.4375\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9428 - val_loss: 1.4646\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6521 - val_loss: 1.4832\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5932 - val_loss: 1.4393\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5177 - val_loss: 1.3811\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8634 - val_loss: 1.3910\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6576 - val_loss: 1.3492\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0211 - val_loss: 1.3808\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8165 - val_loss: 1.3955\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.0204 - val_loss: 1.4141\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7710 - val_loss: 1.3531\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4595 - val_loss: 1.3691\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6084 - val_loss: 1.2570\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9307 - val_loss: 1.3189\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6018 - val_loss: 1.2495\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6095 - val_loss: 1.2638\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4913 - val_loss: 1.3749\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5465 - val_loss: 1.2244\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5794 - val_loss: 1.2327\n",
      "Epoch 130/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5871 - val_loss: 1.2060\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7921 - val_loss: 1.1645\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2526 - val_loss: 1.1835\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2682 - val_loss: 1.1818\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5041 - val_loss: 1.1655\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.9787 - val_loss: 1.1526\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5575 - val_loss: 1.1513\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8708 - val_loss: 1.1696\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7537 - val_loss: 1.1610\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7133 - val_loss: 1.2109\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3814 - val_loss: 1.1532\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.3268 - val_loss: 1.0791\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3686 - val_loss: 1.0618\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3434 - val_loss: 1.0772\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7007 - val_loss: 1.1281\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2979 - val_loss: 1.0578\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2846 - val_loss: 1.0396\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5608 - val_loss: 1.1729\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4277 - val_loss: 1.0279\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8077 - val_loss: 1.1466\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4472 - val_loss: 1.0416\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8149 - val_loss: 1.1543\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.2201 - val_loss: 1.0474\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5150 - val_loss: 1.0607\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6902 - val_loss: 0.9959\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3932 - val_loss: 1.0050\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.8258 - val_loss: 0.9923\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 1.4232 - val_loss: 1.0463\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6141 - val_loss: 0.9788\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5970 - val_loss: 1.0076\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3279 - val_loss: 0.9844\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2099 - val_loss: 1.0792\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6084 - val_loss: 0.9704\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5551 - val_loss: 0.9462\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5632 - val_loss: 1.0454\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4587 - val_loss: 0.9522\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4496 - val_loss: 1.0092\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6441 - val_loss: 1.0592\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6559 - val_loss: 0.9603\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.0520 - val_loss: 0.9538\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5133 - val_loss: 0.9035\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3268 - val_loss: 0.8833\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5766 - val_loss: 1.0772\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7487 - val_loss: 0.9579\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7038 - val_loss: 0.8829\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7882 - val_loss: 0.8943\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5464 - val_loss: 0.8633\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6089 - val_loss: 0.9790\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4862 - val_loss: 0.9798\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6123 - val_loss: 0.9410\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2642 - val_loss: 0.8554\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3259 - val_loss: 0.8492\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5528 - val_loss: 1.0702\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3786 - val_loss: 0.8400\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5249 - val_loss: 0.8475\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 1.4638 - val_loss: 0.9414\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2921 - val_loss: 0.8637\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6621 - val_loss: 0.8134\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.7539 - val_loss: 0.9476\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.2633 - val_loss: 0.9344\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.6428 - val_loss: 0.8422\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5063 - val_loss: 0.8331\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5123 - val_loss: 1.0259\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.6259 - val_loss: 0.8304\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.5456 - val_loss: 0.9863\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.3672 - val_loss: 0.8661\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.5811 - val_loss: 0.8878\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 1.4915 - val_loss: 0.8978\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4101 - val_loss: 0.7885\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.4257 - val_loss: 0.7678\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 1.3032 - val_loss: 0.8133\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Epoch 1/200\n",
      "19/19 [==============================] - 5s 42ms/step - loss: 83.9934 - val_loss: 70.5320\n",
      "Epoch 2/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 57.8601 - val_loss: 27.4620\n",
      "Epoch 3/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 14.2438 - val_loss: 3.9483\n",
      "Epoch 4/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.9368 - val_loss: 4.6173\n",
      "Epoch 5/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.6107 - val_loss: 3.8371\n",
      "Epoch 6/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.4748 - val_loss: 3.6030\n",
      "Epoch 7/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.0468 - val_loss: 3.3704\n",
      "Epoch 8/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 5.0689 - val_loss: 2.9853\n",
      "Epoch 9/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.2842 - val_loss: 2.6053\n",
      "Epoch 10/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 4.0424 - val_loss: 2.0857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 3.7108 - val_loss: 1.5322\n",
      "Epoch 12/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.5466 - val_loss: 1.0524\n",
      "Epoch 13/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 2.1796 - val_loss: 0.7077\n",
      "Epoch 14/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.9108 - val_loss: 0.5672\n",
      "Epoch 15/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.7973 - val_loss: 0.5374\n",
      "Epoch 16/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6222 - val_loss: 0.4865\n",
      "Epoch 17/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.6552 - val_loss: 0.4631\n",
      "Epoch 18/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5770 - val_loss: 0.4443\n",
      "Epoch 19/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.7163 - val_loss: 0.4457\n",
      "Epoch 20/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.5705 - val_loss: 0.4121\n",
      "Epoch 21/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.4816 - val_loss: 0.3785\n",
      "Epoch 22/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 1.4802 - val_loss: 0.3979\n",
      "Epoch 23/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.3440 - val_loss: 0.3418\n",
      "Epoch 24/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.4323 - val_loss: 0.3538\n",
      "Epoch 25/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.3812 - val_loss: 0.3540\n",
      "Epoch 26/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.2642 - val_loss: 0.3115\n",
      "Epoch 27/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.2892 - val_loss: 0.3017\n",
      "Epoch 28/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.3692 - val_loss: 0.3007\n",
      "Epoch 29/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.2858 - val_loss: 0.3143\n",
      "Epoch 30/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.1532 - val_loss: 0.2426\n",
      "Epoch 31/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.3230 - val_loss: 0.2886\n",
      "Epoch 32/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.0686 - val_loss: 0.2326\n",
      "Epoch 33/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.1422 - val_loss: 0.2073\n",
      "Epoch 34/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.1682 - val_loss: 0.2250\n",
      "Epoch 35/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.0944 - val_loss: 0.2013\n",
      "Epoch 36/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 1.0955 - val_loss: 0.1852\n",
      "Epoch 37/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.3292 - val_loss: 0.1933\n",
      "Epoch 38/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.0766 - val_loss: 0.1689\n",
      "Epoch 39/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9559 - val_loss: 0.1900\n",
      "Epoch 40/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.0317 - val_loss: 0.1657\n",
      "Epoch 41/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.0346 - val_loss: 0.1513\n",
      "Epoch 42/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.0301 - val_loss: 0.1325\n",
      "Epoch 43/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.0047 - val_loss: 0.1236\n",
      "Epoch 44/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.0381 - val_loss: 0.2008\n",
      "Epoch 45/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 1.0387 - val_loss: 0.1225\n",
      "Epoch 46/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8427 - val_loss: 0.1125\n",
      "Epoch 47/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9701 - val_loss: 0.1221\n",
      "Epoch 48/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8497 - val_loss: 0.1754\n",
      "Epoch 49/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9746 - val_loss: 0.2280\n",
      "Epoch 50/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8525 - val_loss: 0.1199\n",
      "Epoch 51/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8647 - val_loss: 0.1052\n",
      "Epoch 52/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8817 - val_loss: 0.1133\n",
      "Epoch 53/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9368 - val_loss: 0.0950\n",
      "Epoch 54/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8824 - val_loss: 0.1121\n",
      "Epoch 55/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7893 - val_loss: 0.0758\n",
      "Epoch 56/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8047 - val_loss: 0.0697\n",
      "Epoch 57/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.9290 - val_loss: 0.0738\n",
      "Epoch 58/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9464 - val_loss: 0.1105\n",
      "Epoch 59/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8738 - val_loss: 0.0915\n",
      "Epoch 60/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8129 - val_loss: 0.0845\n",
      "Epoch 61/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.9008 - val_loss: 0.0672\n",
      "Epoch 62/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8466 - val_loss: 0.1190\n",
      "Epoch 63/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8483 - val_loss: 0.0653\n",
      "Epoch 64/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8023 - val_loss: 0.0595\n",
      "Epoch 65/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7971 - val_loss: 0.0804\n",
      "Epoch 66/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.8214 - val_loss: 0.0889\n",
      "Epoch 67/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7434 - val_loss: 0.0787\n",
      "Epoch 68/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6687 - val_loss: 0.0775\n",
      "Epoch 69/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.8375 - val_loss: 0.0714\n",
      "Epoch 70/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7744 - val_loss: 0.0750\n",
      "Epoch 71/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.7322 - val_loss: 0.0488\n",
      "Epoch 72/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7880 - val_loss: 0.0519\n",
      "Epoch 73/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6558 - val_loss: 0.0463\n",
      "Epoch 74/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6886 - val_loss: 0.0488\n",
      "Epoch 75/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6927 - val_loss: 0.0437\n",
      "Epoch 76/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7295 - val_loss: 0.0585\n",
      "Epoch 77/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.7618 - val_loss: 0.0820\n",
      "Epoch 78/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7527 - val_loss: 0.0640\n",
      "Epoch 79/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.7212 - val_loss: 0.0483\n",
      "Epoch 80/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7124 - val_loss: 0.0578\n",
      "Epoch 81/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7414 - val_loss: 0.0549\n",
      "Epoch 82/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6580 - val_loss: 0.0462\n",
      "Epoch 83/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7391 - val_loss: 0.0647\n",
      "Epoch 84/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7204 - val_loss: 0.0499\n",
      "Epoch 85/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7255 - val_loss: 0.0510\n",
      "Epoch 86/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6451 - val_loss: 0.0554\n",
      "Epoch 87/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6480 - val_loss: 0.0398\n",
      "Epoch 88/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6476 - val_loss: 0.0360\n",
      "Epoch 89/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7462 - val_loss: 0.0669\n",
      "Epoch 90/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6523 - val_loss: 0.0359\n",
      "Epoch 91/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6241 - val_loss: 0.0533\n",
      "Epoch 92/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6232 - val_loss: 0.0530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6875 - val_loss: 0.0378\n",
      "Epoch 94/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6620 - val_loss: 0.0380\n",
      "Epoch 95/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6173 - val_loss: 0.0321\n",
      "Epoch 96/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6125 - val_loss: 0.0379\n",
      "Epoch 97/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6428 - val_loss: 0.0395\n",
      "Epoch 98/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6729 - val_loss: 0.0335\n",
      "Epoch 99/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6610 - val_loss: 0.0455\n",
      "Epoch 100/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6034 - val_loss: 0.0562\n",
      "Epoch 101/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6337 - val_loss: 0.0364\n",
      "Epoch 102/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6989 - val_loss: 0.0294\n",
      "Epoch 103/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6429 - val_loss: 0.0316\n",
      "Epoch 104/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5378 - val_loss: 0.0538\n",
      "Epoch 105/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7307 - val_loss: 0.0280\n",
      "Epoch 106/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.7054 - val_loss: 0.0297\n",
      "Epoch 107/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5786 - val_loss: 0.0316\n",
      "Epoch 108/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6172 - val_loss: 0.0259\n",
      "Epoch 109/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5354 - val_loss: 0.0256\n",
      "Epoch 110/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5313 - val_loss: 0.0275\n",
      "Epoch 111/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6280 - val_loss: 0.0348\n",
      "Epoch 112/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6481 - val_loss: 0.0283\n",
      "Epoch 113/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6529 - val_loss: 0.0251\n",
      "Epoch 114/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6323 - val_loss: 0.0280\n",
      "Epoch 115/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5928 - val_loss: 0.0252\n",
      "Epoch 116/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5514 - val_loss: 0.0343\n",
      "Epoch 117/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5968 - val_loss: 0.0257\n",
      "Epoch 118/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6200 - val_loss: 0.0493\n",
      "Epoch 119/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6122 - val_loss: 0.0326\n",
      "Epoch 120/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6460 - val_loss: 0.0280\n",
      "Epoch 121/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6271 - val_loss: 0.0322\n",
      "Epoch 122/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5840 - val_loss: 0.0665\n",
      "Epoch 123/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6520 - val_loss: 0.0356\n",
      "Epoch 124/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6015 - val_loss: 0.0373\n",
      "Epoch 125/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6483 - val_loss: 0.0255\n",
      "Epoch 126/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5383 - val_loss: 0.0321\n",
      "Epoch 127/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5791 - val_loss: 0.0320\n",
      "Epoch 128/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5182 - val_loss: 0.0350\n",
      "Epoch 129/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5607 - val_loss: 0.0494\n",
      "Epoch 130/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6846 - val_loss: 0.0346\n",
      "Epoch 131/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5724 - val_loss: 0.0375\n",
      "Epoch 132/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5532 - val_loss: 0.0613\n",
      "Epoch 133/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5878 - val_loss: 0.0323\n",
      "Epoch 134/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6065 - val_loss: 0.0244\n",
      "Epoch 135/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5404 - val_loss: 0.0416\n",
      "Epoch 136/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5755 - val_loss: 0.0328\n",
      "Epoch 137/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6055 - val_loss: 0.0282\n",
      "Epoch 138/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5897 - val_loss: 0.0424\n",
      "Epoch 139/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5429 - val_loss: 0.0250\n",
      "Epoch 140/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5195 - val_loss: 0.0280\n",
      "Epoch 141/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.6458 - val_loss: 0.0214\n",
      "Epoch 142/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5987 - val_loss: 0.0486\n",
      "Epoch 143/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5919 - val_loss: 0.0271\n",
      "Epoch 144/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5957 - val_loss: 0.0224\n",
      "Epoch 145/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5012 - val_loss: 0.0217\n",
      "Epoch 146/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5536 - val_loss: 0.0237\n",
      "Epoch 147/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5906 - val_loss: 0.0204\n",
      "Epoch 148/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5020 - val_loss: 0.0249\n",
      "Epoch 149/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5810 - val_loss: 0.0210\n",
      "Epoch 150/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5517 - val_loss: 0.0377\n",
      "Epoch 151/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5213 - val_loss: 0.0504\n",
      "Epoch 152/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5493 - val_loss: 0.0371\n",
      "Epoch 153/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5526 - val_loss: 0.0412\n",
      "Epoch 154/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4867 - val_loss: 0.0279\n",
      "Epoch 155/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5836 - val_loss: 0.0469\n",
      "Epoch 156/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5575 - val_loss: 0.0259\n",
      "Epoch 157/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5872 - val_loss: 0.0237\n",
      "Epoch 158/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5221 - val_loss: 0.0327\n",
      "Epoch 159/200\n",
      "19/19 [==============================] - 0s 4ms/step - loss: 0.5562 - val_loss: 0.0244\n",
      "Epoch 160/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5978 - val_loss: 0.0235\n",
      "Epoch 161/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5834 - val_loss: 0.0271\n",
      "Epoch 162/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5155 - val_loss: 0.0401\n",
      "Epoch 163/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5938 - val_loss: 0.0593\n",
      "Epoch 164/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5426 - val_loss: 0.0471\n",
      "Epoch 165/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6225 - val_loss: 0.0503\n",
      "Epoch 166/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5190 - val_loss: 0.0220\n",
      "Epoch 167/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5625 - val_loss: 0.0266\n",
      "Epoch 168/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5492 - val_loss: 0.0224\n",
      "Epoch 169/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5419 - val_loss: 0.0419\n",
      "Epoch 170/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5514 - val_loss: 0.0216\n",
      "Epoch 171/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6491 - val_loss: 0.0291\n",
      "Epoch 172/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.6468 - val_loss: 0.0316\n",
      "Epoch 173/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5255 - val_loss: 0.0183\n",
      "Epoch 174/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5816 - val_loss: 0.0421\n",
      "Epoch 175/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5229 - val_loss: 0.0471\n",
      "Epoch 176/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4770 - val_loss: 0.0224\n",
      "Epoch 177/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5494 - val_loss: 0.0228\n",
      "Epoch 178/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5601 - val_loss: 0.0213\n",
      "Epoch 179/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5258 - val_loss: 0.0172\n",
      "Epoch 180/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5444 - val_loss: 0.0212\n",
      "Epoch 181/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4800 - val_loss: 0.0300\n",
      "Epoch 182/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5302 - val_loss: 0.0214\n",
      "Epoch 183/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5073 - val_loss: 0.0211\n",
      "Epoch 184/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.5067 - val_loss: 0.0272\n",
      "Epoch 185/200\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.4901 - val_loss: 0.0229\n",
      "Epoch 186/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5426 - val_loss: 0.0177\n",
      "Epoch 187/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5514 - val_loss: 0.0185\n",
      "Epoch 188/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4714 - val_loss: 0.0196\n",
      "Epoch 189/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5236 - val_loss: 0.0171\n",
      "Epoch 190/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4673 - val_loss: 0.0180\n",
      "Epoch 191/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5870 - val_loss: 0.0152\n",
      "Epoch 192/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5179 - val_loss: 0.0182\n",
      "Epoch 193/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.4786 - val_loss: 0.0240\n",
      "Epoch 194/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5582 - val_loss: 0.0223\n",
      "Epoch 195/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5146 - val_loss: 0.0154\n",
      "Epoch 196/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5368 - val_loss: 0.0256\n",
      "Epoch 197/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5156 - val_loss: 0.0168\n",
      "Epoch 198/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5524 - val_loss: 0.0169\n",
      "Epoch 199/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5552 - val_loss: 0.0206\n",
      "Epoch 200/200\n",
      "19/19 [==============================] - 0s 5ms/step - loss: 0.5561 - val_loss: 0.0156\n",
      "7/7 [==============================] - 1s 2ms/step\n",
      "Evaluation results for SAVE:\n",
      "Mean Squared Error: 0.4794737244317963\n",
      "Mean Absolute Error: 0.560515062132878\n",
      "R-squared: 0.9914723170087661\n",
      "\n",
      "Evaluation results for CLNE:\n",
      "Mean Squared Error: 0.05233011446051706\n",
      "Mean Absolute Error: 0.12409837566204927\n",
      "R-squared: 0.9951997084639876\n",
      "\n",
      "Evaluation results for LAZR:\n",
      "Mean Squared Error: 0.23932105659279082\n",
      "Mean Absolute Error: 0.32120410973827035\n",
      "R-squared: 0.9960643278921892\n",
      "\n",
      "Evaluation results for AMWL:\n",
      "Mean Squared Error: 0.23662062486990768\n",
      "Mean Absolute Error: 0.3384645703327224\n",
      "R-squared: 0.9973146817736946\n",
      "\n",
      "Evaluation results for GEO:\n",
      "Mean Squared Error: 0.013656731628594529\n",
      "Mean Absolute Error: 0.07719759917377826\n",
      "R-squared: 0.9975246956721519\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('dataset.csv').dropna()\n",
    "\n",
    "# List of ticker symbols\n",
    "tickers = df['level_0'].unique()\n",
    "\n",
    "# Dictionary to store evaluation results\n",
    "evaluation_results_current = {}\n",
    "\n",
    "# Loop through each ticker\n",
    "for ticker in tickers:\n",
    "    # Filter data for the current ticker\n",
    "    ticker_df = df[df['level_0'] == ticker]\n",
    "    \n",
    "    # Extract features and target variable\n",
    "    X = ticker_df[['Open', 'High', 'Low', 'Volume','Daily Returns','Volatility','RSI', '%K', '%D','Sentiment Score','Movement','PreviousDayClose']].values\n",
    "    y = ticker_df['Close'].values\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split dataset into training plus validation, and testing sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Split training plus validation set into training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "    # Reshape input data for GRU (samples, time steps, features)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], 1, X_val.shape[1]))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "    \n",
    "    # Define the GRU model\n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(units=50, return_sequences=True))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(GRU(units=50))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=1))\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, epochs=200, batch_size=32, verbose=1, validation_data=(X_val, y_val))\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    \n",
    "    # Store evaluation results\n",
    "    evaluation_results_current[ticker] = {'Mean Squared Error': mse, 'Mean Absolute Error': mae, 'R-squared': r2}\n",
    "\n",
    "# Display evaluation results\n",
    "for ticker, results in evaluation_results_current.items():\n",
    "    print(f'Evaluation results for {ticker}:')\n",
    "    for metric, value in results.items():\n",
    "        print(f'{metric}: {value}')\n",
    "    print()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Scatter plot of actual vs. predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, predictions, color='red', alpha=0.5, label='Actual')  # Actual values in red\n",
    "plt.scatter(y_test, predictions, color='blue', alpha=0.5, label='Predicted')  # Predicted values in blue\n",
    "plt.title('Actual vs. Predicted Stock Prices')\n",
    "plt.xlabel('Actual Current Close Price')\n",
    "plt.ylabel('Predicted Current Close Price')\n",
    "plt.legend()  # Show legend to differentiate between actual and predicted\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6abb7dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Score Weight: [-0.5084823]\n"
     ]
    }
   ],
   "source": [
    "# Extract the sentiment score weights from the dense layer\n",
    "sentiment_score_weights = model.layers[-1].get_weights()[0][-1]\n",
    "\n",
    "# Interpret the sentiment score weights\n",
    "print(\"Sentiment Score Weight:\", sentiment_score_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94bbcc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Aggregate stock prices based on sentiment scores\n",
    "sentiment_price_avg = ticker_df.groupby('Sentiment Score')['PreviousDayClose'].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the line plot\n",
    "plt.plot(sentiment_price_avg.index, sentiment_price_avg.values, marker='o', linestyle='-')\n",
    "plt.title('Average Stock Price vs. Sentiment Score')\n",
    "plt.xlabel('Sentiment Score')\n",
    "plt.ylabel('Average Current Day Close Price')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b218b3",
   "metadata": {},
   "source": [
    "Comparison Model Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b047858",
   "metadata": {},
   "source": [
    "NextDay Close Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e77401c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for Linear Regression:\n",
      "SAVE: MSE=0.4567, MAE=0.4734, R2=0.9917\n",
      "CLNE: MSE=0.0562, MAE=0.1652, R2=0.9948\n",
      "LAZR: MSE=0.3310, MAE=0.4151, R2=0.9945\n",
      "AMWL: MSE=0.3010, MAE=0.3293, R2=0.9967\n",
      "GEO: MSE=0.0766, MAE=0.1758, R2=0.9863\n",
      "\n",
      "Evaluation results for Random Forest Regression:\n",
      "SAVE: MSE=0.5033, MAE=0.4336, R2=0.9908\n",
      "CLNE: MSE=0.1049, MAE=0.1835, R2=0.9903\n",
      "LAZR: MSE=0.4916, MAE=0.3973, R2=0.9919\n",
      "AMWL: MSE=0.4009, MAE=0.3156, R2=0.9956\n",
      "GEO: MSE=0.0853, MAE=0.1633, R2=0.9848\n",
      "\n",
      "Evaluation results for Decision Tree Regression:\n",
      "SAVE: MSE=0.7756, MAE=0.5894, R2=0.9859\n",
      "CLNE: MSE=0.1874, MAE=0.2574, R2=0.9826\n",
      "LAZR: MSE=0.9477, MAE=0.5458, R2=0.9843\n",
      "AMWL: MSE=0.6212, MAE=0.3890, R2=0.9931\n",
      "GEO: MSE=0.1948, MAE=0.2552, R2=0.9653\n",
      "\n",
      "Evaluation results for KNN:\n",
      "SAVE: MSE=1.2414, MAE=0.7936, R2=0.9774\n",
      "CLNE: MSE=0.3462, MAE=0.4041, R2=0.9678\n",
      "LAZR: MSE=2.0080, MAE=0.9967, R2=0.9668\n",
      "AMWL: MSE=1.6977, MAE=0.9246, R2=0.9813\n",
      "GEO: MSE=0.1618, MAE=0.2897, R2=0.9711\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('dataset.csv').dropna()\n",
    "tickers = ['SAVE', 'CLNE', 'LAZR', 'AMWL', 'GEO']\n",
    "\n",
    "# Initialize dictionaries to store evaluation results for each model\n",
    "evaluation_results_nextdaycomp = {'Linear Regression': [], 'Random Forest Regression': [], 'Decision Tree Regression': [], 'KNN': []}\n",
    "\n",
    "# Loop through each ticker\n",
    "for ticker in tickers:\n",
    "    # Filter data for the current ticker\n",
    "    ticker_df = df[df['level_0'] == ticker]\n",
    "    \n",
    "    # Extract features and target variable\n",
    "    X = ticker_df[['Open', 'High', 'Low', 'Close', 'Volume','Daily Returns','Volatility','RSI', '%K', '%D','Sentiment Score','Movement']].values\n",
    "    y = ticker_df['NextDayClose'].values\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define function to perform regression and evaluate the model\n",
    "    def perform_regression(model, X_train, X_test, y_train, y_test):\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        \n",
    "        return mse, mae, r2, predictions\n",
    "    \n",
    "    # Perform Linear Regression\n",
    "    lr_model = LinearRegression()\n",
    "    lr_mse, lr_mae, lr_r2, _ = perform_regression(lr_model, X_train, X_test, y_train, y_test)\n",
    "    evaluation_results_nextdaycomp['Linear Regression'].append((lr_mse, lr_mae, lr_r2))\n",
    "    \n",
    "    # Perform Random Forest Regression\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_mse, rf_mae, rf_r2, _ = perform_regression(rf_model, X_train, X_test, y_train, y_test)\n",
    "    evaluation_results_nextdaycomp['Random Forest Regression'].append((rf_mse, rf_mae, rf_r2))\n",
    "    \n",
    "    # Perform Decision Tree Regression\n",
    "    dt_model = DecisionTreeRegressor(random_state=42)\n",
    "    dt_mse, dt_mae, dt_r2, _ = perform_regression(dt_model, X_train, X_test, y_train, y_test)\n",
    "    evaluation_results_nextdaycomp['Decision Tree Regression'].append((dt_mse, dt_mae, dt_r2))\n",
    "    \n",
    "    # Perform KNN Regression\n",
    "    knn_model = KNeighborsRegressor()\n",
    "    knn_mse, knn_mae, knn_r2, _ = perform_regression(knn_model, X_train, X_test, y_train, y_test)\n",
    "    evaluation_results_nextdaycomp['KNN'].append((knn_mse, knn_mae, knn_r2))\n",
    "\n",
    "# Print evaluation results for each model\n",
    "for model, results in evaluation_results_nextdaycomp.items():\n",
    "    print(f'Evaluation results for {model}:')\n",
    "    for ticker, (mse, mae, r2) in zip(tickers, results):\n",
    "        print(f'{ticker}: MSE={mse:.4f}, MAE={mae:.4f}, R2={r2:.4f}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322cacd6",
   "metadata": {},
   "source": [
    "PreviousDay Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a764c3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for Linear Regression:\n",
      "SAVE: MSE=0.0935, MAE=0.1827, R2=0.9983\n",
      "CLNE: MSE=0.0616, MAE=0.0895, R2=0.9938\n",
      "LAZR: MSE=0.1535, MAE=0.2106, R2=0.9975\n",
      "AMWL: MSE=0.0622, MAE=0.1671, R2=0.9993\n",
      "GEO: MSE=0.0087, MAE=0.0544, R2=0.9985\n",
      "\n",
      "Evaluation results for Random Forest Regression:\n",
      "SAVE: MSE=0.3946, MAE=0.3732, R2=0.9927\n",
      "CLNE: MSE=0.1448, MAE=0.1368, R2=0.9855\n",
      "LAZR: MSE=0.1643, MAE=0.2271, R2=0.9973\n",
      "AMWL: MSE=0.0810, MAE=0.1450, R2=0.9991\n",
      "GEO: MSE=0.0257, MAE=0.0937, R2=0.9956\n",
      "\n",
      "Evaluation results for Decision Tree Regression:\n",
      "SAVE: MSE=0.5780, MAE=0.4784, R2=0.9893\n",
      "CLNE: MSE=0.1542, MAE=0.1715, R2=0.9846\n",
      "LAZR: MSE=0.3103, MAE=0.2969, R2=0.9949\n",
      "AMWL: MSE=0.2338, MAE=0.2250, R2=0.9974\n",
      "GEO: MSE=0.0522, MAE=0.1315, R2=0.9910\n",
      "\n",
      "Evaluation results for KNN:\n",
      "SAVE: MSE=1.0971, MAE=0.7783, R2=0.9796\n",
      "CLNE: MSE=0.2948, MAE=0.3983, R2=0.9705\n",
      "LAZR: MSE=1.9196, MAE=0.9842, R2=0.9687\n",
      "AMWL: MSE=1.8166, MAE=0.9315, R2=0.9801\n",
      "GEO: MSE=0.1537, MAE=0.2703, R2=0.9736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('dataset.csv').dropna()\n",
    "tickers = ['SAVE', 'CLNE', 'LAZR', 'AMWL', 'GEO']\n",
    "\n",
    "# Initialize dictionaries to store evaluation results for each model\n",
    "evaluation_results = {'Linear Regression': [], 'Random Forest Regression': [], 'Decision Tree Regression': [], 'KNN': []}\n",
    "\n",
    "# Loop through each ticker\n",
    "for ticker in tickers:\n",
    "    # Filter data for the current ticker\n",
    "    ticker_df = df[df['level_0'] == ticker]\n",
    "    \n",
    "    # Extract features and target variable\n",
    "    X = ticker_df[['Open', 'High', 'Low', 'Close', 'Volume','Daily Returns','Volatility','RSI', '%K', '%D','Sentiment Score','Movement']].values\n",
    "    y = ticker_df['PreviousDayClose'].values\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define function to perform regression and evaluate the model\n",
    "    def perform_regression(model, X_train, X_test, y_train, y_test):\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        \n",
    "        return mse, mae, r2, predictions\n",
    "    \n",
    "    # Perform Linear Regression\n",
    "    lr_model = LinearRegression()\n",
    "    lr_mse, lr_mae, lr_r2, _ = perform_regression(lr_model, X_train, X_test, y_train, y_test)\n",
    "    evaluation_results['Linear Regression'].append((lr_mse, lr_mae, lr_r2))\n",
    "    \n",
    "    # Perform Random Forest Regression\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_mse, rf_mae, rf_r2, _ = perform_regression(rf_model, X_train, X_test, y_train, y_test)\n",
    "    evaluation_results['Random Forest Regression'].append((rf_mse, rf_mae, rf_r2))\n",
    "    \n",
    "    # Perform Decision Tree Regression\n",
    "    dt_model = DecisionTreeRegressor(random_state=42)\n",
    "    dt_mse, dt_mae, dt_r2, _ = perform_regression(dt_model, X_train, X_test, y_train, y_test)\n",
    "    evaluation_results['Decision Tree Regression'].append((dt_mse, dt_mae, dt_r2))\n",
    "    \n",
    "    # Perform KNN Regression\n",
    "    knn_model = KNeighborsRegressor()\n",
    "    knn_mse, knn_mae, knn_r2, _ = perform_regression(knn_model, X_train, X_test, y_train, y_test)\n",
    "    evaluation_results['KNN'].append((knn_mse, knn_mae, knn_r2))\n",
    "\n",
    "# Print evaluation results for each model\n",
    "for model, results in evaluation_results.items():\n",
    "    print(f'Evaluation results for {model}:')\n",
    "    for ticker, (mse, mae, r2) in zip(tickers, results):\n",
    "        print(f'{ticker}: MSE={mse:.4f}, MAE={mae:.4f}, R2={r2:.4f}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0241f5",
   "metadata": {},
   "source": [
    "CurrentDay Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14d70004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results for Linear Regression:\n",
      "SAVE: MSE=0.0477, MAE=0.1402, R2=0.9992\n",
      "CLNE: MSE=0.0157, MAE=0.0744, R2=0.9986\n",
      "LAZR: MSE=0.0925, MAE=0.1763, R2=0.9985\n",
      "AMWL: MSE=0.0548, MAE=0.1207, R2=0.9994\n",
      "GEO: MSE=0.0066, MAE=0.0506, R2=0.9988\n",
      "\n",
      "Evaluation results for Random Forest Regression:\n",
      "SAVE: MSE=0.1591, MAE=0.2223, R2=0.9972\n",
      "CLNE: MSE=0.0385, MAE=0.0999, R2=0.9965\n",
      "LAZR: MSE=0.1994, MAE=0.2053, R2=0.9967\n",
      "AMWL: MSE=0.0560, MAE=0.1288, R2=0.9994\n",
      "GEO: MSE=0.0205, MAE=0.0793, R2=0.9963\n",
      "\n",
      "Evaluation results for Decision Tree Regression:\n",
      "SAVE: MSE=0.2763, MAE=0.3198, R2=0.9951\n",
      "CLNE: MSE=0.0445, MAE=0.1197, R2=0.9959\n",
      "LAZR: MSE=0.3825, MAE=0.2995, R2=0.9937\n",
      "AMWL: MSE=0.1080, MAE=0.1811, R2=0.9988\n",
      "GEO: MSE=0.0389, MAE=0.1146, R2=0.9930\n",
      "\n",
      "Evaluation results for KNN:\n",
      "SAVE: MSE=1.2457, MAE=0.8183, R2=0.9778\n",
      "CLNE: MSE=0.4038, MAE=0.4218, R2=0.9630\n",
      "LAZR: MSE=2.2610, MAE=1.0695, R2=0.9628\n",
      "AMWL: MSE=1.8655, MAE=0.9772, R2=0.9788\n",
      "GEO: MSE=0.1492, MAE=0.2831, R2=0.9730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('dataset.csv').dropna()\n",
    "tickers = ['SAVE', 'CLNE', 'LAZR', 'AMWL', 'GEO']\n",
    "\n",
    "# Initialize dictionaries to store evaluation results for each model\n",
    "evaluation_results = {'Linear Regression': [], 'Random Forest Regression': [], 'Decision Tree Regression': [], 'KNN': []}\n",
    "\n",
    "# Loop through each ticker\n",
    "for ticker in tickers:\n",
    "    # Filter data for the current ticker\n",
    "    ticker_df = df[df['level_0'] == ticker]\n",
    "    \n",
    "    # Extract features and target variable\n",
    "    X = ticker_df[['Open', 'High', 'Low', 'Volume','Daily Returns','Volatility','RSI', '%K', '%D','Sentiment Score','Movement']].values\n",
    "    y = ticker_df['Close'].values\n",
    "    \n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Define function to perform regression and evaluate the model\n",
    "    def perform_regression(model, X_train, X_test, y_train, y_test):\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "        \n",
    "        return mse, mae, r2, predictions\n",
    "    \n",
    "    # Perform Linear Regression\n",
    "    lr_model = LinearRegression()\n",
    "    lr_mse, lr_mae, lr_r2, _ = perform_regression(lr_model, X_train, X_test, y_train, y_test)\n",
    "    evaluation_results['Linear Regression'].append((lr_mse, lr_mae, lr_r2))\n",
    "    \n",
    "    # Perform Random Forest Regression\n",
    "    rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf_mse, rf_mae, rf_r2, _ = perform_regression(rf_model, X_train, X_test, y_train, y_test)\n",
    "    evaluation_results['Random Forest Regression'].append((rf_mse, rf_mae, rf_r2))\n",
    "    \n",
    "    # Perform Decision Tree Regression\n",
    "    dt_model = DecisionTreeRegressor(random_state=42)\n",
    "    dt_mse, dt_mae, dt_r2, _ = perform_regression(dt_model, X_train, X_test, y_train, y_test)\n",
    "    evaluation_results['Decision Tree Regression'].append((dt_mse, dt_mae, dt_r2))\n",
    "    \n",
    "    # Perform KNN Regression\n",
    "    knn_model = KNeighborsRegressor()\n",
    "    knn_mse, knn_mae, knn_r2, _ = perform_regression(knn_model, X_train, X_test, y_train, y_test)\n",
    "    evaluation_results['KNN'].append((knn_mse, knn_mae, knn_r2))\n",
    "\n",
    "# Print evaluation results for each model\n",
    "for model, results in evaluation_results.items():\n",
    "    print(f'Evaluation results for {model}:')\n",
    "    for ticker, (mse, mae, r2) in zip(tickers, results):\n",
    "        print(f'{ticker}: MSE={mse:.4f}, MAE={mae:.4f}, R2={r2:.4f}')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582a058f",
   "metadata": {},
   "source": [
    "Cross Validation Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8b9aa9",
   "metadata": {},
   "source": [
    "NextDay Close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa1ea246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation for ticker: SAVE\n",
      "Fold 1:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 127ms/step - loss: 525.3286 - val_loss: 498.6476\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 386.7306 - val_loss: 268.5704\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 203.7726 - val_loss: 168.3932\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 141.4191 - val_loss: 131.7695\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 114.9071 - val_loss: 109.3108\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 96.4393 - val_loss: 93.5790\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 83.6086 - val_loss: 82.3150\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 74.4025 - val_loss: 73.9296\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 67.7759 - val_loss: 68.2059\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 62.2316 - val_loss: 63.7719\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 59.4339 - val_loss: 60.9778\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 58.7706 - val_loss: 58.8459\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 57.2797 - val_loss: 57.3931\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 55.7433 - val_loss: 56.3910\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 54.4965 - val_loss: 55.6595\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 55.0475 - val_loss: 55.1389\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 55.5073 - val_loss: 54.8703\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 53.5287 - val_loss: 54.4836\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 54.6680 - val_loss: 54.1028\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 52.2967 - val_loss: 53.5606\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 52.4436 - val_loss: 52.3829\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 50.2438 - val_loss: 49.3659\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 46.5826 - val_loss: 43.5582\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 40.7809 - val_loss: 36.3861\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 34.7221 - val_loss: 32.0049\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 31.8876 - val_loss: 28.5868\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 28.1759 - val_loss: 25.8631\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 26.6700 - val_loss: 23.4111\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 25.5245 - val_loss: 21.2758\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 22.8134 - val_loss: 19.9384\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 21.7662 - val_loss: 18.0370\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 20.0684 - val_loss: 16.7933\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 19.4716 - val_loss: 15.5374\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 17.7148 - val_loss: 14.3487\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 17.3972 - val_loss: 13.3880\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 17.1910 - val_loss: 12.5245\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 15.9429 - val_loss: 12.1401\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 14.6949 - val_loss: 10.9366\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 14.6555 - val_loss: 10.1503\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 13.7819 - val_loss: 9.4259\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 12.7242 - val_loss: 8.8512\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 12.4215 - val_loss: 8.3069\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 12.0316 - val_loss: 7.9819\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 11.2711 - val_loss: 7.5366\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 11.3892 - val_loss: 6.9195\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 10.9653 - val_loss: 6.6063\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 10.6255 - val_loss: 6.0215\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 10.0211 - val_loss: 5.6297\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 9.5173 - val_loss: 5.2736\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 9.2926 - val_loss: 4.9753\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 9.2782 - val_loss: 4.9709\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 8.5903 - val_loss: 4.5118\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 8.6179 - val_loss: 4.1827\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 8.4171 - val_loss: 3.9026\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 8.0851 - val_loss: 3.7941\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.6276 - val_loss: 3.5443\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.4173 - val_loss: 3.6390\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 8.0544 - val_loss: 3.7305\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 7.4331 - val_loss: 3.3280\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.4746 - val_loss: 2.8530\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.5784 - val_loss: 2.8470\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.9691 - val_loss: 2.5589\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.7106 - val_loss: 2.4125\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 6.5169 - val_loss: 2.2696\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.7603 - val_loss: 2.5637\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 7.3487 - val_loss: 2.1125\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.3981 - val_loss: 2.3707\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.0837 - val_loss: 2.0697\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.7143 - val_loss: 1.7690\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.8023 - val_loss: 1.7389\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.4785 - val_loss: 1.6506\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.8073 - val_loss: 1.5931\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.1977 - val_loss: 1.9179\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.6616 - val_loss: 1.5207\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.3108 - val_loss: 1.4384\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.0282 - val_loss: 1.8685\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.0583 - val_loss: 1.3791\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.0917 - val_loss: 1.3448\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.2137 - val_loss: 1.4699\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.4301 - val_loss: 1.2637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.2221 - val_loss: 1.3180\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.0760 - val_loss: 1.3689\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.6178 - val_loss: 1.7471\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.9106 - val_loss: 1.6596\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.5935 - val_loss: 1.1571\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.9391 - val_loss: 1.3733\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2643 - val_loss: 1.1643\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.0747 - val_loss: 1.3098\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2019 - val_loss: 1.1043\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2747 - val_loss: 1.1018\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.3630 - val_loss: 1.0639\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.4574 - val_loss: 1.0474\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.1072 - val_loss: 1.4547\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.4476 - val_loss: 0.9626\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5308 - val_loss: 0.9578\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.3770 - val_loss: 0.9584\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.4264 - val_loss: 0.9307\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.6176 - val_loss: 1.0594\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2144 - val_loss: 0.8834\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1520 - val_loss: 0.9537\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5177 - val_loss: 0.9961\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2299 - val_loss: 0.8895\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8741 - val_loss: 0.8561\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1856 - val_loss: 0.8723\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.4601 - val_loss: 0.8584\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9072 - val_loss: 0.8947\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1028 - val_loss: 0.8440\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2363 - val_loss: 0.9307\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8584 - val_loss: 0.7877\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1047 - val_loss: 0.7876\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5241 - val_loss: 0.8677\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1194 - val_loss: 0.7987\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9501 - val_loss: 0.8490\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7642 - val_loss: 0.9442\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.4068 - val_loss: 0.7796\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0941 - val_loss: 0.7906\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5090 - val_loss: 0.7298\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2294 - val_loss: 0.8511\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1280 - val_loss: 0.7687\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7739 - val_loss: 1.0147\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8409 - val_loss: 0.7852\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7344 - val_loss: 0.7360\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9442 - val_loss: 0.7283\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9192 - val_loss: 0.7532\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8059 - val_loss: 0.9683\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1246 - val_loss: 0.7935\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6760 - val_loss: 0.7710\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2944 - val_loss: 0.7018\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9472 - val_loss: 0.7777\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6817 - val_loss: 0.6629\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8184 - val_loss: 0.8370\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2624 - val_loss: 0.7366\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5242 - val_loss: 0.6595\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7651 - val_loss: 0.7001\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6147 - val_loss: 1.5264\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6541 - val_loss: 0.6372\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4868 - val_loss: 0.6498\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4429 - val_loss: 0.7191\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8098 - val_loss: 0.6715\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8365 - val_loss: 1.0574\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8392 - val_loss: 0.8224\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1740 - val_loss: 0.7860\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.2743 - val_loss: 0.6983\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8803 - val_loss: 0.7113\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8978 - val_loss: 0.7823\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7960 - val_loss: 0.6030\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8573 - val_loss: 1.1406\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9633 - val_loss: 0.5808\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1843 - val_loss: 0.7162\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8281 - val_loss: 0.5772\n",
      "7/7 [==============================] - 2s 6ms/step\n",
      "Mean Squared Error: 0.5772151692883778\n",
      "Mean Absolute Error: 0.5325750758991906\n",
      "R-squared: 0.9894741000832314\n",
      "\n",
      "Fold 2:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 14s 106ms/step - loss: 520.6387 - val_loss: 518.7242\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 376.5187 - val_loss: 264.6375\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 177.8468 - val_loss: 156.6777\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 118.1993 - val_loss: 122.9340\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 95.6280 - val_loss: 103.5049\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 82.6024 - val_loss: 90.1043\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 71.0926 - val_loss: 80.5437\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 64.1582 - val_loss: 73.9812\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 59.6519 - val_loss: 69.2250\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 55.8187 - val_loss: 66.2432\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 55.6051 - val_loss: 64.2249\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 55.9460 - val_loss: 62.8663\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 55.1334 - val_loss: 61.7422\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 52.5920 - val_loss: 60.9383\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 52.1480 - val_loss: 60.4328\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 53.5170 - val_loss: 59.9713\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 52.9244 - val_loss: 59.5277\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 52.3762 - val_loss: 59.0039\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 51.6634 - val_loss: 58.2423\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 49.5067 - val_loss: 55.8180\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 45.6125 - val_loss: 49.7922\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 39.6429 - val_loss: 41.8710\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 34.5219 - val_loss: 36.8253\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 30.2516 - val_loss: 33.0839\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 27.6579 - val_loss: 30.4901\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 26.1973 - val_loss: 27.6974\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 24.3492 - val_loss: 25.3314\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 22.9136 - val_loss: 23.4591\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 21.1715 - val_loss: 21.9998\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 19.7834 - val_loss: 20.6457\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 17.9458 - val_loss: 18.9159\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 17.6320 - val_loss: 17.7460\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 17.6564 - val_loss: 16.8561\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 15.3933 - val_loss: 15.7390\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 14.2665 - val_loss: 15.6595\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 14.0733 - val_loss: 13.9974\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 14.4289 - val_loss: 13.2060\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 12.6873 - val_loss: 12.5239\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 12.4894 - val_loss: 11.5646\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 12.8610 - val_loss: 10.8528\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 12.2765 - val_loss: 10.0924\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 11.7104 - val_loss: 9.4483\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 10.8936 - val_loss: 8.8979\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 10.4855 - val_loss: 8.3928\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 9.8148 - val_loss: 7.8869\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 10.0487 - val_loss: 7.7808\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.9352 - val_loss: 7.4274\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.9338 - val_loss: 7.0657\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 8.2374 - val_loss: 6.1520\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 8.4414 - val_loss: 5.7741\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.4655 - val_loss: 6.1979\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.2032 - val_loss: 5.0761\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 7.7128 - val_loss: 4.8587\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.2007 - val_loss: 4.5573\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.2100 - val_loss: 4.3180\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 7.2314 - val_loss: 4.0585\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.7021 - val_loss: 3.9990\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.0574 - val_loss: 4.2958\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.3849 - val_loss: 3.6428\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.4204 - val_loss: 3.3384\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.3609 - val_loss: 3.0894\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.5547 - val_loss: 3.1832\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.9779 - val_loss: 2.7639\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.2818 - val_loss: 2.7700\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.1971 - val_loss: 2.5348\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.2271 - val_loss: 2.5800\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.7199 - val_loss: 2.3239\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.6482 - val_loss: 2.6318\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.4961 - val_loss: 2.1555\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.1993 - val_loss: 2.1002\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.3989 - val_loss: 2.0299\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.7445 - val_loss: 2.2792\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.2431 - val_loss: 1.9437\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.8548 - val_loss: 1.9418\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8503 - val_loss: 2.0037\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.0913 - val_loss: 1.7927\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.5495 - val_loss: 1.8029\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6972 - val_loss: 1.6951\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.1115 - val_loss: 1.6536\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.6622 - val_loss: 1.7583\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8953 - val_loss: 1.6274\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8144 - val_loss: 1.6454\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6924 - val_loss: 1.5077\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.3403 - val_loss: 1.5305\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5760 - val_loss: 1.5678\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.1715 - val_loss: 1.4390\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6993 - val_loss: 1.4236\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.7039 - val_loss: 1.4668\n",
      "Epoch 89/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8082 - val_loss: 1.3521\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.0157 - val_loss: 1.3225\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1864 - val_loss: 1.3583\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9394 - val_loss: 1.3054\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5155 - val_loss: 1.3694\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.4909 - val_loss: 1.2251\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.7364 - val_loss: 1.4275\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2996 - val_loss: 1.2727\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2331 - val_loss: 1.2509\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2451 - val_loss: 1.3326\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0755 - val_loss: 1.1719\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.7973 - val_loss: 1.1499\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2950 - val_loss: 1.2333\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7909 - val_loss: 1.0753\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.4491 - val_loss: 1.0969\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.9419 - val_loss: 1.0723\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1169 - val_loss: 1.0453\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9956 - val_loss: 1.0256\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0326 - val_loss: 1.0634\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.0282 - val_loss: 1.0238\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8225 - val_loss: 1.2423\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0830 - val_loss: 1.0183\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7063 - val_loss: 1.0148\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0131 - val_loss: 1.0066\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0276 - val_loss: 1.2768\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0448 - val_loss: 1.1875\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6909 - val_loss: 1.0460\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.0623 - val_loss: 1.0107\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8054 - val_loss: 1.0089\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9119 - val_loss: 1.0055\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2653 - val_loss: 0.9960\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.6684 - val_loss: 0.9054\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5917 - val_loss: 1.1629\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7038 - val_loss: 0.9919\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8547 - val_loss: 0.8931\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2105 - val_loss: 0.9628\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.8734 - val_loss: 0.8357\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7779 - val_loss: 0.8301\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7258 - val_loss: 0.8995\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6115 - val_loss: 1.0150\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9016 - val_loss: 0.9341\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1918 - val_loss: 0.9107\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5128 - val_loss: 0.7691\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.6046 - val_loss: 1.0345\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.7070 - val_loss: 0.8367\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1137 - val_loss: 0.8636\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8540 - val_loss: 0.8045\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4433 - val_loss: 0.8245\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9241 - val_loss: 1.1235\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.1405 - val_loss: 0.7489\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.6142 - val_loss: 0.8934\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.4443 - val_loss: 0.7709\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1780 - val_loss: 0.8348\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.7630 - val_loss: 0.7490\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1638 - val_loss: 0.7319\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.9215 - val_loss: 0.8930\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8150 - val_loss: 0.7220\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9009 - val_loss: 0.7899\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7943 - val_loss: 0.8431\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6377 - val_loss: 0.7604\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1037 - val_loss: 0.9598\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9653 - val_loss: 0.8826\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.8825510512869824\n",
      "Mean Absolute Error: 0.664687294272048\n",
      "R-squared: 0.985203995595152\n",
      "\n",
      "Fold 3:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 106ms/step - loss: 526.6641 - val_loss: 503.8177\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 388.1661 - val_loss: 270.3978\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 196.4179 - val_loss: 159.9331\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 133.9259 - val_loss: 123.7917\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 107.6899 - val_loss: 103.0429\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 91.3823 - val_loss: 88.4840\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 80.4469 - val_loss: 77.9135\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 70.9411 - val_loss: 70.7150\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 64.9964 - val_loss: 65.4836\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 60.6332 - val_loss: 61.9790\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 58.4628 - val_loss: 59.5633\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 56.2804 - val_loss: 57.7360\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 56.9042 - val_loss: 56.6531\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 55.2929 - val_loss: 55.9354\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 53.7569 - val_loss: 55.3378\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 54.8508 - val_loss: 54.8006\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 54.2751 - val_loss: 54.3498\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 53.2273 - val_loss: 53.9273\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 54.2322 - val_loss: 53.3122\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 53.5256 - val_loss: 52.2243\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 51.4092 - val_loss: 50.1156\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 49.4015 - val_loss: 45.5610\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 42.7043 - val_loss: 39.1531\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 37.6401 - val_loss: 32.4236\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 31.6408 - val_loss: 28.9134\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 29.5418 - val_loss: 26.5159\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 26.6279 - val_loss: 23.5886\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 24.9552 - val_loss: 21.6663\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 22.5174 - val_loss: 19.8368\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 21.9237 - val_loss: 18.4017\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 20.3728 - val_loss: 17.2371\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 19.1626 - val_loss: 16.1645\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 18.1533 - val_loss: 14.7726\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 18.0659 - val_loss: 13.8325\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 16.7462 - val_loss: 12.9037\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 14.9765 - val_loss: 12.1391\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 14.8945 - val_loss: 11.3487\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 14.3323 - val_loss: 10.6626\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 13.1068 - val_loss: 10.3004\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 14.0868 - val_loss: 9.4863\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 13.0030 - val_loss: 8.9453\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 11.2587 - val_loss: 8.3676\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 11.7886 - val_loss: 7.9575\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 10.1409 - val_loss: 8.1201\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 10.8758 - val_loss: 7.0187\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 10.1080 - val_loss: 6.7011\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 9.9496 - val_loss: 6.3005\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 10.0669 - val_loss: 5.9329\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.3727 - val_loss: 5.6924\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.9294 - val_loss: 5.2419\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 9.2128 - val_loss: 5.2345\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 8.0510 - val_loss: 4.6746\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 8.1358 - val_loss: 4.4982\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.7109 - val_loss: 4.3745\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.0354 - val_loss: 4.1298\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.5250 - val_loss: 4.0225\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.9325 - val_loss: 3.6127\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 7.4477 - val_loss: 5.1849\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.3358 - val_loss: 3.4928\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.5763 - val_loss: 3.1898\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.7928 - val_loss: 3.0290\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.8691 - val_loss: 3.4885\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.3466 - val_loss: 3.0398\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.7853 - val_loss: 2.6659\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.5560 - val_loss: 2.5391\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.7418 - val_loss: 2.4576\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.0058 - val_loss: 2.4059\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.2808 - val_loss: 2.3775\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.9785 - val_loss: 2.2847\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.7201 - val_loss: 2.1808\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.5144 - val_loss: 2.0707\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.4042 - val_loss: 2.0086\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.5747 - val_loss: 1.9779\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.0275 - val_loss: 1.9616\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.3949 - val_loss: 1.9260\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.6248 - val_loss: 1.7471\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6204 - val_loss: 1.6885\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.7913 - val_loss: 1.7009\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.0558 - val_loss: 1.7523\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8575 - val_loss: 1.6946\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.9014 - val_loss: 1.9246\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6260 - val_loss: 1.6301\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8118 - val_loss: 1.4856\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5033 - val_loss: 1.4323\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6492 - val_loss: 1.4468\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6819 - val_loss: 1.4462\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6380 - val_loss: 1.3228\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.4413 - val_loss: 1.3531\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5424 - val_loss: 1.3123\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0179 - val_loss: 1.3380\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.4650 - val_loss: 1.3380\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.4998 - val_loss: 1.2487\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0686 - val_loss: 1.3851\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.4442 - val_loss: 1.4009\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.0699 - val_loss: 1.3411\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1375 - val_loss: 1.2153\n",
      "Epoch 97/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8804 - val_loss: 1.1285\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.3212 - val_loss: 1.8485\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.2493 - val_loss: 1.0837\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5771 - val_loss: 1.1636\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8037 - val_loss: 1.4699\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9805 - val_loss: 1.1083\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1455 - val_loss: 1.0194\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.4964 - val_loss: 0.9931\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.7092 - val_loss: 0.9668\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5026 - val_loss: 1.0637\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2669 - val_loss: 1.3754\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.3237 - val_loss: 1.0032\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9782 - val_loss: 1.0117\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8799 - val_loss: 0.9327\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.3658 - val_loss: 0.9216\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1396 - val_loss: 0.9801\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.9673 - val_loss: 0.8748\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2579 - val_loss: 0.8851\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9897 - val_loss: 0.8196\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5858 - val_loss: 0.8132\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7130 - val_loss: 0.9444\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0311 - val_loss: 0.7985\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0773 - val_loss: 0.8408\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.4025 - val_loss: 0.7908\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1545 - val_loss: 0.8139\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7998 - val_loss: 0.9120\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0913 - val_loss: 0.7430\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9894 - val_loss: 0.7513\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8374 - val_loss: 0.8053\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8397 - val_loss: 0.7003\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9761 - val_loss: 0.7970\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7932 - val_loss: 0.8112\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5583 - val_loss: 0.8301\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0918 - val_loss: 0.6820\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7452 - val_loss: 0.7852\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.4624 - val_loss: 0.7390\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4112 - val_loss: 0.7184\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4817 - val_loss: 0.7994\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7314 - val_loss: 0.7483\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8845 - val_loss: 0.9002\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1766 - val_loss: 0.7059\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2695 - val_loss: 0.7069\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5675 - val_loss: 0.6592\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7770 - val_loss: 0.6891\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7267 - val_loss: 0.7352\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6329 - val_loss: 0.7309\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0402 - val_loss: 0.6452\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8978 - val_loss: 0.6564\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.6807 - val_loss: 0.6425\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6538 - val_loss: 0.9257\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5411 - val_loss: 0.6725\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0721 - val_loss: 0.6648\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2985 - val_loss: 0.5799\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9304 - val_loss: 0.6450\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.6450258906087583\n",
      "Mean Absolute Error: 0.5233894319676641\n",
      "R-squared: 0.9882168809259249\n",
      "\n",
      "Fold 4:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 133ms/step - loss: 541.7918 - val_loss: 445.7353\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 399.0621 - val_loss: 218.6586\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 194.6708 - val_loss: 117.3491\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 133.0232 - val_loss: 87.5590\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 106.2843 - val_loss: 71.4449\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 91.0806 - val_loss: 60.9521\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 79.8289 - val_loss: 53.7424\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 73.5654 - val_loss: 49.0219\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 68.1171 - val_loss: 46.0258\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 61.8698 - val_loss: 44.3539\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 61.5305 - val_loss: 43.3936\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 56.4770 - val_loss: 42.8642\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 58.7726 - val_loss: 42.6489\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 58.5707 - val_loss: 42.5582\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 55.7617 - val_loss: 42.5141\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 56.2113 - val_loss: 42.2944\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 56.1576 - val_loss: 41.9672\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 54.9073 - val_loss: 41.1748\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 54.2422 - val_loss: 39.4577\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 52.3037 - val_loss: 34.4295\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 45.4507 - val_loss: 27.1766\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 39.8750 - val_loss: 22.6534\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 35.7734 - val_loss: 19.2609\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 31.2537 - val_loss: 17.0067\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 29.0633 - val_loss: 15.5801\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 26.2789 - val_loss: 13.8755\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 23.7972 - val_loss: 12.8302\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 23.9346 - val_loss: 11.5522\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 21.3717 - val_loss: 10.7075\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 20.0426 - val_loss: 10.0072\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 19.4230 - val_loss: 9.2648\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 18.0822 - val_loss: 8.5463\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 17.6977 - val_loss: 8.0430\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 15.8742 - val_loss: 7.3785\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 16.6007 - val_loss: 6.9404\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 14.7236 - val_loss: 6.5034\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 15.6951 - val_loss: 6.1164\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 13.6277 - val_loss: 5.5843\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 12.9853 - val_loss: 5.2944\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 12.9570 - val_loss: 5.2498\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 12.5422 - val_loss: 4.6341\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 11.3591 - val_loss: 4.3264\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 10.8635 - val_loss: 4.0823\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 11.2816 - val_loss: 3.7460\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 10.4223 - val_loss: 3.8698\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 9.2385 - val_loss: 3.3829\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.4902 - val_loss: 3.1581\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 10.1065 - val_loss: 3.0241\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.9318 - val_loss: 3.4978\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.4055 - val_loss: 2.6762\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.4703 - val_loss: 2.5796\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 9.1666 - val_loss: 2.3809\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.8504 - val_loss: 2.3825\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.9805 - val_loss: 2.1152\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.8787 - val_loss: 2.0308\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.2238 - val_loss: 1.9781\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.1066 - val_loss: 2.0978\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.0456 - val_loss: 2.2216\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.1040 - val_loss: 1.8720\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.4893 - val_loss: 1.6407\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.8066 - val_loss: 1.7489\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.5879 - val_loss: 1.6905\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.1225 - val_loss: 1.4821\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.0563 - val_loss: 1.5439\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.0631 - val_loss: 1.5182\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.4233 - val_loss: 1.3979\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.0174 - val_loss: 1.3759\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 5.6366 - val_loss: 1.3421\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.4707 - val_loss: 1.4369\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.1782 - val_loss: 1.2942\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.7164 - val_loss: 1.3193\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.9640 - val_loss: 1.4188\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.9617 - val_loss: 1.1510\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.2125 - val_loss: 1.3253\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.6959 - val_loss: 1.1726\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.1415 - val_loss: 1.2368\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.1000 - val_loss: 1.2493\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.0807 - val_loss: 1.2794\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.5387 - val_loss: 1.1757\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.8634 - val_loss: 1.0989\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.5333 - val_loss: 1.0927\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 4.5177 - val_loss: 1.1225\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.9974 - val_loss: 1.0727\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.7758 - val_loss: 1.0795\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.1173 - val_loss: 1.0912\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.0656 - val_loss: 1.0275\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.8375 - val_loss: 1.2215\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.7856 - val_loss: 1.0512\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 5.1607 - val_loss: 1.3290\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.7568 - val_loss: 1.0061\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.3071 - val_loss: 1.0109\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.9331 - val_loss: 0.9983\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.6224 - val_loss: 0.9990\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.1222 - val_loss: 0.9507\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.1700 - val_loss: 0.9279\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 4.8365 - val_loss: 0.9272\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.7239 - val_loss: 1.3443\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.3898 - val_loss: 0.9780\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.5409 - val_loss: 0.9216\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.4104 - val_loss: 0.9235\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.4003 - val_loss: 0.8883\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.8394 - val_loss: 1.1489\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.4949 - val_loss: 0.8595\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.0909 - val_loss: 0.8734\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.7811 - val_loss: 1.5762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 4.6771 - val_loss: 0.8497\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.5145 - val_loss: 0.9592\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 4.7287 - val_loss: 0.8064\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.6997 - val_loss: 0.9421\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.2441 - val_loss: 0.8061\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.5292 - val_loss: 0.9653\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.1248 - val_loss: 0.7548\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.9655 - val_loss: 0.9659\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.9803 - val_loss: 0.7702\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.2717 - val_loss: 0.8386\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.8976 - val_loss: 0.7450\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.7858 - val_loss: 0.8314\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.2214 - val_loss: 0.8240\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.3674 - val_loss: 0.7581\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.3089 - val_loss: 0.9362\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.2961 - val_loss: 1.0811\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 4.0283 - val_loss: 0.7504\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.1888 - val_loss: 0.8583\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.7721 - val_loss: 0.7674\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.1429 - val_loss: 0.9517\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.2270 - val_loss: 0.7500\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.9811 - val_loss: 0.7292\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.9157 - val_loss: 0.6997\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.3601 - val_loss: 0.7337\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.8766 - val_loss: 0.7661\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.0065 - val_loss: 0.7980\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.8433 - val_loss: 0.8188\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 3.9769 - val_loss: 1.0200\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.6523 - val_loss: 0.7408\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2374 - val_loss: 0.7710\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.8613 - val_loss: 0.8129\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.0727 - val_loss: 0.7192\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.1226 - val_loss: 0.8112\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.4887 - val_loss: 0.7761\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.5225 - val_loss: 0.7577\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.7551 - val_loss: 0.9888\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.4361 - val_loss: 0.6816\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7318 - val_loss: 0.6635\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.9501 - val_loss: 0.6914\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.4040 - val_loss: 0.6481\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.5550 - val_loss: 0.7797\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.9990 - val_loss: 0.7610\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.7493 - val_loss: 0.7602\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.0611 - val_loss: 0.6323\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0159 - val_loss: 0.6206\n",
      "7/7 [==============================] - 2s 6ms/step\n",
      "Mean Squared Error: 0.6205808923365763\n",
      "Mean Absolute Error: 0.518745166152271\n",
      "R-squared: 0.9856881044035868\n",
      "\n",
      "Fold 5:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 16s 117ms/step - loss: 532.0048 - val_loss: 473.9452\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 388.7588 - val_loss: 236.1502\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 187.4094 - val_loss: 134.3342\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 127.6813 - val_loss: 101.8146\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 101.3450 - val_loss: 83.6938\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 87.0006 - val_loss: 71.8986\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 75.3582 - val_loss: 64.0231\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 68.4652 - val_loss: 58.4820\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 63.8945 - val_loss: 54.8235\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 61.3750 - val_loss: 52.6649\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 59.2033 - val_loss: 51.1066\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 56.1431 - val_loss: 50.3816\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 57.0205 - val_loss: 49.9663\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 56.4419 - val_loss: 49.6429\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 57.2976 - val_loss: 49.4743\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 55.6529 - val_loss: 49.2918\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 56.3971 - val_loss: 49.0794\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 52.6137 - val_loss: 48.7575\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 52.8195 - val_loss: 48.1314\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 53.3006 - val_loss: 47.0187\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 52.0089 - val_loss: 44.5657\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 48.1310 - val_loss: 38.7217\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 43.6904 - val_loss: 31.8555\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 35.5776 - val_loss: 27.0665\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 30.4796 - val_loss: 24.8532\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 29.1262 - val_loss: 22.8175\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 25.2131 - val_loss: 20.0520\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 25.4066 - val_loss: 18.2742\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 21.6843 - val_loss: 16.7509\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 20.2989 - val_loss: 15.6992\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 19.6153 - val_loss: 14.5340\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 19.1185 - val_loss: 13.9282\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 18.1796 - val_loss: 12.8605\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 16.7733 - val_loss: 11.9800\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 15.2182 - val_loss: 11.2313\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 15.0166 - val_loss: 10.9278\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 13.8781 - val_loss: 10.0860\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 13.5239 - val_loss: 9.3148\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 12.8204 - val_loss: 8.9928\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 12.8852 - val_loss: 8.3033\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 12.2426 - val_loss: 8.0836\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 11.2062 - val_loss: 7.4518\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 11.0912 - val_loss: 7.2865\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 10.6344 - val_loss: 6.7633\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 10.0786 - val_loss: 6.3284\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 10.2026 - val_loss: 6.0193\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 9.3620 - val_loss: 5.6994\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 9.2238 - val_loss: 5.4693\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 9.0449 - val_loss: 5.2580\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 9.6428 - val_loss: 4.7375\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 8.3786 - val_loss: 4.6323\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.5498 - val_loss: 4.6006\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 7.8879 - val_loss: 4.1129\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.5872 - val_loss: 3.8887\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 7.4028 - val_loss: 3.6668\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 6.9582 - val_loss: 3.5254\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.0996 - val_loss: 3.4089\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 6.8164 - val_loss: 3.1943\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.0155 - val_loss: 3.0440\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.6074 - val_loss: 2.9160\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.7811 - val_loss: 3.0017\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.8339 - val_loss: 2.6706\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 6.5220 - val_loss: 2.7627\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.4033 - val_loss: 2.4500\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.8716 - val_loss: 2.4333\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.9340 - val_loss: 2.3579\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.5932 - val_loss: 2.2771\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 5.4215 - val_loss: 2.1893\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.0231 - val_loss: 2.0889\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.7327 - val_loss: 2.1063\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.1585 - val_loss: 2.1876\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.8521 - val_loss: 2.1779\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 5.4284 - val_loss: 2.0007\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.1251 - val_loss: 1.8318\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.4304 - val_loss: 1.9257\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.7754 - val_loss: 1.8168\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.4249 - val_loss: 1.7034\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.0694 - val_loss: 1.7506\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.1875 - val_loss: 1.6903\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.8788 - val_loss: 1.6065\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.7273 - val_loss: 1.6647\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.1899 - val_loss: 1.5410\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.9020 - val_loss: 1.5033\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.9603 - val_loss: 1.5118\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.9273 - val_loss: 1.5678\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.7788 - val_loss: 1.4688\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.0832 - val_loss: 1.5122\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.8038 - val_loss: 1.3981\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5610 - val_loss: 1.4192\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5477 - val_loss: 1.3664\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.3774 - val_loss: 1.7411\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.3237 - val_loss: 1.3348\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.7197 - val_loss: 1.3110\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.8671 - val_loss: 1.4119\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.8756 - val_loss: 1.3097\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1654 - val_loss: 1.4473\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.0158 - val_loss: 1.3109\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1232 - val_loss: 1.3280\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.2708 - val_loss: 1.1881\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.6918 - val_loss: 1.2006\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1064 - val_loss: 1.1907\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.4047 - val_loss: 1.2963\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.4792 - val_loss: 1.5306\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.1136 - val_loss: 1.1377\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1327 - val_loss: 1.1342\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.2350 - val_loss: 1.1219\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1547 - val_loss: 1.2094\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.5726 - val_loss: 1.3723\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.0764 - val_loss: 1.1369\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7511 - val_loss: 1.1727\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1709 - val_loss: 1.1101\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.3471 - val_loss: 1.0307\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1248 - val_loss: 1.0250\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.9016 - val_loss: 1.0646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.0573 - val_loss: 1.3532\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.4299 - val_loss: 1.0670\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.9585 - val_loss: 1.1168\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7627 - val_loss: 0.9827\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.2245 - val_loss: 1.1652\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.3376 - val_loss: 0.9915\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.2249 - val_loss: 1.3692\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1826 - val_loss: 0.9579\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.3734 - val_loss: 0.9331\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.8595 - val_loss: 0.9112\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.8571 - val_loss: 1.0146\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1369 - val_loss: 0.9354\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7756 - val_loss: 0.9142\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.4071 - val_loss: 0.9987\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.9886 - val_loss: 0.9066\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1201 - val_loss: 0.9455\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1424 - val_loss: 1.0464\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.9376 - val_loss: 0.8998\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.5248 - val_loss: 0.9108\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.8223 - val_loss: 0.8705\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.8004 - val_loss: 0.8934\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8757 - val_loss: 1.0560\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.9697 - val_loss: 0.9257\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7430 - val_loss: 0.9491\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.9871 - val_loss: 0.8664\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.8529 - val_loss: 0.9625\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.2572 - val_loss: 0.8176\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.9061 - val_loss: 0.9490\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7640 - val_loss: 0.8470\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.9343 - val_loss: 0.8284\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.0151 - val_loss: 0.8109\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.6160 - val_loss: 0.8134\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.8299 - val_loss: 1.0679\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7428 - val_loss: 0.8291\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1708 - val_loss: 1.0810\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.5469 - val_loss: 0.7830\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.7829856066098556\n",
      "Mean Absolute Error: 0.582917849222819\n",
      "R-squared: 0.9843398251665532\n",
      "\n",
      "Average scores for ticker SAVE:\n",
      "Mean Squared Error: 0.7016717220261102\n",
      "Mean Absolute Error: 0.5644629635027985\n",
      "R-squared: 0.9865845812348896\n",
      "\n",
      "Cross-validation for ticker: CLNE\n",
      "Fold 1:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 105ms/step - loss: 36.8658 - val_loss: 34.3240\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 15.3626 - val_loss: 7.6579\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.6071 - val_loss: 6.8825\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.3017 - val_loss: 4.9792\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.4433 - val_loss: 2.7131\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.9923 - val_loss: 1.2075\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.3344 - val_loss: 0.8257\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0899 - val_loss: 0.6935\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9737 - val_loss: 0.6192\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0465 - val_loss: 0.5735\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9021 - val_loss: 0.5362\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.9022 - val_loss: 0.5175\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9515 - val_loss: 0.5237\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9399 - val_loss: 0.4649\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8160 - val_loss: 0.4199\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.8211 - val_loss: 0.3891\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8418 - val_loss: 0.3662\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7458 - val_loss: 0.3483\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7479 - val_loss: 0.3427\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6697 - val_loss: 0.3187\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6940 - val_loss: 0.3531\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7328 - val_loss: 0.2955\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6419 - val_loss: 0.2882\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8216 - val_loss: 0.2727\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6714 - val_loss: 0.2622\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6335 - val_loss: 0.2569\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5890 - val_loss: 0.2991\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5800 - val_loss: 0.2435\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6005 - val_loss: 0.2265\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6173 - val_loss: 0.2295\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5665 - val_loss: 0.2522\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5976 - val_loss: 0.2622\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5719 - val_loss: 0.2045\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6292 - val_loss: 0.2404\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5780 - val_loss: 0.2074\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5661 - val_loss: 0.2266\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5666 - val_loss: 0.1927\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5288 - val_loss: 0.2430\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5116 - val_loss: 0.2000\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5619 - val_loss: 0.2099\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5280 - val_loss: 0.1920\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6485 - val_loss: 0.1782\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5350 - val_loss: 0.1590\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4729 - val_loss: 0.1858\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5172 - val_loss: 0.2164\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5796 - val_loss: 0.1539\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5372 - val_loss: 0.1738\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5060 - val_loss: 0.1519\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4633 - val_loss: 0.1678\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5078 - val_loss: 0.1711\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5070 - val_loss: 0.1560\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5312 - val_loss: 0.1704\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4677 - val_loss: 0.1483\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5031 - val_loss: 0.1450\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4414 - val_loss: 0.1569\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4574 - val_loss: 0.1544\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4663 - val_loss: 0.1543\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4894 - val_loss: 0.1538\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4232 - val_loss: 0.1408\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4692 - val_loss: 0.1424\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4566 - val_loss: 0.1344\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4120 - val_loss: 0.1519\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4865 - val_loss: 0.1399\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5144 - val_loss: 0.1344\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5114 - val_loss: 0.1553\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4111 - val_loss: 0.1322\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4265 - val_loss: 0.1361\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4283 - val_loss: 0.1347\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4139 - val_loss: 0.1279\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4600 - val_loss: 0.1260\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4600 - val_loss: 0.1353\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3922 - val_loss: 0.1249\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4359 - val_loss: 0.1826\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4640 - val_loss: 0.1398\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4157 - val_loss: 0.1259\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4328 - val_loss: 0.1348\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4362 - val_loss: 0.1364\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4628 - val_loss: 0.1214\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4124 - val_loss: 0.1206\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4466 - val_loss: 0.1468\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3848 - val_loss: 0.1458\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4743 - val_loss: 0.1805\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4867 - val_loss: 0.1250\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4855 - val_loss: 0.1307\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4113 - val_loss: 0.1176\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4672 - val_loss: 0.1219\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3909 - val_loss: 0.1187\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4130 - val_loss: 0.1387\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4551 - val_loss: 0.1388\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3942 - val_loss: 0.1524\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3949 - val_loss: 0.1233\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3615 - val_loss: 0.1143\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4754 - val_loss: 0.1209\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4053 - val_loss: 0.1329\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4475 - val_loss: 0.1056\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4586 - val_loss: 0.1198\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3531 - val_loss: 0.1413\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4113 - val_loss: 0.1185\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3735 - val_loss: 0.1658\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3857 - val_loss: 0.1189\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4149 - val_loss: 0.1060\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3725 - val_loss: 0.1031\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4066 - val_loss: 0.1033\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4188 - val_loss: 0.0976\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4054 - val_loss: 0.0968\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4303 - val_loss: 0.1027\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3386 - val_loss: 0.0977\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4027 - val_loss: 0.0958\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.4133 - val_loss: 0.0989\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3860 - val_loss: 0.1098\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4256 - val_loss: 0.1003\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3863 - val_loss: 0.1023\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4102 - val_loss: 0.0913\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4011 - val_loss: 0.0927\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3825 - val_loss: 0.1095\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3986 - val_loss: 0.1081\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3555 - val_loss: 0.1167\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3978 - val_loss: 0.0984\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3755 - val_loss: 0.0855\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3753 - val_loss: 0.0850\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3903 - val_loss: 0.1145\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3967 - val_loss: 0.1098\n",
      "Epoch 123/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4045 - val_loss: 0.0877\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3511 - val_loss: 0.0857\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3115 - val_loss: 0.0965\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3864 - val_loss: 0.0996\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3936 - val_loss: 0.1016\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3936 - val_loss: 0.0840\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4235 - val_loss: 0.1176\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4060 - val_loss: 0.0820\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3916 - val_loss: 0.0939\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3589 - val_loss: 0.1037\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4142 - val_loss: 0.0780\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3848 - val_loss: 0.0869\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3964 - val_loss: 0.0798\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3466 - val_loss: 0.1188\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3833 - val_loss: 0.0936\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3734 - val_loss: 0.0861\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3181 - val_loss: 0.1176\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3918 - val_loss: 0.0835\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3620 - val_loss: 0.0922\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3642 - val_loss: 0.0801\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3685 - val_loss: 0.0728\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3188 - val_loss: 0.0896\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3099 - val_loss: 0.1080\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3668 - val_loss: 0.0759\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3770 - val_loss: 0.1118\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3738 - val_loss: 0.0855\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3563 - val_loss: 0.0753\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3383 - val_loss: 0.0924\n",
      "7/7 [==============================] - 2s 6ms/step\n",
      "Mean Squared Error: 0.0923796663531741\n",
      "Mean Absolute Error: 0.20051919642965596\n",
      "R-squared: 0.9914198991297526\n",
      "\n",
      "Fold 2:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 107ms/step - loss: 38.9234 - val_loss: 32.0968\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 18.4454 - val_loss: 7.7562\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.1130 - val_loss: 7.0424\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.2655 - val_loss: 5.7699\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.8295 - val_loss: 3.7638\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 2.9143 - val_loss: 1.7240\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.7312 - val_loss: 0.8830\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.2052 - val_loss: 0.6855\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.2497 - val_loss: 0.6008\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1647 - val_loss: 0.5642\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1427 - val_loss: 0.4814\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9745 - val_loss: 0.4433\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0872 - val_loss: 0.4054\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9776 - val_loss: 0.3761\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0036 - val_loss: 0.3497\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8436 - val_loss: 0.3399\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7741 - val_loss: 0.3343\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9342 - val_loss: 0.2897\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9223 - val_loss: 0.2803\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7410 - val_loss: 0.2437\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8123 - val_loss: 0.2486\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7331 - val_loss: 0.2242\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7953 - val_loss: 0.2098\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6858 - val_loss: 0.1958\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7263 - val_loss: 0.2199\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6826 - val_loss: 0.1829\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7010 - val_loss: 0.1954\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7297 - val_loss: 0.1741\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6464 - val_loss: 0.1787\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7197 - val_loss: 0.1593\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6841 - val_loss: 0.1554\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5463 - val_loss: 0.1468\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6283 - val_loss: 0.1396\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6333 - val_loss: 0.1346\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6242 - val_loss: 0.1627\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5558 - val_loss: 0.1297\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5980 - val_loss: 0.1219\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5535 - val_loss: 0.2034\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5835 - val_loss: 0.1194\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5918 - val_loss: 0.1384\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5970 - val_loss: 0.1402\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5467 - val_loss: 0.1107\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5235 - val_loss: 0.1136\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5686 - val_loss: 0.1086\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5180 - val_loss: 0.1098\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5358 - val_loss: 0.1119\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5603 - val_loss: 0.1549\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5761 - val_loss: 0.1026\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5527 - val_loss: 0.1128\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5095 - val_loss: 0.1089\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4471 - val_loss: 0.1062\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4396 - val_loss: 0.1076\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4915 - val_loss: 0.1247\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5348 - val_loss: 0.1489\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5561 - val_loss: 0.1276\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4641 - val_loss: 0.1070\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4728 - val_loss: 0.1192\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4905 - val_loss: 0.1055\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4938 - val_loss: 0.0945\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4269 - val_loss: 0.0978\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4725 - val_loss: 0.1356\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5754 - val_loss: 0.1348\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4518 - val_loss: 0.1199\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4800 - val_loss: 0.0997\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4462 - val_loss: 0.0983\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4589 - val_loss: 0.1317\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4657 - val_loss: 0.0863\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3997 - val_loss: 0.0886\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4674 - val_loss: 0.0949\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3964 - val_loss: 0.0875\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4576 - val_loss: 0.0928\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4854 - val_loss: 0.0820\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4900 - val_loss: 0.0827\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3850 - val_loss: 0.0945\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3973 - val_loss: 0.0892\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4536 - val_loss: 0.0867\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4788 - val_loss: 0.0751\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4581 - val_loss: 0.0804\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3446 - val_loss: 0.0851\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4352 - val_loss: 0.0883\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3784 - val_loss: 0.0894\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4297 - val_loss: 0.0841\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4521 - val_loss: 0.1068\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3777 - val_loss: 0.0823\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3926 - val_loss: 0.0816\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4367 - val_loss: 0.1014\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4101 - val_loss: 0.0703\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4539 - val_loss: 0.1046\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4555 - val_loss: 0.0858\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4314 - val_loss: 0.0727\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4061 - val_loss: 0.0807\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4069 - val_loss: 0.0754\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4148 - val_loss: 0.0772\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4557 - val_loss: 0.0730\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4071 - val_loss: 0.0708\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4544 - val_loss: 0.0784\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3950 - val_loss: 0.0757\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4375 - val_loss: 0.1143\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3942 - val_loss: 0.0700\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4779 - val_loss: 0.0732\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4289 - val_loss: 0.1001\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3899 - val_loss: 0.0717\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4202 - val_loss: 0.0742\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4391 - val_loss: 0.0662\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4257 - val_loss: 0.0671\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3939 - val_loss: 0.0719\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4252 - val_loss: 0.0677\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4017 - val_loss: 0.0752\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4105 - val_loss: 0.0930\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4321 - val_loss: 0.0801\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4791 - val_loss: 0.0632\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4421 - val_loss: 0.0673\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4251 - val_loss: 0.0703\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5155 - val_loss: 0.0619\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3771 - val_loss: 0.0874\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4547 - val_loss: 0.0791\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4118 - val_loss: 0.0913\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3948 - val_loss: 0.0650\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4322 - val_loss: 0.1093\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3960 - val_loss: 0.0826\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3552 - val_loss: 0.0668\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3908 - val_loss: 0.0716\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4187 - val_loss: 0.0758\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4107 - val_loss: 0.0719\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4162 - val_loss: 0.0639\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3936 - val_loss: 0.0703\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3777 - val_loss: 0.0713\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3914 - val_loss: 0.1125\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3919 - val_loss: 0.0626\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3619 - val_loss: 0.1028\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4396 - val_loss: 0.0653\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4193 - val_loss: 0.0964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4208 - val_loss: 0.0660\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4191 - val_loss: 0.0611\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3954 - val_loss: 0.0694\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3872 - val_loss: 0.0820\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4250 - val_loss: 0.0777\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4162 - val_loss: 0.0667\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3900 - val_loss: 0.0689\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4607 - val_loss: 0.0692\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4466 - val_loss: 0.0679\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4109 - val_loss: 0.0766\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3693 - val_loss: 0.0774\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3891 - val_loss: 0.0649\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3508 - val_loss: 0.1013\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3976 - val_loss: 0.0667\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3795 - val_loss: 0.0803\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3078 - val_loss: 0.0803\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3515 - val_loss: 0.0622\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4423 - val_loss: 0.0654\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.06536376482220047\n",
      "Mean Absolute Error: 0.177837721743987\n",
      "R-squared: 0.993435644851473\n",
      "\n",
      "Fold 3:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 103ms/step - loss: 38.0150 - val_loss: 28.5863\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 15.7419 - val_loss: 7.2220\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.6376 - val_loss: 6.2679\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.1946 - val_loss: 4.9691\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5907 - val_loss: 3.0165\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 2.7474 - val_loss: 1.2213\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.5038 - val_loss: 0.6937\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 1.2414 - val_loss: 0.5685\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1397 - val_loss: 0.5296\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0671 - val_loss: 0.4677\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.9546 - val_loss: 0.4353\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.9250 - val_loss: 0.4060\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9567 - val_loss: 0.3862\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8792 - val_loss: 0.3498\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9186 - val_loss: 0.3242\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9930 - val_loss: 0.3119\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.8549 - val_loss: 0.2894\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7396 - val_loss: 0.3046\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7209 - val_loss: 0.2809\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6586 - val_loss: 0.2565\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6572 - val_loss: 0.2499\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7676 - val_loss: 0.2387\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7302 - val_loss: 0.2301\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.7329 - val_loss: 0.2305\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6140 - val_loss: 0.2277\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7779 - val_loss: 0.2132\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5667 - val_loss: 0.2165\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6272 - val_loss: 0.2036\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6521 - val_loss: 0.2046\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6525 - val_loss: 0.1974\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6925 - val_loss: 0.1963\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6036 - val_loss: 0.1965\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5878 - val_loss: 0.1883\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6067 - val_loss: 0.1823\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6128 - val_loss: 0.1842\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5047 - val_loss: 0.1766\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5680 - val_loss: 0.1822\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.5641 - val_loss: 0.1865\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5423 - val_loss: 0.1859\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5750 - val_loss: 0.1748\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5427 - val_loss: 0.2006\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6449 - val_loss: 0.1808\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5616 - val_loss: 0.1666\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6012 - val_loss: 0.1720\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4758 - val_loss: 0.1812\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5330 - val_loss: 0.1647\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5258 - val_loss: 0.1732\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5568 - val_loss: 0.1667\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5312 - val_loss: 0.2191\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4978 - val_loss: 0.1634\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4715 - val_loss: 0.1711\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.4625 - val_loss: 0.1606\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5640 - val_loss: 0.2084\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4937 - val_loss: 0.2000\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5039 - val_loss: 0.1841\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4752 - val_loss: 0.1565\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4650 - val_loss: 0.1571\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5238 - val_loss: 0.1632\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4940 - val_loss: 0.2095\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5693 - val_loss: 0.1688\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5199 - val_loss: 0.1718\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4011 - val_loss: 0.1558\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4526 - val_loss: 0.2151\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4509 - val_loss: 0.1589\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4779 - val_loss: 0.2219\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4625 - val_loss: 0.1737\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4559 - val_loss: 0.1511\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4217 - val_loss: 0.1886\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4862 - val_loss: 0.1920\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4243 - val_loss: 0.1385\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4865 - val_loss: 0.2019\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4902 - val_loss: 0.1562\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5220 - val_loss: 0.1463\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4711 - val_loss: 0.1863\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4444 - val_loss: 0.1534\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4408 - val_loss: 0.1503\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4911 - val_loss: 0.1362\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4576 - val_loss: 0.1818\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4060 - val_loss: 0.1476\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4600 - val_loss: 0.1757\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4241 - val_loss: 0.1917\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4287 - val_loss: 0.1579\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4060 - val_loss: 0.1722\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4322 - val_loss: 0.1357\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4168 - val_loss: 0.1402\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4073 - val_loss: 0.1311\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4225 - val_loss: 0.1369\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3667 - val_loss: 0.1296\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3978 - val_loss: 0.1325\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4264 - val_loss: 0.1290\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4052 - val_loss: 0.1310\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3656 - val_loss: 0.1672\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4562 - val_loss: 0.1294\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4547 - val_loss: 0.1520\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4212 - val_loss: 0.1281\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4151 - val_loss: 0.1500\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3347 - val_loss: 0.1429\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4050 - val_loss: 0.1363\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4037 - val_loss: 0.1578\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4298 - val_loss: 0.1400\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4408 - val_loss: 0.1327\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4235 - val_loss: 0.1232\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4122 - val_loss: 0.1388\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3862 - val_loss: 0.1242\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4359 - val_loss: 0.1193\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3375 - val_loss: 0.1433\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3971 - val_loss: 0.1179\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3620 - val_loss: 0.1448\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4204 - val_loss: 0.1267\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4454 - val_loss: 0.1595\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3980 - val_loss: 0.1412\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3925 - val_loss: 0.1484\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3804 - val_loss: 0.1299\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4426 - val_loss: 0.1518\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4166 - val_loss: 0.1225\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4131 - val_loss: 0.1903\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4411 - val_loss: 0.1254\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3776 - val_loss: 0.1893\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4169 - val_loss: 0.1609\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4102 - val_loss: 0.1542\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4016 - val_loss: 0.1976\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4271 - val_loss: 0.1179\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4196 - val_loss: 0.1556\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3843 - val_loss: 0.1201\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3938 - val_loss: 0.1183\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3774 - val_loss: 0.1295\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3625 - val_loss: 0.1905\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4050 - val_loss: 0.1248\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3924 - val_loss: 0.1684\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3481 - val_loss: 0.1503\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4356 - val_loss: 0.1239\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3721 - val_loss: 0.1483\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4270 - val_loss: 0.2011\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3955 - val_loss: 0.1410\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3526 - val_loss: 0.1216\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3575 - val_loss: 0.1181\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.3571 - val_loss: 0.1213\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3008 - val_loss: 0.1304\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4059 - val_loss: 0.1246\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3946 - val_loss: 0.1147\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3912 - val_loss: 0.1470\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3861 - val_loss: 0.1167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3626 - val_loss: 0.1406\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3679 - val_loss: 0.1350\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3880 - val_loss: 0.1440\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4219 - val_loss: 0.1465\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4068 - val_loss: 0.1264\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3539 - val_loss: 0.1171\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3571 - val_loss: 0.1735\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3498 - val_loss: 0.1303\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.13033893508112124\n",
      "Mean Absolute Error: 0.21890049312838272\n",
      "R-squared: 0.985588499631521\n",
      "\n",
      "Fold 4:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 114ms/step - loss: 38.7909 - val_loss: 27.1801\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 16.9000 - val_loss: 6.1178\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.7935 - val_loss: 5.1452\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.9647 - val_loss: 3.9325\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5052 - val_loss: 2.2319\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 2.5545 - val_loss: 0.8653\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.3422 - val_loss: 0.5527\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1628 - val_loss: 0.5073\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1085 - val_loss: 0.4857\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1247 - val_loss: 0.4425\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0544 - val_loss: 0.4160\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9255 - val_loss: 0.3974\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9785 - val_loss: 0.3746\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9604 - val_loss: 0.3477\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8505 - val_loss: 0.3453\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8807 - val_loss: 0.3393\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8606 - val_loss: 0.3777\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8127 - val_loss: 0.3473\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7925 - val_loss: 0.2694\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8165 - val_loss: 0.2611\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7599 - val_loss: 0.2378\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7828 - val_loss: 0.3104\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8033 - val_loss: 0.2333\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6709 - val_loss: 0.2272\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6700 - val_loss: 0.2059\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7094 - val_loss: 0.2282\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7135 - val_loss: 0.2008\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6162 - val_loss: 0.2327\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6574 - val_loss: 0.2090\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6700 - val_loss: 0.1941\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6286 - val_loss: 0.2001\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6237 - val_loss: 0.1788\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6083 - val_loss: 0.2309\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6591 - val_loss: 0.1886\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7259 - val_loss: 0.1738\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5885 - val_loss: 0.1719\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5988 - val_loss: 0.2024\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6153 - val_loss: 0.1565\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6012 - val_loss: 0.1565\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5950 - val_loss: 0.1842\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5617 - val_loss: 0.1703\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5322 - val_loss: 0.1878\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5956 - val_loss: 0.1597\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5147 - val_loss: 0.1409\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5185 - val_loss: 0.1485\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5719 - val_loss: 0.1352\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5471 - val_loss: 0.1485\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5433 - val_loss: 0.1544\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4937 - val_loss: 0.1650\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5145 - val_loss: 0.2236\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5381 - val_loss: 0.1365\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5414 - val_loss: 0.1464\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5441 - val_loss: 0.1440\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5349 - val_loss: 0.1355\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5207 - val_loss: 0.1311\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4794 - val_loss: 0.1374\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4819 - val_loss: 0.1536\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4634 - val_loss: 0.1372\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4431 - val_loss: 0.1612\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4513 - val_loss: 0.1556\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4734 - val_loss: 0.1349\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4631 - val_loss: 0.1283\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4931 - val_loss: 0.1203\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4917 - val_loss: 0.1304\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4126 - val_loss: 0.1220\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4497 - val_loss: 0.1352\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4637 - val_loss: 0.1271\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4274 - val_loss: 0.1620\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5137 - val_loss: 0.1192\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5058 - val_loss: 0.1271\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4420 - val_loss: 0.1257\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4865 - val_loss: 0.1467\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4650 - val_loss: 0.1130\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4432 - val_loss: 0.1306\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4747 - val_loss: 0.1137\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4814 - val_loss: 0.1124\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4797 - val_loss: 0.1285\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5479 - val_loss: 0.1428\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4766 - val_loss: 0.1349\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4680 - val_loss: 0.1595\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4105 - val_loss: 0.1176\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4338 - val_loss: 0.1148\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4065 - val_loss: 0.1095\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4720 - val_loss: 0.1239\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4741 - val_loss: 0.1091\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4621 - val_loss: 0.1874\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4772 - val_loss: 0.1140\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4791 - val_loss: 0.1175\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3988 - val_loss: 0.1323\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4261 - val_loss: 0.1226\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4313 - val_loss: 0.1050\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4677 - val_loss: 0.1165\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4281 - val_loss: 0.1018\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3841 - val_loss: 0.1105\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4618 - val_loss: 0.1546\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3963 - val_loss: 0.1062\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4421 - val_loss: 0.1004\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3917 - val_loss: 0.1025\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3419 - val_loss: 0.0994\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4587 - val_loss: 0.1015\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4379 - val_loss: 0.1475\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3399 - val_loss: 0.1319\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4297 - val_loss: 0.0984\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4601 - val_loss: 0.1441\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4498 - val_loss: 0.0976\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3863 - val_loss: 0.1221\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4850 - val_loss: 0.1053\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4094 - val_loss: 0.1152\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3931 - val_loss: 0.1167\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3832 - val_loss: 0.1132\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4745 - val_loss: 0.1007\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4309 - val_loss: 0.1074\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3628 - val_loss: 0.0924\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4071 - val_loss: 0.0950\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4105 - val_loss: 0.0951\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4188 - val_loss: 0.1367\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3838 - val_loss: 0.0919\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4099 - val_loss: 0.1094\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3835 - val_loss: 0.1186\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3760 - val_loss: 0.1078\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4197 - val_loss: 0.1303\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4342 - val_loss: 0.1176\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3882 - val_loss: 0.1271\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4295 - val_loss: 0.1018\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4281 - val_loss: 0.0945\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3755 - val_loss: 0.0950\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3932 - val_loss: 0.1147\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4222 - val_loss: 0.1008\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5190 - val_loss: 0.1022\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3928 - val_loss: 0.0884\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4022 - val_loss: 0.0945\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3939 - val_loss: 0.0938\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3993 - val_loss: 0.0902\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3757 - val_loss: 0.0984\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3417 - val_loss: 0.0896\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3967 - val_loss: 0.1029\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3646 - val_loss: 0.0927\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4253 - val_loss: 0.1793\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4200 - val_loss: 0.0961\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4137 - val_loss: 0.1081\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3773 - val_loss: 0.0886\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3609 - val_loss: 0.0985\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3709 - val_loss: 0.0873\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3481 - val_loss: 0.0922\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3870 - val_loss: 0.0872\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4230 - val_loss: 0.1024\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3852 - val_loss: 0.1467\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4031 - val_loss: 0.0993\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4157 - val_loss: 0.0987\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3831 - val_loss: 0.0963\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.09625866891043874\n",
      "Mean Absolute Error: 0.19227516710461667\n",
      "R-squared: 0.9878589172977785\n",
      "\n",
      "Fold 5:\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 15s 107ms/step - loss: 38.4328 - val_loss: 26.5856\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 15.7826 - val_loss: 6.2181\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.7139 - val_loss: 5.0213\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.5471 - val_loss: 3.5471\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8073 - val_loss: 1.6835\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 2.0763 - val_loss: 0.7327\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.2392 - val_loss: 0.5551\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1426 - val_loss: 0.4702\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1418 - val_loss: 0.4614\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0504 - val_loss: 0.4260\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8877 - val_loss: 0.4059\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9469 - val_loss: 0.3690\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8933 - val_loss: 0.3399\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9062 - val_loss: 0.4287\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8937 - val_loss: 0.3141\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.8261 - val_loss: 0.3152\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.9117 - val_loss: 0.2810\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.8193 - val_loss: 0.3129\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7852 - val_loss: 0.2784\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7001 - val_loss: 0.2903\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8088 - val_loss: 0.2543\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8023 - val_loss: 0.2489\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6435 - val_loss: 0.2379\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6524 - val_loss: 0.2595\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6692 - val_loss: 0.2359\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6840 - val_loss: 0.2288\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6930 - val_loss: 0.2435\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7343 - val_loss: 0.2137\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6081 - val_loss: 0.2896\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6538 - val_loss: 0.2324\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5980 - val_loss: 0.2279\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6153 - val_loss: 0.2132\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6081 - val_loss: 0.2902\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5892 - val_loss: 0.1993\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6363 - val_loss: 0.1988\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5932 - val_loss: 0.1928\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5543 - val_loss: 0.1943\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6024 - val_loss: 0.1906\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5874 - val_loss: 0.2071\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5655 - val_loss: 0.2278\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5341 - val_loss: 0.1886\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5364 - val_loss: 0.1909\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4963 - val_loss: 0.2073\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5082 - val_loss: 0.2005\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5509 - val_loss: 0.1829\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4992 - val_loss: 0.1776\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5111 - val_loss: 0.1833\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4698 - val_loss: 0.1800\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5129 - val_loss: 0.1794\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5093 - val_loss: 0.1979\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4658 - val_loss: 0.1773\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.5169 - val_loss: 0.2382\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5142 - val_loss: 0.1762\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5249 - val_loss: 0.1819\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4660 - val_loss: 0.1709\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5897 - val_loss: 0.1710\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5083 - val_loss: 0.2030\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5309 - val_loss: 0.1740\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.5202 - val_loss: 0.1728\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5093 - val_loss: 0.1687\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4567 - val_loss: 0.1790\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5475 - val_loss: 0.1667\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4567 - val_loss: 0.1716\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4656 - val_loss: 0.1810\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4289 - val_loss: 0.1895\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4358 - val_loss: 0.1666\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4887 - val_loss: 0.1815\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4759 - val_loss: 0.1793\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5024 - val_loss: 0.1758\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4963 - val_loss: 0.1653\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4623 - val_loss: 0.1620\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4709 - val_loss: 0.1724\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4642 - val_loss: 0.1688\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4397 - val_loss: 0.2897\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4836 - val_loss: 0.1669\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4363 - val_loss: 0.1656\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4601 - val_loss: 0.1738\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4237 - val_loss: 0.1758\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4257 - val_loss: 0.1656\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3882 - val_loss: 0.1713\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4024 - val_loss: 0.1616\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4010 - val_loss: 0.1754\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4600 - val_loss: 0.1826\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4182 - val_loss: 0.1685\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4187 - val_loss: 0.1609\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4600 - val_loss: 0.1650\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4320 - val_loss: 0.1746\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3944 - val_loss: 0.1667\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4162 - val_loss: 0.1629\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3930 - val_loss: 0.1634\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3714 - val_loss: 0.1717\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4278 - val_loss: 0.1613\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4116 - val_loss: 0.1739\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4018 - val_loss: 0.1620\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4040 - val_loss: 0.1553\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4795 - val_loss: 0.1680\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4000 - val_loss: 0.1910\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3860 - val_loss: 0.1792\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4192 - val_loss: 0.1525\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4098 - val_loss: 0.1597\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4274 - val_loss: 0.1618\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3665 - val_loss: 0.1534\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4062 - val_loss: 0.1696\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4330 - val_loss: 0.1706\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3810 - val_loss: 0.1768\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4040 - val_loss: 0.1985\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4836 - val_loss: 0.1810\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3677 - val_loss: 0.1494\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4399 - val_loss: 0.1489\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3679 - val_loss: 0.1600\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4032 - val_loss: 0.1476\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4272 - val_loss: 0.1502\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4403 - val_loss: 0.1806\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3502 - val_loss: 0.1513\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4056 - val_loss: 0.1509\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4018 - val_loss: 0.1713\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3747 - val_loss: 0.1913\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3885 - val_loss: 0.1656\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4463 - val_loss: 0.1480\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4021 - val_loss: 0.1501\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4103 - val_loss: 0.1572\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3744 - val_loss: 0.1694\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4058 - val_loss: 0.1603\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4040 - val_loss: 0.1500\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4089 - val_loss: 0.1556\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.4083 - val_loss: 0.1576\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.3882 - val_loss: 0.1471\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3817 - val_loss: 0.1489\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.3667 - val_loss: 0.2202\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.3746 - val_loss: 0.1691\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3759 - val_loss: 0.1639\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4424 - val_loss: 0.2465\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4015 - val_loss: 0.1679\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3380 - val_loss: 0.1655\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3933 - val_loss: 0.1494\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4058 - val_loss: 0.1670\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3862 - val_loss: 0.1442\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3614 - val_loss: 0.2289\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3925 - val_loss: 0.1462\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3736 - val_loss: 0.1541\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3648 - val_loss: 0.1486\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3808 - val_loss: 0.1828\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.3699 - val_loss: 0.1446\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3243 - val_loss: 0.2058\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3711 - val_loss: 0.1696\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3782 - val_loss: 0.1440\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3600 - val_loss: 0.1546\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4009 - val_loss: 0.1877\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3232 - val_loss: 0.1531\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3498 - val_loss: 0.1527\n",
      "7/7 [==============================] - 2s 6ms/step\n",
      "Mean Squared Error: 0.1527227733520266\n",
      "Mean Absolute Error: 0.18904610296980065\n",
      "R-squared: 0.9802124042108484\n",
      "\n",
      "Average scores for ticker CLNE:\n",
      "Mean Squared Error: 0.10741276170379224\n",
      "Mean Absolute Error: 0.1957157362752886\n",
      "R-squared: 0.9877030730242747\n",
      "\n",
      "Cross-validation for ticker: LAZR\n",
      "Fold 1:\n",
      "Epoch 1/150\n",
      "24/24 [==============================] - 16s 138ms/step - loss: 205.1983 - val_loss: 193.5091\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 149.5556 - val_loss: 94.5501\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 68.0119 - val_loss: 58.8693\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 55.0292 - val_loss: 56.5361\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 53.5359 - val_loss: 54.9481\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 51.1534 - val_loss: 52.0331\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 48.0065 - val_loss: 46.7689\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 42.0801 - val_loss: 37.6716\n",
      "Epoch 9/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 16ms/step - loss: 33.9100 - val_loss: 27.2748\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 26.5984 - val_loss: 20.6641\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 21.0504 - val_loss: 17.1950\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 18.5537 - val_loss: 14.9222\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 16.5767 - val_loss: 12.9963\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 14.9710 - val_loss: 11.5186\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 14.0440 - val_loss: 10.4730\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 12.5754 - val_loss: 9.3775\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 11.8346 - val_loss: 8.4710\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 11.7242 - val_loss: 7.5932\n",
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 10.0482 - val_loss: 6.9171\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 10.3175 - val_loss: 6.4438\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 9.1163 - val_loss: 5.7743\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 8.2857 - val_loss: 5.3090\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 8.0384 - val_loss: 5.0021\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 7.8183 - val_loss: 4.4888\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 6.9042 - val_loss: 4.1155\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 6.6739 - val_loss: 3.8551\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 6.5978 - val_loss: 3.5582\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.8060 - val_loss: 3.3120\n",
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 6.3433 - val_loss: 3.1887\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.5214 - val_loss: 2.9888\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.2888 - val_loss: 2.7017\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.8242 - val_loss: 2.7033\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.7337 - val_loss: 2.4773\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.5881 - val_loss: 2.2837\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.5171 - val_loss: 2.1337\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.6593 - val_loss: 2.0530\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.3664 - val_loss: 1.9748\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.0168 - val_loss: 1.8978\n",
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.7722 - val_loss: 1.7578\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.2141 - val_loss: 1.6922\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.4733 - val_loss: 1.6319\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.0234 - val_loss: 1.6168\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.8594 - val_loss: 1.4891\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.0691 - val_loss: 1.9841\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.4957 - val_loss: 1.4614\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.3015 - val_loss: 1.4142\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.2327 - val_loss: 1.3411\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.0326 - val_loss: 1.2980\n",
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.3958 - val_loss: 1.3023\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.1470 - val_loss: 1.6912\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.0129 - val_loss: 1.2246\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.7397 - val_loss: 1.2418\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.9360 - val_loss: 1.2018\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.7531 - val_loss: 1.1443\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.9984 - val_loss: 1.2794\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.7567 - val_loss: 1.1444\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.3111 - val_loss: 1.0374\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.8057 - val_loss: 1.0733\n",
      "24/24 [==============================] - 81s 4s/step - loss: 2.7292 - val_loss: 1.0297\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.8841 - val_loss: 1.0170\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.8907 - val_loss: 1.1074\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 2.7273 - val_loss: 1.0113\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.6883 - val_loss: 1.0011\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.7651 - val_loss: 1.3509\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.5637 - val_loss: 0.9711\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 2.7222 - val_loss: 0.9044\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 2.8016 - val_loss: 0.9434\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 2.4889 - val_loss: 0.9001\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.9095 - val_loss: 0.8569\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2.5218 - val_loss: 0.8420\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.8342 - val_loss: 0.8915\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.7362 - val_loss: 0.8641\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 2.6807 - val_loss: 0.9492\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2.0057 - val_loss: 0.8074\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.6479 - val_loss: 0.8075\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 2.0251 - val_loss: 0.7934\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.6796 - val_loss: 0.7552\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3751 - val_loss: 1.0543\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0930 - val_loss: 0.7325\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4124 - val_loss: 0.9107\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 2.3596 - val_loss: 0.7110\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.5856 - val_loss: 0.6963\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.7831 - val_loss: 0.7443\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.8845 - val_loss: 0.7556\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2465 - val_loss: 1.0706\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3844 - val_loss: 0.7164\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4756 - val_loss: 0.9767\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4231 - val_loss: 0.6404\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4734 - val_loss: 0.6702\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2286 - val_loss: 0.6636\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3878 - val_loss: 0.7566\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.3526 - val_loss: 0.6501\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0335 - val_loss: 0.5894\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9688 - val_loss: 0.6765\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2101 - val_loss: 0.5840\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2873 - val_loss: 0.6249\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2051 - val_loss: 0.6157\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2585 - val_loss: 0.5961\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0824 - val_loss: 0.8347\n",
      "Epoch 100/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3633 - val_loss: 0.5325\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1540 - val_loss: 0.5608\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2893 - val_loss: 0.6219\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1177 - val_loss: 0.5737\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2113 - val_loss: 0.5835\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2897 - val_loss: 0.5045\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0661 - val_loss: 0.6352\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8852 - val_loss: 0.7487\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.5247 - val_loss: 0.5595\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0885 - val_loss: 0.5081\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2832 - val_loss: 0.5676\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0022 - val_loss: 0.5264\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.0158 - val_loss: 0.5219\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8198 - val_loss: 0.6396\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1738 - val_loss: 0.4607\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1855 - val_loss: 0.4790\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3763 - val_loss: 0.4369\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3076 - val_loss: 0.6004\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1381 - val_loss: 0.4448\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9414 - val_loss: 0.4322\n",
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0227 - val_loss: 0.4691\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6978 - val_loss: 0.4172\n",
      "Epoch 122/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8756 - val_loss: 0.4277\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6053 - val_loss: 0.3846\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1420 - val_loss: 0.5020\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1921 - val_loss: 0.3933\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0225 - val_loss: 0.3782\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7661 - val_loss: 0.3790\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.8758 - val_loss: 0.5728\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1242 - val_loss: 0.3976\n",
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8874 - val_loss: 0.4498\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9553 - val_loss: 0.4484\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.1031 - val_loss: 0.4167\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2985 - val_loss: 0.4824\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0949 - val_loss: 0.3999\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9148 - val_loss: 0.3911\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1600 - val_loss: 0.3607\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0793 - val_loss: 0.4765\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1584 - val_loss: 0.4897\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6964 - val_loss: 0.4814\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1218 - val_loss: 0.4136\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.7523 - val_loss: 0.3715\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8689 - val_loss: 0.4205\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0030 - val_loss: 0.3484\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9616 - val_loss: 0.3633\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0937 - val_loss: 0.6104\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8230 - val_loss: 0.5011\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2494 - val_loss: 0.4630\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0880 - val_loss: 0.3878\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8288 - val_loss: 0.3394\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8115 - val_loss: 0.4123\n",
      "6/6 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.4122929435232323\n",
      "Mean Absolute Error: 0.47640408699711173\n",
      "R-squared: 0.9931767882849964\n",
      "\n",
      "Fold 2:\n",
      "Epoch 1/150\n",
      "24/24 [==============================] - 14s 111ms/step - loss: 204.3965 - val_loss: 194.7733\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 146.6142 - val_loss: 91.4522\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 66.6818 - val_loss: 52.2704\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 54.2962 - val_loss: 49.7787\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 52.4752 - val_loss: 47.8124\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 49.9781 - val_loss: 44.5618\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 44.4503 - val_loss: 38.5665\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 38.1055 - val_loss: 29.8201\n",
      "Epoch 9/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 27.2216 - val_loss: 21.7287\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 20.8890 - val_loss: 17.5865\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 17.9826 - val_loss: 15.4951\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 16.0957 - val_loss: 13.6566\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 14.8777 - val_loss: 12.2996\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 12.7097 - val_loss: 11.2761\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 11.4996 - val_loss: 10.2097\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 10.8595 - val_loss: 9.3269\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 9.9582 - val_loss: 8.5994\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 9.9860 - val_loss: 7.9490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 9.4265 - val_loss: 7.2999\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 8.3697 - val_loss: 6.8080\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 8.2851 - val_loss: 6.2479\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 7.4780 - val_loss: 5.7930\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 6.8588 - val_loss: 5.3845\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 6.6060 - val_loss: 5.0285\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 6.5266 - val_loss: 4.9006\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 6.1731 - val_loss: 4.4248\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 5.9841 - val_loss: 4.1367\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 5.0371 - val_loss: 3.9295\n",
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 5.8739 - val_loss: 3.7594\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.8804 - val_loss: 3.4647\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.9789 - val_loss: 3.2116\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.3993 - val_loss: 3.0745\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 4.2078 - val_loss: 2.9300\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 4.2169 - val_loss: 2.7499\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.2064 - val_loss: 2.6284\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.4211 - val_loss: 2.5143\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.9920 - val_loss: 2.5276\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.7515 - val_loss: 2.3198\n",
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.5095 - val_loss: 2.3064\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.7707 - val_loss: 2.1456\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.9671 - val_loss: 2.1516\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.7567 - val_loss: 2.0466\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.2965 - val_loss: 1.9431\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.5646 - val_loss: 1.8843\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.3464 - val_loss: 2.0845\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.4788 - val_loss: 1.7940\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.3372 - val_loss: 1.8676\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.5433 - val_loss: 1.6871\n",
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.0307 - val_loss: 1.6323\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.8864 - val_loss: 1.5685\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.2005 - val_loss: 1.4888\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.1061 - val_loss: 1.5244\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.2037 - val_loss: 1.7018\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.9866 - val_loss: 1.4332\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.8965 - val_loss: 1.3889\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.8893 - val_loss: 1.4874\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.8971 - val_loss: 1.3838\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.8814 - val_loss: 1.4661\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.8314 - val_loss: 1.3318\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.8054 - val_loss: 1.3286\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6077 - val_loss: 1.3433\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.8984 - val_loss: 1.2841\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.8172 - val_loss: 1.2447\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.6962 - val_loss: 1.3493\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5817 - val_loss: 1.2137\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.8263 - val_loss: 1.2285\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.3810 - val_loss: 1.2105\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.7390 - val_loss: 1.1942\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6266 - val_loss: 1.1498\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.3637 - val_loss: 1.0698\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3589 - val_loss: 1.1085\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3484 - val_loss: 1.1647\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6559 - val_loss: 1.1182\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.4344 - val_loss: 1.1087\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5759 - val_loss: 1.1526\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3066 - val_loss: 1.0897\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5741 - val_loss: 0.9971\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3422 - val_loss: 1.0313\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.4246 - val_loss: 1.0575\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.7611 - val_loss: 1.0178\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0620 - val_loss: 1.0445\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.2479 - val_loss: 0.9493\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6348 - val_loss: 1.0487\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2433 - val_loss: 0.9510\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.7019 - val_loss: 1.2828\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.5007 - val_loss: 1.0405\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1353 - val_loss: 0.9611\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1722 - val_loss: 0.8989\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5108 - val_loss: 0.9202\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1413 - val_loss: 0.9344\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.1894 - val_loss: 0.9300\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.4458 - val_loss: 1.0224\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0557 - val_loss: 0.9756\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3290 - val_loss: 0.8887\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1102 - val_loss: 0.9181\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1301 - val_loss: 0.8241\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.4144 - val_loss: 0.9802\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9738 - val_loss: 0.9017\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.3380 - val_loss: 0.8461\n",
      "Epoch 100/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1228 - val_loss: 0.8528\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.3614 - val_loss: 0.8789\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8506 - val_loss: 0.7959\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2117 - val_loss: 0.8211\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2401 - val_loss: 0.9986\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1281 - val_loss: 0.7479\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1442 - val_loss: 0.8725\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0525 - val_loss: 0.7974\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4334 - val_loss: 0.7720\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2489 - val_loss: 0.9275\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9129 - val_loss: 0.8208\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1590 - val_loss: 0.8550\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2616 - val_loss: 0.8008\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8686 - val_loss: 0.7482\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1875 - val_loss: 0.7448\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4589 - val_loss: 0.7727\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8525 - val_loss: 0.7333\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0696 - val_loss: 0.8221\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0970 - val_loss: 0.7428\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0062 - val_loss: 0.7059\n",
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0446 - val_loss: 0.7607\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0166 - val_loss: 0.7212\n",
      "Epoch 122/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0542 - val_loss: 0.8114\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1956 - val_loss: 0.7967\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2064 - val_loss: 0.7597\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1524 - val_loss: 0.6924\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.7023 - val_loss: 0.6859\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0434 - val_loss: 0.7518\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0046 - val_loss: 0.7335\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1839 - val_loss: 0.7346\n",
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0009 - val_loss: 0.6925\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0637 - val_loss: 0.6769\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2346 - val_loss: 0.6721\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9814 - val_loss: 0.6350\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9596 - val_loss: 0.7049\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0933 - val_loss: 0.6980\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8891 - val_loss: 0.6660\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9201 - val_loss: 0.7658\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1391 - val_loss: 0.6705\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.7383 - val_loss: 0.6490\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9915 - val_loss: 0.6374\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1258 - val_loss: 0.8923\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8337 - val_loss: 0.6959\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9162 - val_loss: 0.6704\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9523 - val_loss: 0.6202\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9269 - val_loss: 0.7367\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7672 - val_loss: 0.5865\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9475 - val_loss: 0.6890\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8612 - val_loss: 0.6007\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6938 - val_loss: 0.6096\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2434 - val_loss: 0.7927\n",
      "6/6 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.7927444199567789\n",
      "Mean Absolute Error: 0.5273924460585828\n",
      "R-squared: 0.9853651155583989\n",
      "\n",
      "Fold 3:\n",
      "Epoch 1/150\n",
      "24/24 [==============================] - 15s 111ms/step - loss: 205.9242 - val_loss: 184.3188\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 145.1922 - val_loss: 83.2126\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 68.2680 - val_loss: 47.7053\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 56.0435 - val_loss: 45.6726\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 55.4276 - val_loss: 44.1951\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 53.0141 - val_loss: 41.9542\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 50.1353 - val_loss: 37.4465\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 42.2918 - val_loss: 29.7019\n",
      "Epoch 9/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 32.3820 - val_loss: 20.6232\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 23.9035 - val_loss: 15.3662\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 20.8579 - val_loss: 12.8211\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 18.0797 - val_loss: 11.1625\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 15.8938 - val_loss: 9.9094\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 15.1828 - val_loss: 8.8973\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 13.4637 - val_loss: 7.9993\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 12.0000 - val_loss: 7.2583\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 11.4232 - val_loss: 6.6464\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 11.3173 - val_loss: 6.0355\n",
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 9.8189 - val_loss: 5.5088\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 9.6955 - val_loss: 5.0765\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 8.1486 - val_loss: 4.6969\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 7.8962 - val_loss: 4.3759\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 8.1961 - val_loss: 4.0301\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 7.5854 - val_loss: 3.7467\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 6.9087 - val_loss: 3.5253\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 6.4136 - val_loss: 3.1944\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 6.5421 - val_loss: 2.9931\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 6.1005 - val_loss: 2.7897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.5393 - val_loss: 2.6291\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.3880 - val_loss: 2.5548\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 5.0996 - val_loss: 2.4988\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.8889 - val_loss: 2.3299\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.8493 - val_loss: 2.2878\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.8350 - val_loss: 2.0481\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.5622 - val_loss: 1.9602\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.4781 - val_loss: 1.7754\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.6762 - val_loss: 1.7272\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.1063 - val_loss: 1.5532\n",
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.1000 - val_loss: 1.5565\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.7602 - val_loss: 1.4375\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.5597 - val_loss: 1.3556\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.5332 - val_loss: 1.3323\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.8439 - val_loss: 1.2604\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.7910 - val_loss: 1.3031\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.5031 - val_loss: 1.4721\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.1505 - val_loss: 1.2761\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.4470 - val_loss: 1.0995\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 3.2498 - val_loss: 1.1892\n",
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.1904 - val_loss: 1.0860\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.1293 - val_loss: 1.0457\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.0685 - val_loss: 1.0732\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.0819 - val_loss: 1.0043\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6879 - val_loss: 0.9797\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.9854 - val_loss: 1.1040\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.4380 - val_loss: 1.1284\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.2273 - val_loss: 1.1083\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.3601 - val_loss: 0.8904\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.0321 - val_loss: 0.9208\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.0773 - val_loss: 0.8910\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.2564 - val_loss: 1.1332\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4516 - val_loss: 0.8278\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6050 - val_loss: 0.8084\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.7601 - val_loss: 0.7885\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.7963 - val_loss: 0.8210\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6699 - val_loss: 0.7856\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.7442 - val_loss: 0.7817\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.5033 - val_loss: 1.0405\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6114 - val_loss: 0.7637\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4887 - val_loss: 1.0007\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.6425 - val_loss: 0.8479\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.7619 - val_loss: 0.7759\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.8577 - val_loss: 0.7447\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.4919 - val_loss: 0.8341\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3551 - val_loss: 0.7875\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.4901 - val_loss: 0.7095\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.5363 - val_loss: 0.6464\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.5925 - val_loss: 0.8062\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.4239 - val_loss: 0.6620\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.3043 - val_loss: 0.6142\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.3820 - val_loss: 0.8500\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5166 - val_loss: 0.7021\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4220 - val_loss: 0.6250\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3317 - val_loss: 0.6539\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.5663 - val_loss: 0.6045\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2425 - val_loss: 0.5915\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2790 - val_loss: 0.7855\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2063 - val_loss: 0.6063\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5609 - val_loss: 0.6916\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3050 - val_loss: 0.6165\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1483 - val_loss: 0.5713\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.2034 - val_loss: 0.5647\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1658 - val_loss: 0.7093\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2084 - val_loss: 0.6306\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9378 - val_loss: 0.5953\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4484 - val_loss: 0.6265\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1950 - val_loss: 0.5383\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.3202 - val_loss: 0.5142\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.3275 - val_loss: 0.5510\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0199 - val_loss: 0.5625\n",
      "Epoch 100/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2447 - val_loss: 0.5567\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2661 - val_loss: 0.5492\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2758 - val_loss: 0.5330\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1425 - val_loss: 0.5439\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2765 - val_loss: 0.5125\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0359 - val_loss: 0.5346\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1288 - val_loss: 0.6323\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2551 - val_loss: 0.4766\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1327 - val_loss: 0.6465\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2073 - val_loss: 0.5142\n",
      "Epoch 110/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5027 - val_loss: 0.4945\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0418 - val_loss: 0.5213\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3596 - val_loss: 0.5487\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3593 - val_loss: 0.4898\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1543 - val_loss: 0.5357\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.1605 - val_loss: 0.4796\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0973 - val_loss: 0.5703\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1043 - val_loss: 0.5967\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.1196 - val_loss: 0.5743\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2995 - val_loss: 0.5175\n",
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0801 - val_loss: 0.4685\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1346 - val_loss: 0.5358\n",
      "Epoch 122/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9511 - val_loss: 0.6675\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2596 - val_loss: 0.5773\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7847 - val_loss: 0.4386\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.1140 - val_loss: 0.5645\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7082 - val_loss: 0.4452\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.7638 - val_loss: 0.4226\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9199 - val_loss: 0.4496\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.4291 - val_loss: 0.6060\n",
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8102 - val_loss: 0.4932\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9253 - val_loss: 0.4756\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1532 - val_loss: 0.4680\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.7371 - val_loss: 0.4873\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.4000 - val_loss: 0.4373\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0237 - val_loss: 0.4827\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9198 - val_loss: 0.4625\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.7021 - val_loss: 0.4396\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8460 - val_loss: 0.4785\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0413 - val_loss: 0.5634\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.7246 - val_loss: 0.4113\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8576 - val_loss: 0.4096\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9250 - val_loss: 0.3935\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8745 - val_loss: 0.5457\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1339 - val_loss: 0.5005\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9693 - val_loss: 0.4149\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1284 - val_loss: 0.5942\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0327 - val_loss: 0.3784\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.8870 - val_loss: 0.4169\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7748 - val_loss: 0.4150\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0475 - val_loss: 0.3866\n",
      "6/6 [==============================] - 2s 6ms/step\n",
      "Mean Squared Error: 0.3866063244422177\n",
      "Mean Absolute Error: 0.3466172492941013\n",
      "R-squared: 0.9921253631703602\n",
      "\n",
      "Fold 4:\n",
      "Epoch 1/150\n",
      "24/24 [==============================] - 14s 108ms/step - loss: 205.0073 - val_loss: 184.3428\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 138.9468 - val_loss: 86.7395\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 64.0922 - val_loss: 63.8212\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 54.2487 - val_loss: 63.2708\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 52.2869 - val_loss: 62.2857\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 50.4189 - val_loss: 59.6551\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 49.4893 - val_loss: 54.5218\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 43.0114 - val_loss: 45.1275\n",
      "Epoch 9/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 35.6222 - val_loss: 33.7835\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 25.6188 - val_loss: 26.2918\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 21.4002 - val_loss: 22.0649\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 17.9731 - val_loss: 19.4416\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 16.3437 - val_loss: 17.7825\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 13.9536 - val_loss: 16.0496\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 13.7777 - val_loss: 14.6944\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 12.3022 - val_loss: 13.4302\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 11.4941 - val_loss: 12.3543\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 10.4318 - val_loss: 11.3955\n",
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 9.3737 - val_loss: 10.5028\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 9.4627 - val_loss: 9.8196\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 8.8379 - val_loss: 9.1836\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 8.4873 - val_loss: 8.4775\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 7.9066 - val_loss: 8.0705\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 7.1289 - val_loss: 7.4556\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 6.7226 - val_loss: 7.0783\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 6.2736 - val_loss: 6.5456\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 6.1964 - val_loss: 6.1720\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 6.0762 - val_loss: 5.7838\n",
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.3151 - val_loss: 5.5412\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 5.2139 - val_loss: 5.1684\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 4.6078 - val_loss: 4.8592\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 4.5028 - val_loss: 4.6872\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.0619 - val_loss: 4.4321\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.1563 - val_loss: 4.4115\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 4.6667 - val_loss: 3.9760\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 4.5252 - val_loss: 3.7514\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.7716 - val_loss: 3.5925\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.8198 - val_loss: 3.4315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.7902 - val_loss: 3.3322\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.9131 - val_loss: 3.1942\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.7886 - val_loss: 3.0611\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.8956 - val_loss: 2.9898\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.5127 - val_loss: 2.8753\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 3.7484 - val_loss: 2.7502\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.6488 - val_loss: 2.7113\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.8580 - val_loss: 2.6049\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.3331 - val_loss: 2.4983\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.1887 - val_loss: 2.4256\n",
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.1243 - val_loss: 2.3770\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.0801 - val_loss: 2.3317\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.1690 - val_loss: 2.3076\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.7973 - val_loss: 2.2164\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.2492 - val_loss: 2.1397\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6748 - val_loss: 2.2141\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.8196 - val_loss: 2.0577\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.0758 - val_loss: 2.0064\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.1188 - val_loss: 2.0394\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.7082 - val_loss: 2.0808\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6139 - val_loss: 1.9057\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.4938 - val_loss: 1.8304\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6200 - val_loss: 1.8488\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.5479 - val_loss: 1.8908\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.7517 - val_loss: 1.7939\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5015 - val_loss: 1.7750\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6942 - val_loss: 1.7011\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.9669 - val_loss: 1.6777\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1979 - val_loss: 1.7336\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.5060 - val_loss: 1.6357\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.1045 - val_loss: 1.6764\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.9073 - val_loss: 1.5998\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3617 - val_loss: 1.5599\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4612 - val_loss: 1.5427\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3364 - val_loss: 1.5063\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.7254 - val_loss: 1.4772\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.7063 - val_loss: 1.7708\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.7971 - val_loss: 1.7188\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6009 - val_loss: 1.3965\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.4957 - val_loss: 1.4632\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3460 - val_loss: 1.4115\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1254 - val_loss: 1.3699\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5659 - val_loss: 1.4937\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3339 - val_loss: 1.4871\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4550 - val_loss: 1.3778\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5703 - val_loss: 1.2574\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1974 - val_loss: 1.3499\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2352 - val_loss: 1.2621\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1253 - val_loss: 1.4364\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2411 - val_loss: 1.3686\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4669 - val_loss: 1.6977\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4671 - val_loss: 1.1989\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3900 - val_loss: 1.2033\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5145 - val_loss: 1.1597\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1738 - val_loss: 1.1507\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0086 - val_loss: 1.2475\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.6349 - val_loss: 1.4496\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5430 - val_loss: 1.2196\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1130 - val_loss: 1.0602\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9801 - val_loss: 1.0957\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1278 - val_loss: 1.1044\n",
      "Epoch 100/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8961 - val_loss: 1.0943\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8731 - val_loss: 1.2050\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0325 - val_loss: 1.0370\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2647 - val_loss: 1.0629\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8098 - val_loss: 1.0725\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0412 - val_loss: 1.0153\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8745 - val_loss: 1.3044\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2845 - val_loss: 0.9861\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0988 - val_loss: 1.0158\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1219 - val_loss: 0.9886\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3311 - val_loss: 0.9905\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0393 - val_loss: 0.9422\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3977 - val_loss: 0.9378\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8656 - val_loss: 1.0321\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0354 - val_loss: 0.9904\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0720 - val_loss: 1.1529\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4455 - val_loss: 0.9987\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0671 - val_loss: 0.9231\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1453 - val_loss: 0.9881\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9639 - val_loss: 0.9100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1796 - val_loss: 0.9565\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9475 - val_loss: 1.0222\n",
      "Epoch 122/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.1612 - val_loss: 0.9497\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0447 - val_loss: 1.0120\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9995 - val_loss: 0.9603\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0773 - val_loss: 0.9974\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9924 - val_loss: 0.8692\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1424 - val_loss: 1.0234\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9917 - val_loss: 0.9176\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9736 - val_loss: 0.8448\n",
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9349 - val_loss: 0.8199\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3509 - val_loss: 0.8471\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1774 - val_loss: 0.7813\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8802 - val_loss: 0.8001\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9748 - val_loss: 0.8605\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0748 - val_loss: 1.1511\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7137 - val_loss: 0.8542\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0588 - val_loss: 1.0194\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9110 - val_loss: 0.8259\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9207 - val_loss: 0.8456\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0047 - val_loss: 0.8766\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0386 - val_loss: 0.8010\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9332 - val_loss: 0.7680\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0087 - val_loss: 0.7774\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9922 - val_loss: 0.8970\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1805 - val_loss: 0.8024\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8754 - val_loss: 0.8514\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6360 - val_loss: 0.8435\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1534 - val_loss: 0.7298\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9279 - val_loss: 0.7279\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8127 - val_loss: 0.7180\n",
      "6/6 [==============================] - 2s 6ms/step\n",
      "Mean Squared Error: 0.7180385667034348\n",
      "Mean Absolute Error: 0.46569217312398375\n",
      "R-squared: 0.989253828661528\n",
      "\n",
      "Fold 5:\n",
      "Epoch 1/150\n",
      "24/24 [==============================] - 14s 110ms/step - loss: 205.7594 - val_loss: 180.1536\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 142.9905 - val_loss: 83.0305\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 66.5463 - val_loss: 52.6550\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 54.4953 - val_loss: 51.1043\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 53.5599 - val_loss: 49.5866\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 51.7982 - val_loss: 46.7567\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 47.3118 - val_loss: 41.7764\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 41.6827 - val_loss: 34.0890\n",
      "Epoch 9/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 31.2796 - val_loss: 24.7316\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 22.8775 - val_loss: 19.5913\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 19.4342 - val_loss: 16.9782\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 16.9307 - val_loss: 15.2615\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 15.9583 - val_loss: 13.7151\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 14.4107 - val_loss: 12.5171\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 12.8401 - val_loss: 11.3423\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 12.1203 - val_loss: 10.3427\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 10.5612 - val_loss: 9.5114\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 10.0393 - val_loss: 8.8383\n",
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 9.2933 - val_loss: 8.1843\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 9.6163 - val_loss: 7.5491\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 8.1413 - val_loss: 7.1793\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 7.9979 - val_loss: 6.4672\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 8.0204 - val_loss: 6.0292\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 7.0058 - val_loss: 5.6050\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 7.0398 - val_loss: 5.2537\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 6.8218 - val_loss: 5.0109\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 6.5226 - val_loss: 4.6377\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.6426 - val_loss: 4.4216\n",
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 5.5389 - val_loss: 4.1284\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 5.1719 - val_loss: 3.9084\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 5.4500 - val_loss: 3.6139\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.8174 - val_loss: 3.3428\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.3307 - val_loss: 3.4446\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 5.0358 - val_loss: 3.0318\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 4.3724 - val_loss: 2.8780\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.9692 - val_loss: 2.6690\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.0268 - val_loss: 2.5989\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 4.3297 - val_loss: 2.4753\n",
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 4.1647 - val_loss: 2.4729\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 4.1924 - val_loss: 2.2444\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.6596 - val_loss: 2.1504\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.5885 - val_loss: 2.0289\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.5625 - val_loss: 1.9693\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.9469 - val_loss: 1.8957\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 3.6305 - val_loss: 1.8563\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 3.3956 - val_loss: 1.7360\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 3.7287 - val_loss: 1.7028\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 3.5547 - val_loss: 2.0667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.5952 - val_loss: 1.5842\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.4138 - val_loss: 1.5033\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.1274 - val_loss: 1.5025\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.1330 - val_loss: 1.5205\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.7867 - val_loss: 1.4054\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.4037 - val_loss: 1.3741\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.8475 - val_loss: 1.3462\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.4403 - val_loss: 1.3718\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.2192 - val_loss: 1.2854\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.1786 - val_loss: 1.2791\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.7710 - val_loss: 1.2618\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.9060 - val_loss: 1.2486\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.0747 - val_loss: 1.5409\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.7333 - val_loss: 1.1373\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.6568 - val_loss: 1.4455\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.9295 - val_loss: 1.2855\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.4037 - val_loss: 1.1046\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3117 - val_loss: 1.0742\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.7598 - val_loss: 1.0866\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.0897 - val_loss: 1.0198\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4843 - val_loss: 1.0967\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0968 - val_loss: 1.0485\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.7460 - val_loss: 1.0331\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.6927 - val_loss: 1.0207\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4010 - val_loss: 0.9839\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.7123 - val_loss: 0.9938\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.4675 - val_loss: 0.9671\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.5237 - val_loss: 0.9261\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2724 - val_loss: 1.0175\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.4977 - val_loss: 0.9277\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2037 - val_loss: 0.9450\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.4014 - val_loss: 0.9508\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.5364 - val_loss: 0.9614\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2932 - val_loss: 0.9073\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.5041 - val_loss: 0.8671\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4350 - val_loss: 0.9191\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.5031 - val_loss: 0.8306\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.5327 - val_loss: 0.8856\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1290 - val_loss: 0.8204\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.3691 - val_loss: 1.0463\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2730 - val_loss: 0.8117\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2662 - val_loss: 0.7881\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3703 - val_loss: 0.9943\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2841 - val_loss: 0.7936\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2492 - val_loss: 0.8010\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9275 - val_loss: 0.8964\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2653 - val_loss: 0.7973\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2591 - val_loss: 0.8023\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2811 - val_loss: 0.8640\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1845 - val_loss: 0.7540\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.4327 - val_loss: 0.8507\n",
      "Epoch 100/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.6924 - val_loss: 0.7174\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.0222 - val_loss: 0.7379\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1671 - val_loss: 0.7344\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2004 - val_loss: 0.8122\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9977 - val_loss: 0.7232\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2183 - val_loss: 0.7935\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2655 - val_loss: 0.7736\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0400 - val_loss: 0.6806\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1544 - val_loss: 0.8081\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2554 - val_loss: 0.6936\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1737 - val_loss: 0.6962\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7774 - val_loss: 0.6995\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2835 - val_loss: 0.6670\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9755 - val_loss: 1.0898\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9765 - val_loss: 0.7136\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2551 - val_loss: 1.2621\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8982 - val_loss: 0.6794\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8589 - val_loss: 0.6716\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.9743 - val_loss: 0.6278\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9301 - val_loss: 0.6441\n",
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.0629 - val_loss: 0.6669\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1020 - val_loss: 0.6184\n",
      "Epoch 122/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0130 - val_loss: 0.6077\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9767 - val_loss: 0.6618\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0985 - val_loss: 0.6253\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8991 - val_loss: 0.6632\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0397 - val_loss: 0.6242\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.1815 - val_loss: 0.8419\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0931 - val_loss: 0.6510\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8762 - val_loss: 0.5852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.7657 - val_loss: 0.5836\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9475 - val_loss: 0.5856\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9882 - val_loss: 0.6777\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2476 - val_loss: 0.5851\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2688 - val_loss: 0.6117\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0379 - val_loss: 0.6205\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1725 - val_loss: 0.6173\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1170 - val_loss: 0.5670\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0792 - val_loss: 0.5952\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9943 - val_loss: 0.7100\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9657 - val_loss: 0.6171\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8911 - val_loss: 0.6465\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.7570 - val_loss: 0.5916\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8740 - val_loss: 0.6378\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2638 - val_loss: 0.6043\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.5993 - val_loss: 0.5710\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0958 - val_loss: 0.6274\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9180 - val_loss: 0.5348\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8246 - val_loss: 0.5857\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.7701 - val_loss: 0.5830\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6835 - val_loss: 0.6210\n",
      "6/6 [==============================] - 2s 6ms/step\n",
      "Mean Squared Error: 0.6209686663060435\n",
      "Mean Absolute Error: 0.4816187539025751\n",
      "R-squared: 0.9886542479093526\n",
      "\n",
      "Average scores for ticker LAZR:\n",
      "Mean Squared Error: 0.5861301841863416\n",
      "Mean Absolute Error: 0.45954494187527095\n",
      "R-squared: 0.9897150687169273\n",
      "\n",
      "Cross-validation for ticker: AMWL\n",
      "Fold 1:\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 15s 128ms/step - loss: 161.2525 - val_loss: 161.3412\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 134.6459 - val_loss: 108.2743\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 86.4104 - val_loss: 79.8693\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 74.4037 - val_loss: 69.8806\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 62.0853 - val_loss: 54.1104\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 44.9608 - val_loss: 36.6923\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 32.1041 - val_loss: 27.9135\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 26.9224 - val_loss: 23.7419\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 23.4291 - val_loss: 20.3918\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 20.4472 - val_loss: 17.7143\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 19.5170 - val_loss: 15.4888\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 17.3263 - val_loss: 13.6278\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 15.3844 - val_loss: 11.8533\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 13.7485 - val_loss: 10.4656\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 12.9135 - val_loss: 9.1063\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 11.6052 - val_loss: 7.9783\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 10.1794 - val_loss: 7.0375\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 9.1445 - val_loss: 6.1504\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 8.2016 - val_loss: 5.3703\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 7.9327 - val_loss: 4.7320\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 7.9087 - val_loss: 4.2855\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 6.7059 - val_loss: 3.7834\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 6.3801 - val_loss: 3.3028\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 5.7803 - val_loss: 2.8876\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.8716 - val_loss: 2.6493\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.9150 - val_loss: 2.4175\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 5.2376 - val_loss: 2.1650\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.4359 - val_loss: 2.1700\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.4103 - val_loss: 1.6892\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.3678 - val_loss: 1.5614\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.6620 - val_loss: 1.6227\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 4.3601 - val_loss: 1.3689\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 3.8836 - val_loss: 1.3272\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.7113 - val_loss: 1.3804\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 4.1283 - val_loss: 1.1230\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.5288 - val_loss: 1.1375\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.1947 - val_loss: 1.2002\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.3335 - val_loss: 1.1166\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.2964 - val_loss: 1.0268\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.2496 - val_loss: 1.1406\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.7864 - val_loss: 0.9481\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.9706 - val_loss: 1.2001\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.0097 - val_loss: 1.3497\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.1446 - val_loss: 1.0030\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8844 - val_loss: 0.9126\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.1301 - val_loss: 0.8847\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.9157 - val_loss: 0.9052\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6405 - val_loss: 0.9842\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.7728 - val_loss: 0.8567\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.2438 - val_loss: 0.8545\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.2795 - val_loss: 0.8032\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.5489 - val_loss: 0.7768\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.9410 - val_loss: 0.7923\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.2342 - val_loss: 0.8720\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.5580 - val_loss: 0.9674\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.1068 - val_loss: 0.7362\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.6382 - val_loss: 0.7150\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4640 - val_loss: 0.7291\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1871 - val_loss: 0.7065\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3888 - val_loss: 0.7017\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.9524 - val_loss: 0.6955\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1795 - val_loss: 0.6501\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3529 - val_loss: 0.7572\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1851 - val_loss: 0.6758\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5353 - val_loss: 1.0193\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2089 - val_loss: 0.6681\n",
      "Epoch 67/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4905 - val_loss: 0.6038\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.2491 - val_loss: 0.7145\n",
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3944 - val_loss: 0.6002\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 23ms/step - loss: 2.8681 - val_loss: 1.3018\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4886 - val_loss: 0.6106\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4339 - val_loss: 0.6662\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.7989 - val_loss: 0.5778\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.2880 - val_loss: 0.5581\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.5806 - val_loss: 0.6173\n",
      "Epoch 76/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9185 - val_loss: 0.6837\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4396 - val_loss: 0.6595\n",
      "Epoch 78/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.2351 - val_loss: 0.6303\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8895 - val_loss: 0.5707\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0847 - val_loss: 0.6785\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.6316 - val_loss: 0.6609\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.2769 - val_loss: 0.5753\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.2182 - val_loss: 0.7324\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.1678 - val_loss: 0.5639\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 2.1322 - val_loss: 0.6068\n",
      "Epoch 86/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9338 - val_loss: 0.5359\n",
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9493 - val_loss: 0.5877\n",
      "Epoch 88/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1519 - val_loss: 0.6751\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4225 - val_loss: 0.5259\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.6817 - val_loss: 0.4906\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.0430 - val_loss: 0.4923\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.9115 - val_loss: 0.4971\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8320 - val_loss: 0.5778\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.8646 - val_loss: 0.5468\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3008 - val_loss: 0.6028\n",
      "Epoch 96/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0895 - val_loss: 0.4685\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8581 - val_loss: 0.5463\n",
      "Epoch 98/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0151 - val_loss: 0.5490\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0054 - val_loss: 0.4588\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3326 - val_loss: 0.6480\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3195 - val_loss: 0.5243\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.9460 - val_loss: 0.4630\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9906 - val_loss: 0.5211\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9931 - val_loss: 0.4970\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0265 - val_loss: 0.5667\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7174 - val_loss: 0.5026\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0672 - val_loss: 0.8281\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9319 - val_loss: 0.4840\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6735 - val_loss: 0.4692\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.1750 - val_loss: 0.6253\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6638 - val_loss: 0.5194\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9519 - val_loss: 0.4496\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8711 - val_loss: 0.5022\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7836 - val_loss: 0.5449\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8499 - val_loss: 0.5319\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7511 - val_loss: 0.5077\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.2890 - val_loss: 0.4952\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.8322 - val_loss: 0.5458\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0564 - val_loss: 0.5226\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.6783 - val_loss: 0.3973\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1911 - val_loss: 0.4656\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7713 - val_loss: 0.6173\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6525 - val_loss: 0.4559\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0240 - val_loss: 0.5260\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7207 - val_loss: 0.4040\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8909 - val_loss: 0.4154\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7000 - val_loss: 0.4998\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2736 - val_loss: 0.4340\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0537 - val_loss: 0.4844\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7708 - val_loss: 0.3967\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0356 - val_loss: 0.4297\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0030 - val_loss: 0.3962\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7372 - val_loss: 0.3939\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.5569 - val_loss: 0.4292\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.5309 - val_loss: 0.4589\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.3927 - val_loss: 0.4002\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.7794 - val_loss: 0.3704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6818 - val_loss: 0.4972\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8466 - val_loss: 0.3822\n",
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9550 - val_loss: 0.3811\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8955 - val_loss: 0.4590\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9170 - val_loss: 0.3855\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0638 - val_loss: 0.4120\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8188 - val_loss: 0.5548\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9856 - val_loss: 0.4605\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.5903 - val_loss: 0.5856\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.4754 - val_loss: 0.5509\n",
      "Epoch 148/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9742 - val_loss: 0.3885\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0438 - val_loss: 0.5035\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9458 - val_loss: 0.5734\n",
      "6/6 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.5733815222782572\n",
      "Mean Absolute Error: 0.5163565170334046\n",
      "R-squared: 0.9936767904286411\n",
      "\n",
      "Fold 2:\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 14s 127ms/step - loss: 158.3263 - val_loss: 164.6985\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 127.7698 - val_loss: 107.5723\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 83.8521 - val_loss: 83.2845\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 73.4843 - val_loss: 74.0700\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 61.7760 - val_loss: 59.0223\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 46.3599 - val_loss: 42.4225\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 33.6056 - val_loss: 33.3611\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 28.4429 - val_loss: 28.8481\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 25.4399 - val_loss: 25.3509\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 22.0932 - val_loss: 22.6030\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 19.9909 - val_loss: 20.1911\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 18.3036 - val_loss: 18.0200\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 15.6113 - val_loss: 16.1568\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 14.0817 - val_loss: 14.5577\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 12.9062 - val_loss: 13.1054\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 12.1758 - val_loss: 11.8318\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 10.5759 - val_loss: 10.5921\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 9.4776 - val_loss: 9.6986\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 8.7420 - val_loss: 8.7188\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 7.5271 - val_loss: 8.0268\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 7.5550 - val_loss: 7.3012\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 6.6433 - val_loss: 6.7147\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 6.4174 - val_loss: 6.1390\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 5.7545 - val_loss: 5.6808\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 5.8843 - val_loss: 5.2850\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 5.5764 - val_loss: 4.8739\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 4.9206 - val_loss: 4.5769\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 4.4100 - val_loss: 4.2145\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.2743 - val_loss: 3.9871\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 4.5309 - val_loss: 3.7798\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.5040 - val_loss: 3.5913\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.5301 - val_loss: 3.4332\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.5471 - val_loss: 3.6419\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.4512 - val_loss: 3.2097\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.2068 - val_loss: 3.1327\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.1792 - val_loss: 3.0583\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 3.2435 - val_loss: 3.0006\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.1756 - val_loss: 2.7497\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.1776 - val_loss: 2.6912\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.9765 - val_loss: 2.5812\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.1177 - val_loss: 2.5197\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.7645 - val_loss: 2.6088\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8567 - val_loss: 2.4484\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.3123 - val_loss: 2.4515\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.7025 - val_loss: 2.3245\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8900 - val_loss: 2.3038\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.6568 - val_loss: 2.3439\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4974 - val_loss: 2.1523\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2660 - val_loss: 2.1191\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8229 - val_loss: 2.2506\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8045 - val_loss: 2.2964\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.7963 - val_loss: 2.2195\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4621 - val_loss: 1.9389\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.5934 - val_loss: 1.9540\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.9864 - val_loss: 1.9608\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5768 - val_loss: 1.8803\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.2755 - val_loss: 1.8327\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3592 - val_loss: 1.8094\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5258 - val_loss: 1.8565\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0342 - val_loss: 1.7490\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8410 - val_loss: 1.7911\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2419 - val_loss: 1.6855\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9382 - val_loss: 1.6873\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8352 - val_loss: 1.6165\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.3350 - val_loss: 1.7694\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.4376 - val_loss: 1.6953\n",
      "Epoch 67/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 17ms/step - loss: 2.3386 - val_loss: 1.6255\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3306 - val_loss: 1.5565\n",
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1816 - val_loss: 1.5630\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2894 - val_loss: 1.6604\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0087 - val_loss: 1.6227\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9771 - val_loss: 1.5230\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8057 - val_loss: 1.4222\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0453 - val_loss: 1.4217\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0113 - val_loss: 1.3773\n",
      "Epoch 76/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0289 - val_loss: 1.4492\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1001 - val_loss: 1.4017\n",
      "Epoch 78/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9065 - val_loss: 1.3913\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1268 - val_loss: 1.5008\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0484 - val_loss: 1.3398\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9580 - val_loss: 1.3690\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1954 - val_loss: 1.2957\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2104 - val_loss: 1.3799\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7820 - val_loss: 1.2782\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9807 - val_loss: 1.3438\n",
      "Epoch 86/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6535 - val_loss: 1.2413\n",
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0310 - val_loss: 1.2833\n",
      "Epoch 88/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7663 - val_loss: 1.5622\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7671 - val_loss: 1.2813\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6941 - val_loss: 1.1964\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1262 - val_loss: 1.2095\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8837 - val_loss: 1.1693\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0298 - val_loss: 1.1503\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0223 - val_loss: 1.1682\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0338 - val_loss: 1.3205\n",
      "Epoch 96/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0883 - val_loss: 1.1565\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7559 - val_loss: 1.2105\n",
      "Epoch 98/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8982 - val_loss: 1.1232\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1468 - val_loss: 1.1589\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9079 - val_loss: 1.1325\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6557 - val_loss: 1.0815\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0924 - val_loss: 1.1115\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7760 - val_loss: 1.1255\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.6521 - val_loss: 1.0716\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7897 - val_loss: 1.0528\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0722 - val_loss: 1.1037\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8986 - val_loss: 1.0260\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0475 - val_loss: 1.0545\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5142 - val_loss: 1.0552\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7635 - val_loss: 1.0070\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7823 - val_loss: 1.0445\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7903 - val_loss: 1.1064\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6472 - val_loss: 1.0886\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6876 - val_loss: 1.1072\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7969 - val_loss: 1.0788\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7981 - val_loss: 0.9908\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8397 - val_loss: 1.1259\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9038 - val_loss: 0.9983\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3396 - val_loss: 1.0731\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7605 - val_loss: 0.9229\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8734 - val_loss: 0.9380\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0533 - val_loss: 0.9384\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9335 - val_loss: 0.9094\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6809 - val_loss: 1.0802\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8811 - val_loss: 1.0802\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8908 - val_loss: 0.9172\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5292 - val_loss: 0.8936\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6646 - val_loss: 0.9392\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7575 - val_loss: 0.8968\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6499 - val_loss: 0.8745\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1291 - val_loss: 0.9898\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7708 - val_loss: 0.9461\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9233 - val_loss: 0.9542\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9344 - val_loss: 0.9440\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7745 - val_loss: 0.8437\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7992 - val_loss: 0.8571\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4406 - val_loss: 0.8108\n",
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8824 - val_loss: 0.8282\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6604 - val_loss: 0.8689\n",
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7507 - val_loss: 0.8824\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9649 - val_loss: 0.8858\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9398 - val_loss: 0.8857\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9114 - val_loss: 1.0455\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7168 - val_loss: 0.8142\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5770 - val_loss: 1.0034\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6341 - val_loss: 0.9039\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5156 - val_loss: 0.8545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 148/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7993 - val_loss: 0.7934\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8634 - val_loss: 0.8147\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5582 - val_loss: 0.9293\n",
      "6/6 [==============================] - 2s 6ms/step\n",
      "Mean Squared Error: 0.9292731194432704\n",
      "Mean Absolute Error: 0.5832241889202233\n",
      "R-squared: 0.9901314712924209\n",
      "\n",
      "Fold 3:\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 15s 128ms/step - loss: 162.8658 - val_loss: 148.7671\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 132.0331 - val_loss: 97.2017\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 87.8816 - val_loss: 76.4090\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 78.3058 - val_loss: 69.2861\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 66.9380 - val_loss: 55.3479\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 50.2024 - val_loss: 37.0924\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 35.1458 - val_loss: 26.7050\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 27.1631 - val_loss: 22.6210\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 22.3881 - val_loss: 19.8990\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 20.5521 - val_loss: 17.5255\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 16.9488 - val_loss: 15.4950\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 17.0947 - val_loss: 13.7234\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 14.0526 - val_loss: 12.2021\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 13.2338 - val_loss: 10.9241\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 12.2873 - val_loss: 9.8277\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 10.6790 - val_loss: 8.9474\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 9.4292 - val_loss: 7.9980\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 9.2268 - val_loss: 7.2523\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 7.8669 - val_loss: 6.5399\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 7.2729 - val_loss: 6.1024\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 7.4477 - val_loss: 5.4942\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 6.1329 - val_loss: 4.9972\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 5.7267 - val_loss: 4.5934\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 5.4021 - val_loss: 4.3623\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 5.4680 - val_loss: 3.9921\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 4.9327 - val_loss: 3.7529\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.5663 - val_loss: 3.4350\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 4.1637 - val_loss: 3.1965\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 4.3522 - val_loss: 3.0007\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.9279 - val_loss: 2.8397\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 3.4419 - val_loss: 2.7926\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.1652 - val_loss: 2.5976\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.3665 - val_loss: 2.4651\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.7640 - val_loss: 2.4445\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.5796 - val_loss: 2.3686\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.1952 - val_loss: 2.2082\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.1156 - val_loss: 2.2951\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.3479 - val_loss: 2.1553\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 3.0761 - val_loss: 2.0526\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.0948 - val_loss: 1.9992\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.0348 - val_loss: 1.8736\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.9389 - val_loss: 1.8347\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.9522 - val_loss: 1.8386\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.6481 - val_loss: 1.8826\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.1478 - val_loss: 1.6631\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.9802 - val_loss: 1.6519\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.6248 - val_loss: 1.5705\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.7692 - val_loss: 1.6195\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5312 - val_loss: 1.5082\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.7141 - val_loss: 1.5215\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.7489 - val_loss: 1.4545\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.7157 - val_loss: 1.4624\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5838 - val_loss: 1.3544\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4317 - val_loss: 1.3432\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3725 - val_loss: 1.3196\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.5780 - val_loss: 1.2605\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.5064 - val_loss: 1.3383\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.6420 - val_loss: 1.3173\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.2912 - val_loss: 1.2608\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4434 - val_loss: 1.1900\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3184 - val_loss: 1.1690\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.7342 - val_loss: 1.1330\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3727 - val_loss: 1.1194\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.7420 - val_loss: 1.1006\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2155 - val_loss: 1.1661\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0087 - val_loss: 1.0673\n",
      "Epoch 67/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3122 - val_loss: 1.0501\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3761 - val_loss: 1.0218\n",
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5134 - val_loss: 1.0036\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0862 - val_loss: 1.0228\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0504 - val_loss: 1.0205\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.2533 - val_loss: 0.9803\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3609 - val_loss: 1.0432\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3858 - val_loss: 0.9159\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8772 - val_loss: 0.8872\n",
      "Epoch 76/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3948 - val_loss: 0.8767\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1834 - val_loss: 0.9308\n",
      "Epoch 78/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1494 - val_loss: 0.9482\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0935 - val_loss: 0.9519\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1514 - val_loss: 0.9632\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1413 - val_loss: 0.8330\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2057 - val_loss: 0.8669\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4539 - val_loss: 0.8434\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9100 - val_loss: 0.7983\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8578 - val_loss: 0.7757\n",
      "Epoch 86/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9686 - val_loss: 0.7554\n",
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8210 - val_loss: 0.7508\n",
      "Epoch 88/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2673 - val_loss: 0.7649\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3299 - val_loss: 0.8297\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9638 - val_loss: 0.8679\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9335 - val_loss: 0.7389\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1160 - val_loss: 0.6825\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1096 - val_loss: 0.7020\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0376 - val_loss: 0.7981\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1575 - val_loss: 0.7343\n",
      "Epoch 96/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1899 - val_loss: 0.7903\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1922 - val_loss: 0.7349\n",
      "Epoch 98/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7951 - val_loss: 0.7029\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8449 - val_loss: 0.7005\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8867 - val_loss: 0.6355\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9208 - val_loss: 0.6411\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1351 - val_loss: 0.6763\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1352 - val_loss: 0.6495\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7822 - val_loss: 0.6251\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1700 - val_loss: 0.6313\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6609 - val_loss: 0.6358\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.0152 - val_loss: 0.7491\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0238 - val_loss: 0.6325\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2042 - val_loss: 0.6149\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.2261 - val_loss: 0.7400\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0897 - val_loss: 0.6131\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8858 - val_loss: 0.7111\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0727 - val_loss: 0.5646\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8969 - val_loss: 0.6126\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9698 - val_loss: 0.6444\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1064 - val_loss: 0.5766\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9294 - val_loss: 0.5581\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9543 - val_loss: 0.6041\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2294 - val_loss: 0.5386\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0285 - val_loss: 0.6090\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9558 - val_loss: 0.5572\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.5920 - val_loss: 0.6207\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.6357 - val_loss: 0.6830\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.8875 - val_loss: 0.5289\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8796 - val_loss: 0.5304\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9178 - val_loss: 0.5560\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7253 - val_loss: 0.5019\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9541 - val_loss: 0.5264\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.6783 - val_loss: 0.5336\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7080 - val_loss: 0.4913\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7591 - val_loss: 0.6233\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1686 - val_loss: 0.7633\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7259 - val_loss: 0.4965\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9050 - val_loss: 0.5069\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9907 - val_loss: 0.4766\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7289 - val_loss: 0.4702\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.5179 - val_loss: 0.4953\n",
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1287 - val_loss: 0.4876\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9466 - val_loss: 0.6839\n",
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.8243 - val_loss: 0.4708\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.1355 - val_loss: 0.8031\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.9226 - val_loss: 0.4908\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.2704 - val_loss: 0.4713\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8476 - val_loss: 0.4704\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.6813 - val_loss: 0.4847\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.6486 - val_loss: 0.6096\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8358 - val_loss: 0.4831\n",
      "Epoch 148/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8605 - val_loss: 0.6491\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0160 - val_loss: 0.7228\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9052 - val_loss: 0.4648\n",
      "6/6 [==============================] - 2s 6ms/step\n",
      "Mean Squared Error: 0.46482325910118116\n",
      "Mean Absolute Error: 0.3673790180321896\n",
      "R-squared: 0.994484498957715\n",
      "\n",
      "Fold 4:\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 14s 141ms/step - loss: 172.8339 - val_loss: 111.6768\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 142.0742 - val_loss: 70.6649\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 92.4362 - val_loss: 58.3684\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 79.0231 - val_loss: 50.1300\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 65.7703 - val_loss: 34.0250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 48.7358 - val_loss: 21.6855\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 35.8977 - val_loss: 16.3105\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 30.1395 - val_loss: 13.8786\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 25.3564 - val_loss: 12.1676\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 23.0478 - val_loss: 10.7807\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 20.4037 - val_loss: 9.4589\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 18.3467 - val_loss: 8.3575\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 16.9511 - val_loss: 7.3977\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 14.7910 - val_loss: 6.5706\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 13.0429 - val_loss: 5.8161\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 12.5611 - val_loss: 5.1794\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 11.3074 - val_loss: 4.7442\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 9.9339 - val_loss: 4.2029\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 9.4149 - val_loss: 3.7485\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 8.1764 - val_loss: 3.4108\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 7.6990 - val_loss: 3.1436\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 7.3911 - val_loss: 2.7994\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 6.8927 - val_loss: 2.5552\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 6.0573 - val_loss: 2.3927\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 5.7939 - val_loss: 2.4630\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 5.0405 - val_loss: 2.3391\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 5.0839 - val_loss: 2.0238\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.6750 - val_loss: 1.9335\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 4.1261 - val_loss: 1.8633\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.3208 - val_loss: 1.6616\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.4157 - val_loss: 1.9309\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.9092 - val_loss: 1.6338\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.8847 - val_loss: 1.5887\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.1223 - val_loss: 1.6382\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.5665 - val_loss: 1.4662\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.8115 - val_loss: 1.4303\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 3.4680 - val_loss: 1.2499\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.6247 - val_loss: 1.2385\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.5852 - val_loss: 1.2375\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.2156 - val_loss: 1.2579\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.3646 - val_loss: 1.1557\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.4516 - val_loss: 1.0995\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.3654 - val_loss: 1.2160\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.9556 - val_loss: 1.3493\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.0503 - val_loss: 1.2339\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.1485 - val_loss: 1.0921\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.7519 - val_loss: 0.9621\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5723 - val_loss: 0.9441\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6672 - val_loss: 0.9607\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8276 - val_loss: 0.9062\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8465 - val_loss: 0.8851\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6441 - val_loss: 0.8843\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.7430 - val_loss: 0.8618\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5160 - val_loss: 0.8967\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.9962 - val_loss: 0.8040\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6222 - val_loss: 0.8512\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4073 - val_loss: 0.8317\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5373 - val_loss: 0.7264\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2829 - val_loss: 0.8815\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1783 - val_loss: 0.7427\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4706 - val_loss: 1.0244\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5908 - val_loss: 0.7755\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6742 - val_loss: 0.6636\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2761 - val_loss: 0.6954\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4492 - val_loss: 0.6572\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4006 - val_loss: 0.8232\n",
      "Epoch 67/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2906 - val_loss: 0.6482\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1559 - val_loss: 0.6455\n",
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5044 - val_loss: 0.7095\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6156 - val_loss: 0.6054\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1697 - val_loss: 0.6434\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3952 - val_loss: 0.5870\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6308 - val_loss: 0.6826\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4925 - val_loss: 0.5459\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.2537 - val_loss: 0.7238\n",
      "Epoch 76/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6976 - val_loss: 0.7083\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1776 - val_loss: 0.5662\n",
      "Epoch 78/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2802 - val_loss: 0.6501\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2472 - val_loss: 0.5420\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.2871 - val_loss: 0.6589\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0552 - val_loss: 0.5958\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4263 - val_loss: 0.5015\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9052 - val_loss: 0.5231\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1212 - val_loss: 0.5276\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.3121 - val_loss: 0.5345\n",
      "Epoch 86/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9602 - val_loss: 0.5443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2848 - val_loss: 0.5800\n",
      "Epoch 88/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0481 - val_loss: 0.5314\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2145 - val_loss: 0.4303\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0252 - val_loss: 0.4865\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4906 - val_loss: 0.4217\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0282 - val_loss: 0.4431\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2470 - val_loss: 0.4741\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7244 - val_loss: 0.4806\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0101 - val_loss: 0.5983\n",
      "Epoch 96/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8892 - val_loss: 0.4338\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8347 - val_loss: 0.3733\n",
      "Epoch 98/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0982 - val_loss: 0.3678\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7117 - val_loss: 0.4393\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6857 - val_loss: 0.4578\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2474 - val_loss: 0.4018\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0126 - val_loss: 0.3683\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1035 - val_loss: 0.4323\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1839 - val_loss: 0.3803\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8122 - val_loss: 0.4138\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2227 - val_loss: 0.5229\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.2643 - val_loss: 0.4005\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5196 - val_loss: 0.4199\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1228 - val_loss: 0.3807\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0380 - val_loss: 0.3732\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.5218 - val_loss: 0.4586\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0544 - val_loss: 0.3214\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8277 - val_loss: 0.4068\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7081 - val_loss: 0.3209\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.5226 - val_loss: 0.3869\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1416 - val_loss: 0.4311\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9703 - val_loss: 0.3274\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1796 - val_loss: 0.3262\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.0047 - val_loss: 0.3287\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.0464 - val_loss: 0.3042\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9242 - val_loss: 0.4135\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.9932 - val_loss: 0.3634\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.7707 - val_loss: 0.3602\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.5679 - val_loss: 0.3749\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.4849 - val_loss: 0.3335\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.9405 - val_loss: 0.2997\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.2413 - val_loss: 0.3614\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.0656 - val_loss: 0.3892\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.5134 - val_loss: 0.3706\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0465 - val_loss: 0.2999\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8035 - val_loss: 0.3268\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9349 - val_loss: 0.4660\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2290 - val_loss: 0.2736\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2512 - val_loss: 0.3207\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9174 - val_loss: 0.6216\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8215 - val_loss: 0.3828\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2547 - val_loss: 0.2544\n",
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.5091 - val_loss: 0.2742\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7639 - val_loss: 0.3398\n",
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2084 - val_loss: 0.3741\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1925 - val_loss: 0.2492\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8054 - val_loss: 0.2640\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8443 - val_loss: 0.2990\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9898 - val_loss: 0.4137\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7528 - val_loss: 0.2762\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9060 - val_loss: 0.2437\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6655 - val_loss: 0.2993\n",
      "Epoch 148/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8736 - val_loss: 0.3423\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0386 - val_loss: 0.2704\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1369 - val_loss: 0.4678\n",
      "6/6 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.46783403990980615\n",
      "Mean Absolute Error: 0.41788767540093624\n",
      "R-squared: 0.9928405576564652\n",
      "\n",
      "Fold 5:\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 15s 126ms/step - loss: 156.5705 - val_loss: 180.2343\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 130.8399 - val_loss: 127.7626\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 86.6734 - val_loss: 94.9108\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 75.9667 - val_loss: 88.7015\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 68.1404 - val_loss: 76.3767\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 52.7383 - val_loss: 57.9444\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 38.7107 - val_loss: 45.0223\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 30.6727 - val_loss: 38.1351\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 25.5345 - val_loss: 33.5457\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 23.3304 - val_loss: 30.3276\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 20.3095 - val_loss: 27.1730\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 17.7269 - val_loss: 24.4185\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 16.2995 - val_loss: 22.0164\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 14.2131 - val_loss: 19.8249\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 12.7303 - val_loss: 18.1272\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 12.2895 - val_loss: 16.3413\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 11.3932 - val_loss: 14.8816\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 10.3351 - val_loss: 13.4936\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 9.8177 - val_loss: 12.3066\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 8.5770 - val_loss: 11.2049\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 8.1049 - val_loss: 10.3086\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 6.9624 - val_loss: 9.3673\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 6.5660 - val_loss: 8.7532\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 6.5614 - val_loss: 8.0771\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 5.9804 - val_loss: 7.3744\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 5.4024 - val_loss: 6.6868\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 5.5779 - val_loss: 6.1857\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.9662 - val_loss: 5.8369\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.1852 - val_loss: 5.3958\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.8943 - val_loss: 4.9771\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 4.0250 - val_loss: 4.6817\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.1334 - val_loss: 4.4023\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.8939 - val_loss: 4.1650\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.0536 - val_loss: 3.9208\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.7395 - val_loss: 3.7891\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.5583 - val_loss: 3.6126\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.4087 - val_loss: 3.4110\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.4817 - val_loss: 3.3319\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.6604 - val_loss: 3.2223\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.4259 - val_loss: 3.1193\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6931 - val_loss: 2.9314\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.7025 - val_loss: 2.9134\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4199 - val_loss: 2.7987\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.2690 - val_loss: 2.7921\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.9266 - val_loss: 2.6181\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6547 - val_loss: 2.6076\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6805 - val_loss: 2.6332\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3675 - val_loss: 2.4211\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.5878 - val_loss: 2.4416\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.5066 - val_loss: 2.4477\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5494 - val_loss: 2.2876\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.7691 - val_loss: 2.6236\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.6633 - val_loss: 2.1832\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5592 - val_loss: 2.1216\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3424 - val_loss: 2.1338\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0959 - val_loss: 2.0362\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1502 - val_loss: 2.0006\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0540 - val_loss: 1.9679\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0869 - val_loss: 2.1449\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.6060 - val_loss: 1.9554\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1098 - val_loss: 2.0890\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2505 - val_loss: 2.0261\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.2196 - val_loss: 1.8407\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4360 - val_loss: 1.8672\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2489 - val_loss: 1.8839\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5802 - val_loss: 1.7172\n",
      "Epoch 67/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2609 - val_loss: 1.6990\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1485 - val_loss: 1.7165\n",
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1342 - val_loss: 1.7805\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3192 - val_loss: 1.6282\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3877 - val_loss: 1.5864\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0172 - val_loss: 1.5378\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1433 - val_loss: 1.6881\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0349 - val_loss: 1.6012\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4913 - val_loss: 1.4830\n",
      "Epoch 76/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1863 - val_loss: 1.5049\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8919 - val_loss: 1.4713\n",
      "Epoch 78/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2260 - val_loss: 1.4768\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0644 - val_loss: 1.4231\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3167 - val_loss: 1.5253\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4684 - val_loss: 1.3352\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2272 - val_loss: 1.4628\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.3890 - val_loss: 1.5029\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8852 - val_loss: 1.3111\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9746 - val_loss: 1.2933\n",
      "Epoch 86/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3352 - val_loss: 1.2989\n",
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6969 - val_loss: 1.3042\n",
      "Epoch 88/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9467 - val_loss: 1.2225\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9834 - val_loss: 1.4353\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1815 - val_loss: 1.2231\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9823 - val_loss: 1.1740\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0838 - val_loss: 1.1596\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9894 - val_loss: 1.6307\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0342 - val_loss: 1.3393\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1800 - val_loss: 1.1231\n",
      "Epoch 96/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9363 - val_loss: 1.1031\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7911 - val_loss: 1.1785\n",
      "Epoch 98/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9002 - val_loss: 1.1165\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1661 - val_loss: 1.1261\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8471 - val_loss: 1.1052\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8093 - val_loss: 1.1151\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.6631 - val_loss: 1.2345\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8302 - val_loss: 1.0774\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.5890 - val_loss: 1.0244\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7095 - val_loss: 1.0190\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7222 - val_loss: 1.1101\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.5966 - val_loss: 1.1318\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4917 - val_loss: 1.0570\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9039 - val_loss: 1.2044\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4944 - val_loss: 1.2116\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8085 - val_loss: 1.1138\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8984 - val_loss: 0.9791\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6494 - val_loss: 1.1372\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0282 - val_loss: 1.0432\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6878 - val_loss: 0.9292\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.6492 - val_loss: 0.9964\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6814 - val_loss: 0.9152\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9108 - val_loss: 0.9376\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4038 - val_loss: 1.0699\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6397 - val_loss: 0.9215\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7089 - val_loss: 0.9067\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.5544 - val_loss: 0.9007\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7000 - val_loss: 0.9044\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7240 - val_loss: 0.9355\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.8628 - val_loss: 0.8924\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7864 - val_loss: 0.8720\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5203 - val_loss: 0.8862\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.5422 - val_loss: 0.8449\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1719 - val_loss: 0.9516\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7103 - val_loss: 0.9679\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0302 - val_loss: 0.9585\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7840 - val_loss: 0.8477\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5066 - val_loss: 0.8366\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9429 - val_loss: 0.8965\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.6584 - val_loss: 0.8906\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1233 - val_loss: 1.0488\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6404 - val_loss: 0.8215\n",
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6303 - val_loss: 0.8196\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8936 - val_loss: 0.9047\n",
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6549 - val_loss: 0.7992\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7598 - val_loss: 0.8052\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6880 - val_loss: 0.7682\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.5652 - val_loss: 0.7707\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8271 - val_loss: 0.7714\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7981 - val_loss: 0.7621\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7701 - val_loss: 0.8426\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6509 - val_loss: 0.8664\n",
      "Epoch 148/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6833 - val_loss: 0.7893\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6076 - val_loss: 0.7979\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7293 - val_loss: 0.7823\n",
      "6/6 [==============================] - 2s 6ms/step\n",
      "Mean Squared Error: 0.7823387488198164\n",
      "Mean Absolute Error: 0.5348408749609282\n",
      "R-squared: 0.99243104972055\n",
      "\n",
      "Average scores for ticker AMWL:\n",
      "Mean Squared Error: 0.6435301379104663\n",
      "Mean Absolute Error: 0.48393765486953644\n",
      "R-squared: 0.9927128736111583\n",
      "\n",
      "Cross-validation for ticker: GEO\n",
      "Fold 1:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 134ms/step - loss: 79.9802 - val_loss: 58.5488\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 34.5796 - val_loss: 5.6206\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.6698 - val_loss: 5.1485\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.5250 - val_loss: 4.1037\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.1675 - val_loss: 3.8394\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.9981 - val_loss: 3.4516\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.3916 - val_loss: 2.9423\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9364 - val_loss: 2.3219\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.0795 - val_loss: 1.4370\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 2.2589 - val_loss: 0.9936\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.8977 - val_loss: 0.8084\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 1.8765 - val_loss: 0.7284\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.6528 - val_loss: 0.6548\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.6574 - val_loss: 0.6059\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.5708 - val_loss: 0.6407\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.4910 - val_loss: 0.5092\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 1.4315 - val_loss: 0.5375\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.4426 - val_loss: 0.4806\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.3845 - val_loss: 0.4304\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.3185 - val_loss: 0.3972\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.3154 - val_loss: 0.3701\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1381 - val_loss: 0.3711\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.2919 - val_loss: 0.3391\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1661 - val_loss: 0.3244\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.2014 - val_loss: 0.3236\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1402 - val_loss: 0.2958\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1359 - val_loss: 0.2842\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1817 - val_loss: 0.2945\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0531 - val_loss: 0.2547\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0832 - val_loss: 0.2376\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1157 - val_loss: 0.2340\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0759 - val_loss: 0.2211\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0113 - val_loss: 0.2148\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0440 - val_loss: 0.1993\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9222 - val_loss: 0.1951\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9915 - val_loss: 0.1845\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9922 - val_loss: 0.2107\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9520 - val_loss: 0.1845\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8511 - val_loss: 0.1714\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9051 - val_loss: 0.1579\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7935 - val_loss: 0.2043\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8523 - val_loss: 0.1478\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8449 - val_loss: 0.1446\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9035 - val_loss: 0.1720\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8751 - val_loss: 0.1578\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8226 - val_loss: 0.1334\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8768 - val_loss: 0.1422\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9068 - val_loss: 0.1265\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7702 - val_loss: 0.1516\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8941 - val_loss: 0.1566\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8203 - val_loss: 0.1385\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7727 - val_loss: 0.1146\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7647 - val_loss: 0.1191\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8896 - val_loss: 0.1628\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7395 - val_loss: 0.1125\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7835 - val_loss: 0.1144\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8349 - val_loss: 0.1157\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7644 - val_loss: 0.1091\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8011 - val_loss: 0.1260\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7699 - val_loss: 0.1065\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6593 - val_loss: 0.1084\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7900 - val_loss: 0.1082\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.7268 - val_loss: 0.1015\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7697 - val_loss: 0.1116\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8185 - val_loss: 0.0994\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7959 - val_loss: 0.1126\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6998 - val_loss: 0.1006\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7486 - val_loss: 0.1000\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7317 - val_loss: 0.1056\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6952 - val_loss: 0.0945\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7144 - val_loss: 0.0939\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7121 - val_loss: 0.0909\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7285 - val_loss: 0.1151\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6553 - val_loss: 0.0881\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7445 - val_loss: 0.0939\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8270 - val_loss: 0.0905\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7148 - val_loss: 0.1590\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7068 - val_loss: 0.1849\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6415 - val_loss: 0.1135\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7023 - val_loss: 0.0832\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7507 - val_loss: 0.0853\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7271 - val_loss: 0.1225\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6455 - val_loss: 0.1052\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7302 - val_loss: 0.0839\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6956 - val_loss: 0.0966\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6114 - val_loss: 0.1263\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6617 - val_loss: 0.0888\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6498 - val_loss: 0.0879\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6814 - val_loss: 0.0982\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6831 - val_loss: 0.1149\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6260 - val_loss: 0.0827\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6251 - val_loss: 0.0940\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6898 - val_loss: 0.0978\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6602 - val_loss: 0.0950\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7039 - val_loss: 0.1162\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5820 - val_loss: 0.0881\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6338 - val_loss: 0.0831\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7124 - val_loss: 0.1128\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6150 - val_loss: 0.0876\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6293 - val_loss: 0.0815\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.5430 - val_loss: 0.1212\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6638 - val_loss: 0.0830\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6258 - val_loss: 0.1160\n",
      "Epoch 104/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6092 - val_loss: 0.0785\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6737 - val_loss: 0.0769\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6277 - val_loss: 0.0807\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6159 - val_loss: 0.1246\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5863 - val_loss: 0.0809\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6006 - val_loss: 0.1205\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6816 - val_loss: 0.0765\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6268 - val_loss: 0.0709\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6154 - val_loss: 0.0710\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6331 - val_loss: 0.0775\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6296 - val_loss: 0.0838\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6693 - val_loss: 0.0844\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5469 - val_loss: 0.0788\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5960 - val_loss: 0.0781\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6883 - val_loss: 0.0736\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6944 - val_loss: 0.0767\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6022 - val_loss: 0.1193\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5991 - val_loss: 0.0833\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5830 - val_loss: 0.0960\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6349 - val_loss: 0.0902\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5055 - val_loss: 0.0710\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6248 - val_loss: 0.0778\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6483 - val_loss: 0.1159\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6139 - val_loss: 0.0800\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5703 - val_loss: 0.0999\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5495 - val_loss: 0.0987\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6012 - val_loss: 0.1281\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6518 - val_loss: 0.1034\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5952 - val_loss: 0.0894\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5571 - val_loss: 0.0854\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5923 - val_loss: 0.0912\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5918 - val_loss: 0.0954\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6060 - val_loss: 0.0809\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5857 - val_loss: 0.0755\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5582 - val_loss: 0.0687\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5417 - val_loss: 0.0716\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6154 - val_loss: 0.0783\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5743 - val_loss: 0.0789\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5525 - val_loss: 0.0838\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5754 - val_loss: 0.0846\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6307 - val_loss: 0.1094\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6610 - val_loss: 0.0721\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6101 - val_loss: 0.0861\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5645 - val_loss: 0.0715\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5829 - val_loss: 0.0947\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5422 - val_loss: 0.1470\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6010 - val_loss: 0.0922\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.09218488595776525\n",
      "Mean Absolute Error: 0.2012461453527953\n",
      "R-squared: 0.9835648266118558\n",
      "\n",
      "Fold 2:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 106ms/step - loss: 79.0465 - val_loss: 70.0454\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 37.3424 - val_loss: 9.4007\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.7283 - val_loss: 5.6551\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.1158 - val_loss: 5.2514\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.7263 - val_loss: 4.9278\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6137 - val_loss: 4.4652\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.1046 - val_loss: 3.8642\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5105 - val_loss: 3.0272\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 2.8281 - val_loss: 2.1240\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 2.2074 - val_loss: 1.4812\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.6736 - val_loss: 1.2822\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.6340 - val_loss: 1.1462\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.7519 - val_loss: 1.0237\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.5933 - val_loss: 0.9688\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.6342 - val_loss: 0.8954\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.4889 - val_loss: 0.8541\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.5515 - val_loss: 0.8050\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.4397 - val_loss: 0.7319\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.3392 - val_loss: 0.7467\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.2674 - val_loss: 0.6444\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.2214 - val_loss: 0.6118\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.2588 - val_loss: 0.5845\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.2591 - val_loss: 0.5321\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.2480 - val_loss: 0.4901\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1745 - val_loss: 0.4853\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1052 - val_loss: 0.4407\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1054 - val_loss: 0.4470\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0491 - val_loss: 0.4220\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1796 - val_loss: 0.3714\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 1.0449 - val_loss: 0.3587\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0840 - val_loss: 0.3801\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0529 - val_loss: 0.4080\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0081 - val_loss: 0.3140\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0147 - val_loss: 0.4049\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9819 - val_loss: 0.3021\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8837 - val_loss: 0.2487\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9198 - val_loss: 0.2347\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8722 - val_loss: 0.2187\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8964 - val_loss: 0.2050\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9275 - val_loss: 0.2017\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8684 - val_loss: 0.2097\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9718 - val_loss: 0.1872\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9228 - val_loss: 0.1699\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8602 - val_loss: 0.1588\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8566 - val_loss: 0.1652\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8638 - val_loss: 0.1802\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8496 - val_loss: 0.1476\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8408 - val_loss: 0.1435\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8402 - val_loss: 0.1424\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7704 - val_loss: 0.1351\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7160 - val_loss: 0.1472\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7570 - val_loss: 0.1426\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7675 - val_loss: 0.1401\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7537 - val_loss: 0.1310\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8117 - val_loss: 0.1269\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7728 - val_loss: 0.1255\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7335 - val_loss: 0.1139\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7117 - val_loss: 0.2118\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8016 - val_loss: 0.1523\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8285 - val_loss: 0.1216\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7871 - val_loss: 0.1215\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7638 - val_loss: 0.1321\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6285 - val_loss: 0.1298\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6441 - val_loss: 0.1103\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6917 - val_loss: 0.1103\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6689 - val_loss: 0.1108\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6599 - val_loss: 0.1348\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6727 - val_loss: 0.1373\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7243 - val_loss: 0.1170\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6721 - val_loss: 0.1186\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7252 - val_loss: 0.1400\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6737 - val_loss: 0.1228\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6279 - val_loss: 0.1270\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6482 - val_loss: 0.1139\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6857 - val_loss: 0.1068\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6531 - val_loss: 0.1062\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7331 - val_loss: 0.1159\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6205 - val_loss: 0.1282\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6050 - val_loss: 0.1378\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7686 - val_loss: 0.1820\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6656 - val_loss: 0.1198\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7176 - val_loss: 0.1191\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7317 - val_loss: 0.1540\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6210 - val_loss: 0.1639\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6391 - val_loss: 0.1060\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6115 - val_loss: 0.1143\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7496 - val_loss: 0.1180\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6672 - val_loss: 0.1193\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5923 - val_loss: 0.1111\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6412 - val_loss: 0.1260\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6377 - val_loss: 0.1182\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6109 - val_loss: 0.1029\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5831 - val_loss: 0.1400\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6611 - val_loss: 0.1184\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5983 - val_loss: 0.1103\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6270 - val_loss: 0.1078\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6434 - val_loss: 0.1211\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6790 - val_loss: 0.2377\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6731 - val_loss: 0.1396\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7036 - val_loss: 0.1328\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6450 - val_loss: 0.1767\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6410 - val_loss: 0.1239\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5685 - val_loss: 0.1123\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6128 - val_loss: 0.1264\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6207 - val_loss: 0.1072\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6223 - val_loss: 0.1271\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5886 - val_loss: 0.1311\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6199 - val_loss: 0.1113\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6091 - val_loss: 0.1195\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5870 - val_loss: 0.1155\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5787 - val_loss: 0.1032\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5892 - val_loss: 0.1126\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5455 - val_loss: 0.1359\n",
      "Epoch 114/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6054 - val_loss: 0.1079\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5785 - val_loss: 0.1218\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6529 - val_loss: 0.1161\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6374 - val_loss: 0.1118\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5774 - val_loss: 0.1098\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6026 - val_loss: 0.1148\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5729 - val_loss: 0.0980\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5565 - val_loss: 0.0994\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5769 - val_loss: 0.1074\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5983 - val_loss: 0.1118\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5891 - val_loss: 0.1117\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6090 - val_loss: 0.1271\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5735 - val_loss: 0.1301\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5629 - val_loss: 0.1130\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5505 - val_loss: 0.1124\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5418 - val_loss: 0.1082\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5451 - val_loss: 0.1184\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5423 - val_loss: 0.1197\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6503 - val_loss: 0.1272\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5897 - val_loss: 0.1257\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5963 - val_loss: 0.1234\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5855 - val_loss: 0.1326\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5626 - val_loss: 0.1271\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5581 - val_loss: 0.1263\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5605 - val_loss: 0.1325\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5700 - val_loss: 0.1761\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5723 - val_loss: 0.1491\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5737 - val_loss: 0.1487\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5704 - val_loss: 0.1673\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5641 - val_loss: 0.1289\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5945 - val_loss: 0.1294\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5296 - val_loss: 0.1318\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5055 - val_loss: 0.1496\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5592 - val_loss: 0.1546\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5082 - val_loss: 0.1300\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5387 - val_loss: 0.1201\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4950 - val_loss: 0.1297\n",
      "7/7 [==============================] - 2s 6ms/step\n",
      "Mean Squared Error: 0.12969473458947417\n",
      "Mean Absolute Error: 0.20899423675157544\n",
      "R-squared: 0.9819733548896991\n",
      "\n",
      "Fold 3:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 101ms/step - loss: 78.9967 - val_loss: 63.8915\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 34.0829 - val_loss: 7.1008\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.9165 - val_loss: 5.6518\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.1735 - val_loss: 4.8939\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.9382 - val_loss: 4.5225\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5386 - val_loss: 3.9809\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.1801 - val_loss: 3.2364\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.1668 - val_loss: 2.2426\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 2.5674 - val_loss: 1.4082\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 2.0441 - val_loss: 1.0918\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.7492 - val_loss: 0.9873\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.7782 - val_loss: 0.9169\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.6883 - val_loss: 0.8398\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.5800 - val_loss: 0.7776\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.4389 - val_loss: 0.7352\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.5244 - val_loss: 0.6823\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.4533 - val_loss: 0.6405\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.4752 - val_loss: 0.5885\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.2896 - val_loss: 0.5421\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.4063 - val_loss: 0.5059\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.2350 - val_loss: 0.4719\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 1.1309 - val_loss: 0.4688\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.2307 - val_loss: 0.4289\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0854 - val_loss: 0.4086\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1157 - val_loss: 0.3817\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1239 - val_loss: 0.4234\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 1.2115 - val_loss: 0.3434\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1029 - val_loss: 0.3307\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0509 - val_loss: 0.3048\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1045 - val_loss: 0.2939\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.9748 - val_loss: 0.3328\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0404 - val_loss: 0.2944\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9837 - val_loss: 0.2536\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9931 - val_loss: 0.2493\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9893 - val_loss: 0.2326\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9077 - val_loss: 0.2262\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9595 - val_loss: 0.2259\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0661 - val_loss: 0.2154\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9394 - val_loss: 0.2188\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8739 - val_loss: 0.1924\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8249 - val_loss: 0.1909\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8520 - val_loss: 0.1834\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7674 - val_loss: 0.1820\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8743 - val_loss: 0.1758\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8717 - val_loss: 0.1722\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8513 - val_loss: 0.1661\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7537 - val_loss: 0.1880\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8473 - val_loss: 0.1653\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7847 - val_loss: 0.1573\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8461 - val_loss: 0.1600\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8199 - val_loss: 0.1573\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8181 - val_loss: 0.1678\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7638 - val_loss: 0.1859\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7827 - val_loss: 0.1568\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7684 - val_loss: 0.1496\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8528 - val_loss: 0.1418\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6959 - val_loss: 0.1710\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7019 - val_loss: 0.1397\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7612 - val_loss: 0.1411\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7669 - val_loss: 0.1371\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7330 - val_loss: 0.1688\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7593 - val_loss: 0.1425\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7167 - val_loss: 0.1356\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7109 - val_loss: 0.1435\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7145 - val_loss: 0.1520\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8007 - val_loss: 0.1592\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7484 - val_loss: 0.1440\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6728 - val_loss: 0.1550\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6930 - val_loss: 0.1423\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6772 - val_loss: 0.1382\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7326 - val_loss: 0.1366\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6865 - val_loss: 0.1331\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6680 - val_loss: 0.1340\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7012 - val_loss: 0.1625\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6803 - val_loss: 0.1337\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6680 - val_loss: 0.1273\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7439 - val_loss: 0.1570\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5979 - val_loss: 0.1309\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6676 - val_loss: 0.1403\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6567 - val_loss: 0.1328\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6973 - val_loss: 0.1466\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7425 - val_loss: 0.1269\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7677 - val_loss: 0.1341\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7203 - val_loss: 0.1273\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6507 - val_loss: 0.1550\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6617 - val_loss: 0.1290\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6646 - val_loss: 0.1298\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6333 - val_loss: 0.1257\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6572 - val_loss: 0.1231\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6168 - val_loss: 0.1220\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6180 - val_loss: 0.1498\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6082 - val_loss: 0.1219\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6331 - val_loss: 0.1314\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6097 - val_loss: 0.1301\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6384 - val_loss: 0.1475\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6399 - val_loss: 0.1459\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5833 - val_loss: 0.1395\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5705 - val_loss: 0.1813\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6270 - val_loss: 0.1458\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6652 - val_loss: 0.1240\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6592 - val_loss: 0.1248\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6298 - val_loss: 0.1551\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 0.5926 - val_loss: 0.1245\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.5382 - val_loss: 0.1210\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.6229 - val_loss: 0.1241\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6081 - val_loss: 0.1407\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6488 - val_loss: 0.1250\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.5693 - val_loss: 0.1269\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.5952 - val_loss: 0.1189\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6079 - val_loss: 0.1230\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6369 - val_loss: 0.1210\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7155 - val_loss: 0.1223\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5595 - val_loss: 0.1489\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6313 - val_loss: 0.1244\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6275 - val_loss: 0.1203\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5497 - val_loss: 0.1253\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6295 - val_loss: 0.1250\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6150 - val_loss: 0.1288\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6530 - val_loss: 0.1306\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5808 - val_loss: 0.1287\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6133 - val_loss: 0.1216\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5524 - val_loss: 0.1296\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5749 - val_loss: 0.1365\n",
      "Epoch 124/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5637 - val_loss: 0.2023\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6014 - val_loss: 0.1444\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5288 - val_loss: 0.1268\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6067 - val_loss: 0.1269\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5528 - val_loss: 0.1175\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5384 - val_loss: 0.1285\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5699 - val_loss: 0.1173\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5502 - val_loss: 0.1170\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6674 - val_loss: 0.1235\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5873 - val_loss: 0.1237\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5027 - val_loss: 0.1305\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5717 - val_loss: 0.1262\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6012 - val_loss: 0.1374\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5488 - val_loss: 0.1283\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5501 - val_loss: 0.1193\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5825 - val_loss: 0.1422\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6161 - val_loss: 0.1198\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5662 - val_loss: 0.1228\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5601 - val_loss: 0.1510\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5640 - val_loss: 0.1304\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5491 - val_loss: 0.1294\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5448 - val_loss: 0.1330\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6258 - val_loss: 0.1740\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5710 - val_loss: 0.1430\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5948 - val_loss: 0.1222\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5594 - val_loss: 0.1322\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5780 - val_loss: 0.1192\n",
      "7/7 [==============================] - 2s 6ms/step\n",
      "Mean Squared Error: 0.11923380448390948\n",
      "Mean Absolute Error: 0.21028454861237636\n",
      "R-squared: 0.9821708080900716\n",
      "\n",
      "Fold 4:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 14s 102ms/step - loss: 78.7604 - val_loss: 58.8848\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 32.8418 - val_loss: 4.8766\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.0701 - val_loss: 4.0876\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.8506 - val_loss: 3.5176\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.5352 - val_loss: 3.3300\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.3554 - val_loss: 3.0528\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.8910 - val_loss: 2.6756\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.2690 - val_loss: 2.1827\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5724 - val_loss: 1.5090\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 2.5452 - val_loss: 0.9282\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 2.0897 - val_loss: 0.6585\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.7501 - val_loss: 0.5884\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.8186 - val_loss: 0.5553\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.4771 - val_loss: 0.5392\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.5024 - val_loss: 0.4988\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.4977 - val_loss: 0.4398\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.5023 - val_loss: 0.4061\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.4396 - val_loss: 0.4185\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.4856 - val_loss: 0.3942\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.3702 - val_loss: 0.3453\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.2460 - val_loss: 0.3194\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.2783 - val_loss: 0.3439\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1638 - val_loss: 0.3316\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1635 - val_loss: 0.3393\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1837 - val_loss: 0.2630\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1864 - val_loss: 0.2792\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0260 - val_loss: 0.2293\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0163 - val_loss: 0.2753\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.1727 - val_loss: 0.2301\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1914 - val_loss: 0.2052\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0428 - val_loss: 0.2324\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.0192 - val_loss: 0.2113\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9764 - val_loss: 0.2014\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9527 - val_loss: 0.2120\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0804 - val_loss: 0.1649\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8950 - val_loss: 0.2005\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9473 - val_loss: 0.1837\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.9540 - val_loss: 0.1492\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9839 - val_loss: 0.1589\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0340 - val_loss: 0.1328\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9211 - val_loss: 0.1221\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8670 - val_loss: 0.1235\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8728 - val_loss: 0.1220\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.9227 - val_loss: 0.1235\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9455 - val_loss: 0.1321\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9332 - val_loss: 0.1187\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8879 - val_loss: 0.1351\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8838 - val_loss: 0.1224\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.9099 - val_loss: 0.1039\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8342 - val_loss: 0.0954\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7587 - val_loss: 0.1402\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8566 - val_loss: 0.1287\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6763 - val_loss: 0.0949\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7545 - val_loss: 0.1010\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8157 - val_loss: 0.0866\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.8376 - val_loss: 0.1118\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.8222 - val_loss: 0.1416\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7648 - val_loss: 0.0935\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8237 - val_loss: 0.1201\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8100 - val_loss: 0.0807\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7581 - val_loss: 0.1156\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.6653 - val_loss: 0.0892\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7380 - val_loss: 0.1131\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.7430 - val_loss: 0.0839\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7447 - val_loss: 0.0741\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.7653 - val_loss: 0.0756\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8599 - val_loss: 0.0979\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7008 - val_loss: 0.0693\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7570 - val_loss: 0.0749\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6419 - val_loss: 0.0785\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6873 - val_loss: 0.0719\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7526 - val_loss: 0.0715\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7487 - val_loss: 0.0932\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7326 - val_loss: 0.0749\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7842 - val_loss: 0.0757\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7020 - val_loss: 0.0735\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7370 - val_loss: 0.0716\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6785 - val_loss: 0.0999\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6639 - val_loss: 0.1149\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6861 - val_loss: 0.0734\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6646 - val_loss: 0.0756\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7205 - val_loss: 0.0734\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6966 - val_loss: 0.0653\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6075 - val_loss: 0.0681\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6258 - val_loss: 0.0909\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6158 - val_loss: 0.1014\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7515 - val_loss: 0.0964\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6749 - val_loss: 0.0762\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6366 - val_loss: 0.1255\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6767 - val_loss: 0.0920\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7168 - val_loss: 0.0935\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6225 - val_loss: 0.0812\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6485 - val_loss: 0.0627\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6704 - val_loss: 0.0679\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5963 - val_loss: 0.0637\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6924 - val_loss: 0.1053\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6279 - val_loss: 0.0652\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7355 - val_loss: 0.0935\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6181 - val_loss: 0.0735\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6460 - val_loss: 0.0770\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7170 - val_loss: 0.0688\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6500 - val_loss: 0.0652\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6020 - val_loss: 0.0625\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5923 - val_loss: 0.0628\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6093 - val_loss: 0.0669\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6252 - val_loss: 0.0700\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5884 - val_loss: 0.1444\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6397 - val_loss: 0.1081\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6169 - val_loss: 0.0705\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6353 - val_loss: 0.0613\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5979 - val_loss: 0.0634\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5749 - val_loss: 0.0818\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5346 - val_loss: 0.0637\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5745 - val_loss: 0.0641\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6535 - val_loss: 0.0664\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5789 - val_loss: 0.0650\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6178 - val_loss: 0.0652\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6045 - val_loss: 0.0858\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6350 - val_loss: 0.0744\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5716 - val_loss: 0.0620\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5404 - val_loss: 0.0798\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5353 - val_loss: 0.0655\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5818 - val_loss: 0.0677\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6220 - val_loss: 0.0685\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5582 - val_loss: 0.0607\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6528 - val_loss: 0.0765\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6006 - val_loss: 0.0989\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5860 - val_loss: 0.0852\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6180 - val_loss: 0.0614\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5735 - val_loss: 0.0764\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6339 - val_loss: 0.0758\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6344 - val_loss: 0.1058\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5927 - val_loss: 0.0775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5676 - val_loss: 0.0654\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6399 - val_loss: 0.0627\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5823 - val_loss: 0.0773\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6686 - val_loss: 0.0683\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.6097 - val_loss: 0.0785\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5722 - val_loss: 0.0647\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.6120 - val_loss: 0.0596\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5858 - val_loss: 0.0888\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5933 - val_loss: 0.0684\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6437 - val_loss: 0.0649\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5589 - val_loss: 0.0804\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6122 - val_loss: 0.0634\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6051 - val_loss: 0.0747\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5699 - val_loss: 0.0774\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5603 - val_loss: 0.0940\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6098 - val_loss: 0.0664\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5956 - val_loss: 0.0742\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.07423286910480487\n",
      "Mean Absolute Error: 0.19103347484152117\n",
      "R-squared: 0.9840030024892056\n",
      "\n",
      "Fold 5:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 102ms/step - loss: 76.9306 - val_loss: 63.7358\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 29.9734 - val_loss: 6.1593\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 5.3402 - val_loss: 5.1461\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.8017 - val_loss: 4.8179\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5565 - val_loss: 4.4245\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2060 - val_loss: 3.9594\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7194 - val_loss: 3.4086\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3261 - val_loss: 2.7357\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 2.9271 - val_loss: 1.9999\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 2.2132 - val_loss: 1.3286\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.8525 - val_loss: 1.0331\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.5432 - val_loss: 0.8245\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.5187 - val_loss: 0.7245\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.4102 - val_loss: 0.6997\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.4182 - val_loss: 0.6423\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.4007 - val_loss: 0.5951\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 1.2726 - val_loss: 0.5544\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.4105 - val_loss: 0.5264\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.2779 - val_loss: 0.4932\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.2629 - val_loss: 0.4986\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.1392 - val_loss: 0.4844\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.2133 - val_loss: 0.4612\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.2009 - val_loss: 0.4155\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1021 - val_loss: 0.3783\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1525 - val_loss: 0.4120\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1846 - val_loss: 0.3313\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1910 - val_loss: 0.3297\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0691 - val_loss: 0.3816\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0232 - val_loss: 0.2910\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0923 - val_loss: 0.2804\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0313 - val_loss: 0.2701\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0488 - val_loss: 0.2541\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.9903 - val_loss: 0.2487\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.9067 - val_loss: 0.2423\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7901 - val_loss: 0.2263\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 1.0099 - val_loss: 0.2136\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.9497 - val_loss: 0.2072\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.9289 - val_loss: 0.1968\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.9062 - val_loss: 0.2166\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.8424 - val_loss: 0.1866\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8783 - val_loss: 0.1762\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0448 - val_loss: 0.1720\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8469 - val_loss: 0.1689\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8532 - val_loss: 0.1918\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8684 - val_loss: 0.1575\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9081 - val_loss: 0.1555\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8694 - val_loss: 0.2228\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8595 - val_loss: 0.1606\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8030 - val_loss: 0.1572\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7891 - val_loss: 0.1442\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7025 - val_loss: 0.1544\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8652 - val_loss: 0.1381\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8372 - val_loss: 0.1422\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8176 - val_loss: 0.1785\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8299 - val_loss: 0.1956\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7857 - val_loss: 0.1352\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7491 - val_loss: 0.1301\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7000 - val_loss: 0.1367\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7081 - val_loss: 0.1273\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7612 - val_loss: 0.1323\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7526 - val_loss: 0.1919\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7305 - val_loss: 0.1326\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7045 - val_loss: 0.1233\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7629 - val_loss: 0.1249\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7054 - val_loss: 0.1199\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7300 - val_loss: 0.1333\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6297 - val_loss: 0.1207\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6662 - val_loss: 0.1194\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6964 - val_loss: 0.1200\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7330 - val_loss: 0.1174\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6333 - val_loss: 0.1605\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7423 - val_loss: 0.1419\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6517 - val_loss: 0.1423\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6568 - val_loss: 0.1173\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6019 - val_loss: 0.1178\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6359 - val_loss: 0.1357\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5950 - val_loss: 0.1137\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6122 - val_loss: 0.1607\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6935 - val_loss: 0.1127\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6158 - val_loss: 0.1167\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6712 - val_loss: 0.1175\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6784 - val_loss: 0.1624\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7112 - val_loss: 0.1218\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6930 - val_loss: 0.1222\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6272 - val_loss: 0.1200\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6262 - val_loss: 0.1106\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7234 - val_loss: 0.1459\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7039 - val_loss: 0.1092\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6695 - val_loss: 0.1563\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6224 - val_loss: 0.1491\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6387 - val_loss: 0.1120\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5967 - val_loss: 0.1081\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6234 - val_loss: 0.1090\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6020 - val_loss: 0.1533\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6586 - val_loss: 0.1074\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6594 - val_loss: 0.1258\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5555 - val_loss: 0.1097\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6454 - val_loss: 0.1135\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7210 - val_loss: 0.1109\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6065 - val_loss: 0.1409\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6069 - val_loss: 0.1095\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6419 - val_loss: 0.1141\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5599 - val_loss: 0.1067\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5775 - val_loss: 0.1358\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5412 - val_loss: 0.1060\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5832 - val_loss: 0.1050\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6006 - val_loss: 0.1036\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6711 - val_loss: 0.1049\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6186 - val_loss: 0.1066\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5582 - val_loss: 0.1632\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5893 - val_loss: 0.1108\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6396 - val_loss: 0.1142\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5694 - val_loss: 0.1560\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6954 - val_loss: 0.1236\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5858 - val_loss: 0.1051\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5895 - val_loss: 0.1113\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6218 - val_loss: 0.1035\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5858 - val_loss: 0.1176\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5947 - val_loss: 0.1331\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6056 - val_loss: 0.1210\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6013 - val_loss: 0.1475\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6234 - val_loss: 0.1113\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5563 - val_loss: 0.1192\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6108 - val_loss: 0.1050\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5901 - val_loss: 0.1077\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5562 - val_loss: 0.1053\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6387 - val_loss: 0.1554\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6281 - val_loss: 0.1170\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5459 - val_loss: 0.1024\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6125 - val_loss: 0.1190\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5874 - val_loss: 0.1166\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5963 - val_loss: 0.1305\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5262 - val_loss: 0.1007\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5843 - val_loss: 0.1543\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5813 - val_loss: 0.1063\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5441 - val_loss: 0.1081\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6107 - val_loss: 0.1847\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5447 - val_loss: 0.1341\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5643 - val_loss: 0.1026\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6188 - val_loss: 0.1006\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5619 - val_loss: 0.1104\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5402 - val_loss: 0.1214\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5956 - val_loss: 0.1086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5129 - val_loss: 0.0988\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5968 - val_loss: 0.1454\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5597 - val_loss: 0.1041\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5602 - val_loss: 0.0996\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5755 - val_loss: 0.1170\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5283 - val_loss: 0.1094\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5248 - val_loss: 0.1158\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.11575198812421485\n",
      "Mean Absolute Error: 0.23512144705549398\n",
      "R-squared: 0.9824186540576422\n",
      "\n",
      "Average scores for ticker GEO:\n",
      "Mean Squared Error: 0.10621965645203373\n",
      "Mean Absolute Error: 0.2093359705227525\n",
      "R-squared: 0.9828261292276949\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('dataset.csv').dropna()\n",
    "\n",
    "# Define K-fold cross-validation function for each ticker\n",
    "def kfold_cross_validation_per_ticker(df, n_splits=5):\n",
    "    tickers = df['level_0'].unique()\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        print(f\"Cross-validation for ticker: {ticker}\")\n",
    "        ticker_df = df[df['level_0'] == ticker]\n",
    "        \n",
    "        # Define features and target variable for this ticker\n",
    "        X = ticker_df[['Open', 'High', 'Low', 'Close', 'Volume', 'Daily Returns', 'Volatility', 'RSI', '%K', '%D', 'Sentiment Score', 'Movement']].values\n",
    "        y = ticker_df['NextDayClose'].values\n",
    "\n",
    "        # Perform K-Fold cross-validation\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        fold = 1\n",
    "        mse_scores, mae_scores, r2_scores = [], [], []\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            print(f'Fold {fold}:')\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # Normalize features\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "            # Reshape input data for GRU (samples, time steps, features)\n",
    "            X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "            X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "            # Create and train GRU model\n",
    "            model = Sequential()\n",
    "            model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(GRU(units=50, return_sequences=True))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(GRU(units=50))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(units=1))\n",
    "            model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "            history = model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "            # Evaluate model\n",
    "            predictions = model.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, predictions)\n",
    "            mae = mean_absolute_error(y_test, predictions)\n",
    "            r2 = r2_score(y_test, predictions)\n",
    "\n",
    "            print(f'Mean Squared Error: {mse}')\n",
    "            print(f'Mean Absolute Error: {mae}')\n",
    "            print(f'R-squared: {r2}\\n')\n",
    "\n",
    "            mse_scores.append(mse)\n",
    "            mae_scores.append(mae)\n",
    "            r2_scores.append(r2)\n",
    "\n",
    "            fold += 1\n",
    "\n",
    "        # Print average scores for the current ticker\n",
    "        print('Average scores for ticker {}:'.format(ticker))\n",
    "        print(f'Mean Squared Error: {np.mean(mse_scores)}')\n",
    "        print(f'Mean Absolute Error: {np.mean(mae_scores)}')\n",
    "        print(f'R-squared: {np.mean(r2_scores)}\\n')\n",
    "\n",
    "# Perform K-fold cross-validation per ticker\n",
    "kfold_cross_validation_per_ticker(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea58fc9",
   "metadata": {},
   "source": [
    "Previous Day close Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbdbad7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation for ticker: SAVE\n",
      "Fold 1:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 8s 68ms/step - loss: 528.2239 - val_loss: 488.6679\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 374.1584 - val_loss: 235.7249\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 177.1173 - val_loss: 140.4400\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 123.4313 - val_loss: 109.8819\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 100.7059 - val_loss: 91.5421\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 85.7559 - val_loss: 79.2060\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 74.5403 - val_loss: 70.7929\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 67.4922 - val_loss: 65.3782\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 63.7672 - val_loss: 61.4053\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 60.8617 - val_loss: 58.6871\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 59.8228 - val_loss: 56.7448\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 55.9381 - val_loss: 55.5465\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 56.3759 - val_loss: 54.7081\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 55.8707 - val_loss: 54.2069\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 56.4798 - val_loss: 53.8874\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 54.5454 - val_loss: 53.5005\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 53.0933 - val_loss: 53.2014\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 55.2123 - val_loss: 52.9387\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 54.6670 - val_loss: 52.4071\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 53.6561 - val_loss: 51.4686\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 52.6472 - val_loss: 49.4257\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 50.6128 - val_loss: 45.0410\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 44.4026 - val_loss: 37.8136\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 36.9556 - val_loss: 31.2214\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 32.1197 - val_loss: 27.0838\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 29.5515 - val_loss: 24.1865\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 25.9756 - val_loss: 21.7747\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 25.2206 - val_loss: 19.5875\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 23.7719 - val_loss: 17.7918\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 20.4008 - val_loss: 16.3194\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 19.1241 - val_loss: 14.9598\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 19.2672 - val_loss: 13.6875\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 17.0952 - val_loss: 12.6029\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 17.1802 - val_loss: 11.9709\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 15.8740 - val_loss: 10.8786\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 15.8396 - val_loss: 10.0676\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 15.4075 - val_loss: 9.3803\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 13.9388 - val_loss: 8.6472\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 12.5060 - val_loss: 8.0584\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 12.5567 - val_loss: 7.4608\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 12.3780 - val_loss: 6.9674\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 11.8197 - val_loss: 6.3669\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 10.6679 - val_loss: 6.0255\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 9.7727 - val_loss: 5.5016\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 9.5097 - val_loss: 5.5575\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 9.9936 - val_loss: 4.7942\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 9.5284 - val_loss: 4.6718\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 8.8145 - val_loss: 4.0103\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 8.5890 - val_loss: 3.7660\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 7.9075 - val_loss: 3.4709\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 7.7867 - val_loss: 3.2502\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 7.5840 - val_loss: 3.1294\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.3844 - val_loss: 2.7913\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.5446 - val_loss: 2.7987\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.8886 - val_loss: 2.6210\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.9820 - val_loss: 3.0385\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.5299 - val_loss: 2.5200\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 7.6321 - val_loss: 2.0608\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.9072 - val_loss: 2.0177\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.8768 - val_loss: 1.7645\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.4099 - val_loss: 2.1939\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.0604 - val_loss: 1.6129\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.4035 - val_loss: 1.8085\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.6686 - val_loss: 1.5221\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.3528 - val_loss: 1.3299\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 5.5167 - val_loss: 1.5822\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.3094 - val_loss: 1.3237\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.6442 - val_loss: 1.2013\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.8655 - val_loss: 1.0969\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.6706 - val_loss: 1.0746\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.8418 - val_loss: 1.0119\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.6857 - val_loss: 1.0151\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.5783 - val_loss: 0.9481\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.7993 - val_loss: 1.0175\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.7141 - val_loss: 0.9472\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.5001 - val_loss: 0.9113\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.4448 - val_loss: 0.8589\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.7573 - val_loss: 0.8682\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.4144 - val_loss: 0.8395\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.7671 - val_loss: 1.3806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.7325 - val_loss: 0.7765\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.5915 - val_loss: 0.7215\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.0844 - val_loss: 0.7153\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.1417 - val_loss: 0.7145\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.5466 - val_loss: 0.7119\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.6468 - val_loss: 0.7980\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.3120 - val_loss: 0.8254\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.5486 - val_loss: 0.6336\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9586 - val_loss: 0.7683\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.3164 - val_loss: 0.6105\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0147 - val_loss: 0.8521\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.8858 - val_loss: 0.7670\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.1284 - val_loss: 0.9016\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.2480 - val_loss: 0.6248\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.8894 - val_loss: 0.5643\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9681 - val_loss: 0.5702\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.2530 - val_loss: 0.6038\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.0084 - val_loss: 0.6743\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.9340 - val_loss: 0.5274\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0572 - val_loss: 0.5257\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.3167 - val_loss: 0.6364\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.1483 - val_loss: 0.5376\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6094 - val_loss: 0.5094\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0234 - val_loss: 0.5233\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.7554 - val_loss: 0.5308\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6092 - val_loss: 0.4338\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.0004 - val_loss: 0.5238\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.8303 - val_loss: 0.4404\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0044 - val_loss: 0.4832\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0949 - val_loss: 0.4139\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8787 - val_loss: 0.7092\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.8025 - val_loss: 0.5390\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.7669 - val_loss: 0.7096\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.1290 - val_loss: 0.4008\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6322 - val_loss: 0.4745\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9505 - val_loss: 0.4203\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5244 - val_loss: 0.3773\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9126 - val_loss: 0.3777\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6237 - val_loss: 0.3275\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6477 - val_loss: 0.3857\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8709 - val_loss: 0.7155\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.0723 - val_loss: 0.3476\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3590 - val_loss: 0.4214\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.3666 - val_loss: 0.3612\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5738 - val_loss: 0.3344\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6962 - val_loss: 0.3179\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5647 - val_loss: 0.4482\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.0270 - val_loss: 0.3095\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.7725 - val_loss: 0.4660\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8902 - val_loss: 0.3036\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7749 - val_loss: 0.3393\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.5187 - val_loss: 0.2674\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6396 - val_loss: 0.4405\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5427 - val_loss: 0.2454\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.1540 - val_loss: 0.2597\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4131 - val_loss: 0.4470\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.6794 - val_loss: 0.2962\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3302 - val_loss: 0.2640\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5077 - val_loss: 0.3275\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.1636 - val_loss: 0.3196\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8787 - val_loss: 0.2983\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.3224 - val_loss: 0.5709\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.2309 - val_loss: 0.3967\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.8314 - val_loss: 0.3016\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2970 - val_loss: 0.3412\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.2557 - val_loss: 0.3407\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4107 - val_loss: 0.3386\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4569 - val_loss: 0.3654\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.1343 - val_loss: 0.3851\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.3638 - val_loss: 0.3035\n",
      "7/7 [==============================] - 1s 3ms/step\n",
      "Mean Squared Error: 0.3035011278511436\n",
      "Mean Absolute Error: 0.42085796564965705\n",
      "R-squared: 0.9943575020961285\n",
      "\n",
      "Fold 2:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 9s 53ms/step - loss: 524.6176 - val_loss: 519.5626\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 385.5456 - val_loss: 269.5145\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 177.0083 - val_loss: 150.7088\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 114.9073 - val_loss: 117.1799\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 91.5381 - val_loss: 98.9426\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 77.9482 - val_loss: 86.9683\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 69.6434 - val_loss: 78.3982\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 62.9667 - val_loss: 72.6588\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 59.7283 - val_loss: 68.8371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 59.1797 - val_loss: 66.2820\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 56.0558 - val_loss: 64.3434\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 53.5265 - val_loss: 63.1869\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 55.4723 - val_loss: 62.5120\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 53.6704 - val_loss: 62.0534\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 52.4517 - val_loss: 61.5552\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 52.5016 - val_loss: 61.2100\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 52.9586 - val_loss: 60.7146\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 51.8378 - val_loss: 59.9245\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 51.0951 - val_loss: 58.5397\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 47.5226 - val_loss: 55.4654\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 43.6829 - val_loss: 49.2922\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 38.8443 - val_loss: 41.2907\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 30.9104 - val_loss: 34.6772\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 29.1677 - val_loss: 31.1188\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 25.2645 - val_loss: 28.1742\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 23.0543 - val_loss: 25.5556\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 22.0331 - val_loss: 23.3276\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 21.0347 - val_loss: 21.7270\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 19.4726 - val_loss: 20.1170\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 18.4710 - val_loss: 18.4332\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 16.9634 - val_loss: 17.2778\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 15.4700 - val_loss: 16.1370\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 16.4262 - val_loss: 15.0249\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 14.7927 - val_loss: 14.3168\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 13.4465 - val_loss: 13.0298\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 12.4709 - val_loss: 12.0730\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 12.2186 - val_loss: 11.3107\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 12.0690 - val_loss: 10.6002\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 11.0150 - val_loss: 10.0302\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 11.2234 - val_loss: 9.4012\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 10.6628 - val_loss: 8.7257\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 10.6503 - val_loss: 8.0947\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 10.5735 - val_loss: 7.5419\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 8.7105 - val_loss: 7.1242\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 8.9000 - val_loss: 6.5792\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 8.5219 - val_loss: 6.1688\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 8.5855 - val_loss: 5.8425\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 7.9491 - val_loss: 5.5285\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 7.8273 - val_loss: 4.9994\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 7.0214 - val_loss: 4.7127\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 7.0695 - val_loss: 4.5054\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.6267 - val_loss: 4.2106\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 6.5682 - val_loss: 3.9752\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.1506 - val_loss: 3.7090\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 6.8910 - val_loss: 3.4791\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.3977 - val_loss: 3.3940\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.3784 - val_loss: 3.1052\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.3295 - val_loss: 2.8342\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.3091 - val_loss: 3.1768\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.7891 - val_loss: 2.5807\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.4002 - val_loss: 2.3851\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.9107 - val_loss: 2.2483\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.8186 - val_loss: 2.1510\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.0832 - val_loss: 2.0219\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.9877 - val_loss: 1.9112\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.2279 - val_loss: 1.8256\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.3457 - val_loss: 1.7018\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.1801 - val_loss: 1.7047\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.6227 - val_loss: 1.6084\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.5339 - val_loss: 1.5899\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.1323 - val_loss: 1.5004\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.2955 - val_loss: 1.4332\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.1729 - val_loss: 1.3433\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.0415 - val_loss: 1.2617\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.9296 - val_loss: 1.2686\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.6053 - val_loss: 1.1816\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.1929 - val_loss: 1.1122\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.0390 - val_loss: 1.1283\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.6532 - val_loss: 1.1778\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.6195 - val_loss: 1.0666\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.4724 - val_loss: 1.0444\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2020 - val_loss: 1.0172\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.6021 - val_loss: 0.9746\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8203 - val_loss: 0.9493\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5380 - val_loss: 0.8956\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9074 - val_loss: 0.8442\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.1625 - val_loss: 1.0119\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.3488 - val_loss: 0.7991\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0297 - val_loss: 0.7600\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7507 - val_loss: 0.7799\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.1080 - val_loss: 0.7283\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5056 - val_loss: 0.7421\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.9086 - val_loss: 0.7940\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.4893 - val_loss: 0.7670\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.0838 - val_loss: 0.6989\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8169 - val_loss: 0.6503\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 4.2187 - val_loss: 0.7173\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5748 - val_loss: 0.5951\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7184 - val_loss: 0.6015\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.1735 - val_loss: 0.5974\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4796 - val_loss: 0.8543\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6752 - val_loss: 0.5399\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.0345 - val_loss: 0.5449\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.9052 - val_loss: 0.6036\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7122 - val_loss: 0.5172\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7370 - val_loss: 0.4693\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5735 - val_loss: 0.6985\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6115 - val_loss: 0.5862\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.8740 - val_loss: 0.4870\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5308 - val_loss: 0.5098\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9707 - val_loss: 0.5693\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5718 - val_loss: 0.4694\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8251 - val_loss: 0.4364\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5442 - val_loss: 0.4264\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6107 - val_loss: 0.5508\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6510 - val_loss: 0.4617\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.8764 - val_loss: 0.3642\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.2839 - val_loss: 0.4001\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6172 - val_loss: 0.4135\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7917 - val_loss: 0.4465\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6639 - val_loss: 0.6461\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7196 - val_loss: 0.4979\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.0361 - val_loss: 0.6213\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.3864 - val_loss: 0.4586\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.4025 - val_loss: 0.3543\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5603 - val_loss: 0.3425\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2089 - val_loss: 0.4227\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4148 - val_loss: 0.4482\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7579 - val_loss: 0.3165\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.8651 - val_loss: 0.3278\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 2.9838 - val_loss: 0.3665\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3643 - val_loss: 0.6026\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5069 - val_loss: 0.4399\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3254 - val_loss: 0.2628\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.3882 - val_loss: 0.2764\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.0909 - val_loss: 0.2829\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3696 - val_loss: 0.2784\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3477 - val_loss: 0.3027\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5416 - val_loss: 0.3836\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.8113 - val_loss: 0.3801\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6688 - val_loss: 0.3348\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.3800 - val_loss: 0.2327\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.3880 - val_loss: 0.3763\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5120 - val_loss: 0.3533\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3079 - val_loss: 0.3118\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.1301 - val_loss: 0.3622\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.3821 - val_loss: 0.3768\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.7368 - val_loss: 0.2785\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3813 - val_loss: 0.2326\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3485 - val_loss: 0.2348\n",
      "7/7 [==============================] - 1s 4ms/step\n",
      "Mean Squared Error: 0.23480061337751293\n",
      "Mean Absolute Error: 0.27278587948623595\n",
      "R-squared: 0.9961546277194022\n",
      "\n",
      "Fold 3:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 7s 55ms/step - loss: 526.2096 - val_loss: 511.0108\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 385.1907 - val_loss: 267.6391\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 188.3826 - val_loss: 155.5180\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 127.1487 - val_loss: 119.9481\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 101.2497 - val_loss: 99.1787\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 84.9758 - val_loss: 85.0661\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 75.1071 - val_loss: 75.7601\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 69.1084 - val_loss: 68.6039\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 62.7947 - val_loss: 64.0182\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 60.6019 - val_loss: 61.0452\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 56.9170 - val_loss: 59.0280\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 56.0064 - val_loss: 57.5336\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 56.5652 - val_loss: 56.5223\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 55.2770 - val_loss: 55.7875\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 54.2058 - val_loss: 55.3509\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 54.8235 - val_loss: 54.8805\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 54.7545 - val_loss: 54.5542\n",
      "Epoch 18/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 13ms/step - loss: 55.8726 - val_loss: 54.0904\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 53.5843 - val_loss: 53.5284\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 54.6648 - val_loss: 52.1958\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 50.4426 - val_loss: 49.4761\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 48.9041 - val_loss: 43.5800\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 41.4826 - val_loss: 35.8166\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 35.2761 - val_loss: 30.8466\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 30.0602 - val_loss: 27.4570\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 28.9532 - val_loss: 24.6762\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 26.3613 - val_loss: 22.5793\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 23.4428 - val_loss: 20.5506\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 22.4408 - val_loss: 18.8276\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 20.9706 - val_loss: 17.3738\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 19.7503 - val_loss: 15.9904\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 18.0576 - val_loss: 14.8435\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 17.6609 - val_loss: 13.8869\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 16.3151 - val_loss: 12.8790\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 16.0549 - val_loss: 12.0766\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 14.5739 - val_loss: 11.3104\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 14.3633 - val_loss: 10.5833\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 13.6205 - val_loss: 9.7415\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 12.3462 - val_loss: 9.5618\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 11.4020 - val_loss: 8.5313\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 12.5492 - val_loss: 7.9231\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 11.1954 - val_loss: 7.2826\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 10.5021 - val_loss: 6.8820\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 10.1824 - val_loss: 6.3456\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 8.9046 - val_loss: 5.9804\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.1390 - val_loss: 5.6470\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 9.0986 - val_loss: 5.2917\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 8.1509 - val_loss: 4.9922\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.9515 - val_loss: 4.8152\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.6210 - val_loss: 4.4496\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 8.2123 - val_loss: 4.2951\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 7.5895 - val_loss: 4.0810\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.2309 - val_loss: 3.7436\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.0868 - val_loss: 3.5074\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.1405 - val_loss: 3.5590\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.7135 - val_loss: 3.4868\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.1100 - val_loss: 2.9508\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.9641 - val_loss: 2.7699\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.5540 - val_loss: 3.1137\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.1502 - val_loss: 2.5636\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.7892 - val_loss: 2.4358\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.7196 - val_loss: 2.2254\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.9394 - val_loss: 2.2282\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.9435 - val_loss: 2.0121\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.0703 - val_loss: 2.1093\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.2644 - val_loss: 1.8406\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.1406 - val_loss: 1.8908\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.1175 - val_loss: 1.6749\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.4663 - val_loss: 1.7183\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.8259 - val_loss: 1.6129\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.4756 - val_loss: 1.4643\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.5090 - val_loss: 1.6379\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.9032 - val_loss: 1.4353\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.5861 - val_loss: 1.3246\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.5262 - val_loss: 1.3902\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.2015 - val_loss: 1.2696\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.2931 - val_loss: 1.2877\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.9495 - val_loss: 1.1866\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.2139 - val_loss: 1.2264\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.1962 - val_loss: 1.1376\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.3855 - val_loss: 1.1039\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8930 - val_loss: 1.5355\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.1772 - val_loss: 1.1054\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0171 - val_loss: 1.0429\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.3736 - val_loss: 1.0239\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.4492 - val_loss: 0.9671\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.4386 - val_loss: 1.0215\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.4408 - val_loss: 0.8500\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.5076 - val_loss: 0.9062\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.8837 - val_loss: 0.8812\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8533 - val_loss: 0.8384\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0012 - val_loss: 0.8399\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.1038 - val_loss: 0.8230\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.3287 - val_loss: 0.8445\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.2787 - val_loss: 0.7800\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8414 - val_loss: 0.7328\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.8679 - val_loss: 0.7478\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.2849 - val_loss: 0.6930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5839 - val_loss: 0.6526\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3566 - val_loss: 0.6628\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.0175 - val_loss: 0.6692\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9930 - val_loss: 0.6237\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6499 - val_loss: 0.7517\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9908 - val_loss: 0.6492\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.8061 - val_loss: 0.6336\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3402 - val_loss: 0.9125\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.2789 - val_loss: 0.5964\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7807 - val_loss: 0.7580\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6835 - val_loss: 0.6161\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6489 - val_loss: 0.8943\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7454 - val_loss: 0.5637\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8971 - val_loss: 0.5566\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5377 - val_loss: 0.5741\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5934 - val_loss: 0.6892\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.3197 - val_loss: 0.6588\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5219 - val_loss: 0.4890\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6377 - val_loss: 0.5426\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6468 - val_loss: 0.4727\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.4037 - val_loss: 0.7167\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6853 - val_loss: 0.4311\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.0466 - val_loss: 0.4471\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.7016 - val_loss: 0.5518\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4430 - val_loss: 0.4337\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5224 - val_loss: 0.5396\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7143 - val_loss: 0.4437\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8219 - val_loss: 0.4433\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.0763 - val_loss: 0.3989\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7782 - val_loss: 0.4160\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3621 - val_loss: 0.3611\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5262 - val_loss: 0.3741\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6721 - val_loss: 0.3656\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6726 - val_loss: 0.3867\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.1131 - val_loss: 0.6996\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.0412 - val_loss: 0.3203\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 2.9979 - val_loss: 0.3786\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.1336 - val_loss: 0.4316\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2070 - val_loss: 0.3169\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6753 - val_loss: 0.3481\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.4387 - val_loss: 0.6028\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3710 - val_loss: 0.3542\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5223 - val_loss: 0.3373\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.3613 - val_loss: 0.2868\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5384 - val_loss: 0.4324\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3009 - val_loss: 0.3281\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2300 - val_loss: 0.3032\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3804 - val_loss: 0.3432\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.4891 - val_loss: 0.3223\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.0662 - val_loss: 0.2618\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.0964 - val_loss: 0.2776\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.4828 - val_loss: 0.5449\n",
      "7/7 [==============================] - 1s 3ms/step\n",
      "Mean Squared Error: 0.5449306278008123\n",
      "Mean Absolute Error: 0.5707610780326884\n",
      "R-squared: 0.9900397121599139\n",
      "\n",
      "Fold 4:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 8s 52ms/step - loss: 539.3678 - val_loss: 437.2844\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 378.8933 - val_loss: 212.3811\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 196.1119 - val_loss: 124.8808\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 139.5279 - val_loss: 95.1004\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 112.2588 - val_loss: 76.8882\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 95.2323 - val_loss: 65.3572\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 82.5207 - val_loss: 57.6536\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 75.5699 - val_loss: 52.5717\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 68.6849 - val_loss: 49.0996\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 63.9602 - val_loss: 47.0562\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 61.7559 - val_loss: 45.9265\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 60.5504 - val_loss: 45.2347\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 60.0720 - val_loss: 44.9818\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 58.8259 - val_loss: 44.9152\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 57.2451 - val_loss: 44.9208\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 58.9703 - val_loss: 44.8684\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 56.7105 - val_loss: 44.7659\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 57.2051 - val_loss: 44.6125\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 56.4020 - val_loss: 44.0917\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 55.5497 - val_loss: 42.7503\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 53.1067 - val_loss: 39.0129\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 47.4015 - val_loss: 30.6367\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 41.0108 - val_loss: 24.4426\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 35.3778 - val_loss: 21.7887\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 32.1960 - val_loss: 18.7970\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 29.1388 - val_loss: 17.0869\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 27.3261 - val_loss: 15.4762\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 24.2708 - val_loss: 13.8821\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 22.7356 - val_loss: 12.7900\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 21.4421 - val_loss: 11.9155\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 21.3638 - val_loss: 10.7879\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 18.7938 - val_loss: 10.0184\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 18.1461 - val_loss: 9.3439\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 17.4633 - val_loss: 8.6533\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 16.7744 - val_loss: 8.1632\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 15.9174 - val_loss: 7.5394\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 14.1070 - val_loss: 7.0999\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 14.5635 - val_loss: 6.6438\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 14.3663 - val_loss: 6.1337\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 12.6674 - val_loss: 5.6908\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 11.9662 - val_loss: 5.3926\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 12.3950 - val_loss: 5.0416\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 11.5179 - val_loss: 4.6547\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 10.5589 - val_loss: 4.4824\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 10.2346 - val_loss: 4.0820\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 10.2668 - val_loss: 3.8020\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 9.8036 - val_loss: 3.5188\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 9.1199 - val_loss: 3.4681\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 9.4975 - val_loss: 3.4240\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 8.3569 - val_loss: 2.8618\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 8.2471 - val_loss: 2.6675\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 8.2119 - val_loss: 3.0655\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 7.3382 - val_loss: 2.3760\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 7.6551 - val_loss: 2.2057\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.1622 - val_loss: 2.2107\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 7.3271 - val_loss: 1.9237\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.8682 - val_loss: 1.9426\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.6477 - val_loss: 1.6750\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.1583 - val_loss: 2.0274\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.1314 - val_loss: 1.4871\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.2279 - val_loss: 1.6153\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.3812 - val_loss: 1.4430\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 5.5985 - val_loss: 1.6168\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.8771 - val_loss: 1.4186\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.7225 - val_loss: 1.3009\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 5.1863 - val_loss: 1.1663\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.3556 - val_loss: 1.2019\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.6972 - val_loss: 1.0614\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.0334 - val_loss: 0.9912\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.0492 - val_loss: 0.9423\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.5323 - val_loss: 1.0670\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.4838 - val_loss: 1.2706\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.9998 - val_loss: 0.8621\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.4932 - val_loss: 0.9065\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.7398 - val_loss: 1.4264\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.7759 - val_loss: 0.8797\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.6748 - val_loss: 0.8388\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.7428 - val_loss: 0.9211\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.0537 - val_loss: 0.7950\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.7757 - val_loss: 0.8125\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.7828 - val_loss: 0.8718\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.1785 - val_loss: 0.7385\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.2311 - val_loss: 0.7241\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.7519 - val_loss: 0.6518\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.6049 - val_loss: 0.7768\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.4550 - val_loss: 0.6641\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.5314 - val_loss: 0.8798\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.2236 - val_loss: 0.7070\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.7619 - val_loss: 0.5581\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.4791 - val_loss: 0.5725\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.6071 - val_loss: 0.5251\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.5897 - val_loss: 0.5392\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.3320 - val_loss: 0.5030\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.6437 - val_loss: 0.5292\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9168 - val_loss: 0.5369\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.2172 - val_loss: 0.4811\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.9009 - val_loss: 0.5498\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9144 - val_loss: 0.4895\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.1432 - val_loss: 0.5736\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0343 - val_loss: 0.4665\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5797 - val_loss: 0.6012\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0765 - val_loss: 0.4513\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7487 - val_loss: 0.4291\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0925 - val_loss: 0.4371\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.2832 - val_loss: 0.3982\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.0925 - val_loss: 0.4540\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.0358 - val_loss: 0.6162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.7036 - val_loss: 0.5506\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.0002 - val_loss: 0.3994\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8077 - val_loss: 0.3865\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5979 - val_loss: 0.4288\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.9986 - val_loss: 0.3686\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8753 - val_loss: 0.3760\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.1315 - val_loss: 0.4537\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.0329 - val_loss: 0.5702\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9205 - val_loss: 0.3497\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6325 - val_loss: 0.5558\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5260 - val_loss: 0.4211\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.8646 - val_loss: 0.3231\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7697 - val_loss: 0.3167\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0691 - val_loss: 0.3840\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.4836 - val_loss: 0.3855\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8679 - val_loss: 0.5110\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.9032 - val_loss: 0.3031\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.1751 - val_loss: 0.3484\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5380 - val_loss: 0.3687\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6850 - val_loss: 0.3100\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7002 - val_loss: 0.2871\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.0878 - val_loss: 0.2962\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.9070 - val_loss: 0.2498\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.7657 - val_loss: 0.3404\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.8566 - val_loss: 0.2895\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5888 - val_loss: 0.3359\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4119 - val_loss: 0.2359\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5698 - val_loss: 0.2281\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2201 - val_loss: 0.2483\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6138 - val_loss: 0.2569\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.7931 - val_loss: 0.2063\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5803 - val_loss: 0.2526\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7929 - val_loss: 0.2118\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 3.5163 - val_loss: 0.2899\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5528 - val_loss: 0.2585\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3109 - val_loss: 0.4033\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3010 - val_loss: 0.3110\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4246 - val_loss: 0.1951\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.2227 - val_loss: 0.2362\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4949 - val_loss: 0.2647\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7153 - val_loss: 0.2495\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2973 - val_loss: 0.1908\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3363 - val_loss: 0.3516\n",
      "7/7 [==============================] - 1s 3ms/step\n",
      "Mean Squared Error: 0.3516065659382478\n",
      "Mean Absolute Error: 0.473755205448587\n",
      "R-squared: 0.9922701190338346\n",
      "\n",
      "Fold 5:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 7s 52ms/step - loss: 534.2466 - val_loss: 477.4603\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 395.0663 - val_loss: 261.0530\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 216.5274 - val_loss: 161.8329\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 151.9432 - val_loss: 124.8803\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 123.3701 - val_loss: 102.4521\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 103.4128 - val_loss: 86.4500\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 89.0186 - val_loss: 75.1067\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 78.4250 - val_loss: 67.0390\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 71.2598 - val_loss: 61.6671\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 67.3158 - val_loss: 57.8755\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 62.3254 - val_loss: 55.1770\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 60.8192 - val_loss: 53.2882\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 60.3379 - val_loss: 52.0924\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 57.1302 - val_loss: 51.3302\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 58.3041 - val_loss: 50.9092\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 56.5899 - val_loss: 50.6645\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 56.2176 - val_loss: 50.4415\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 56.1554 - val_loss: 50.3105\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 55.2229 - val_loss: 50.2411\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 56.5477 - val_loss: 50.1578\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 1s 34ms/step - loss: 56.5821 - val_loss: 50.0445\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 54.1274 - val_loss: 49.8610\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 54.4705 - val_loss: 49.5050\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 55.0257 - val_loss: 48.7115\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 52.9359 - val_loss: 46.0089\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 48.9514 - val_loss: 38.6598\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 40.1987 - val_loss: 31.2573\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 35.2059 - val_loss: 28.0535\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 31.6841 - val_loss: 25.2306\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 29.0363 - val_loss: 23.2592\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 26.7153 - val_loss: 21.3899\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 25.7455 - val_loss: 19.5476\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 23.5417 - val_loss: 18.0672\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 21.7673 - val_loss: 16.5354\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 19.0145 - val_loss: 15.3066\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 19.2243 - val_loss: 14.3351\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 17.4721 - val_loss: 13.3734\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 16.5748 - val_loss: 12.4161\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 15.8876 - val_loss: 11.5779\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 16.3411 - val_loss: 10.8239\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 14.1608 - val_loss: 10.1534\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 13.3840 - val_loss: 9.9737\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 13.1134 - val_loss: 8.9672\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 12.4030 - val_loss: 8.6610\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 12.4115 - val_loss: 7.8893\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 11.5137 - val_loss: 7.4852\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 10.0660 - val_loss: 7.0157\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 10.2972 - val_loss: 6.6052\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 9.7176 - val_loss: 6.1788\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 9.6041 - val_loss: 5.8336\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 9.0887 - val_loss: 5.5724\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 8.9363 - val_loss: 5.1791\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 8.8446 - val_loss: 4.8675\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 7.8680 - val_loss: 4.6298\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 7.7112 - val_loss: 4.4957\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.7840 - val_loss: 4.0462\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 8.0357 - val_loss: 3.8182\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 7.6328 - val_loss: 3.8359\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 7.3667 - val_loss: 3.3939\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 6.8025 - val_loss: 3.3702\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.7975 - val_loss: 3.3129\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.9099 - val_loss: 2.9364\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 6.0987 - val_loss: 2.7867\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.7673 - val_loss: 2.7017\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.2598 - val_loss: 2.8051\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.4291 - val_loss: 2.5267\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.0687 - val_loss: 2.3514\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.6797 - val_loss: 2.2691\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.8575 - val_loss: 2.3396\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.0589 - val_loss: 2.0630\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.2561 - val_loss: 2.0142\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.2770 - val_loss: 1.8982\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.3202 - val_loss: 1.8117\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.6874 - val_loss: 1.7840\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.7632 - val_loss: 1.8188\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.8926 - val_loss: 1.6241\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.6025 - val_loss: 1.6292\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.0967 - val_loss: 1.5043\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.7688 - val_loss: 1.4757\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.6942 - val_loss: 1.4328\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.8982 - val_loss: 1.3871\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.5485 - val_loss: 1.3086\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.7791 - val_loss: 1.3391\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.1509 - val_loss: 1.2390\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.9803 - val_loss: 1.5916\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.8897 - val_loss: 1.2198\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.2806 - val_loss: 1.1973\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.2954 - val_loss: 1.1610\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.2990 - val_loss: 1.2538\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.2190 - val_loss: 1.0299\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8271 - val_loss: 1.0315\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.0031 - val_loss: 1.0583\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8271 - val_loss: 1.0285\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.8250 - val_loss: 0.9423\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.1187 - val_loss: 1.1580\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.2308 - val_loss: 1.4310\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.6113 - val_loss: 0.8923\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.1777 - val_loss: 0.9974\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.2333 - val_loss: 0.8473\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.0343 - val_loss: 0.8717\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6793 - val_loss: 0.8367\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.4944 - val_loss: 0.7685\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.6816 - val_loss: 0.7706\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 3.9661 - val_loss: 1.1653\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 4.3310 - val_loss: 0.9419\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.7496 - val_loss: 0.7454\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.1941 - val_loss: 0.7020\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.9488 - val_loss: 0.7078\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.9394 - val_loss: 0.7696\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.4878 - val_loss: 0.6546\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9024 - val_loss: 0.6433\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.0210 - val_loss: 0.7708\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.9147 - val_loss: 0.6329\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6410 - val_loss: 0.6396\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.7578 - val_loss: 0.5968\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.7817 - val_loss: 0.5731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.7851 - val_loss: 0.5713\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.0688 - val_loss: 0.5396\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.9458 - val_loss: 0.6147\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6869 - val_loss: 0.7617\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5746 - val_loss: 0.5568\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4076 - val_loss: 0.9669\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.2709 - val_loss: 0.5721\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6756 - val_loss: 0.5586\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.5794 - val_loss: 0.8475\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0970 - val_loss: 0.5184\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.8913 - val_loss: 0.4986\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.7965 - val_loss: 0.4625\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5907 - val_loss: 0.5215\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.4776 - val_loss: 0.4878\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6554 - val_loss: 0.4973\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8615 - val_loss: 0.4526\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.8113 - val_loss: 0.4194\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5652 - val_loss: 0.6285\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.6165 - val_loss: 0.4061\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6648 - val_loss: 0.9313\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.9236 - val_loss: 0.3973\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.5506 - val_loss: 0.3681\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.2786 - val_loss: 0.4323\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.2659 - val_loss: 0.8328\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6551 - val_loss: 0.4182\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.7191 - val_loss: 0.5280\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.6972 - val_loss: 0.3378\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.7546 - val_loss: 0.4434\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.1217 - val_loss: 0.3685\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.2359 - val_loss: 0.3476\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6073 - val_loss: 0.4413\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.0976 - val_loss: 0.3010\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.4532 - val_loss: 0.3405\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.3952 - val_loss: 0.3385\n",
      "7/7 [==============================] - 1s 4ms/step\n",
      "Mean Squared Error: 0.3385377244197414\n",
      "Mean Absolute Error: 0.3671569397200397\n",
      "R-squared: 0.9933147880557982\n",
      "\n",
      "Average scores for ticker SAVE:\n",
      "Mean Squared Error: 0.3546753318774916\n",
      "Mean Absolute Error: 0.42106341366744165\n",
      "R-squared: 0.9932273498130154\n",
      "\n",
      "Cross-validation for ticker: CLNE\n",
      "Fold 1:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 7s 52ms/step - loss: 37.2373 - val_loss: 32.3905\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 14.8889 - val_loss: 6.9938\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.9305 - val_loss: 5.7368\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.0797 - val_loss: 3.5181\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 2.9167 - val_loss: 1.5650\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.6148 - val_loss: 0.6809\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.1452 - val_loss: 0.4998\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9484 - val_loss: 0.4208\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8831 - val_loss: 0.3853\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.9532 - val_loss: 0.3317\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8803 - val_loss: 0.3087\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8469 - val_loss: 0.2800\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8870 - val_loss: 0.2618\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8820 - val_loss: 0.2395\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8131 - val_loss: 0.2147\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8030 - val_loss: 0.1955\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7861 - val_loss: 0.1885\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.7251 - val_loss: 0.1731\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6945 - val_loss: 0.1652\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7259 - val_loss: 0.1511\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7132 - val_loss: 0.1359\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6653 - val_loss: 0.1279\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6540 - val_loss: 0.1231\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5924 - val_loss: 0.1163\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5522 - val_loss: 0.1081\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6119 - val_loss: 0.1074\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5903 - val_loss: 0.0983\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5302 - val_loss: 0.1076\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5860 - val_loss: 0.0917\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5987 - val_loss: 0.0865\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6164 - val_loss: 0.2151\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5772 - val_loss: 0.1546\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5596 - val_loss: 0.1001\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4966 - val_loss: 0.0846\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5647 - val_loss: 0.1053\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4678 - val_loss: 0.0841\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4914 - val_loss: 0.0913\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5123 - val_loss: 0.0739\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5036 - val_loss: 0.0697\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5393 - val_loss: 0.0861\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4947 - val_loss: 0.0662\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4515 - val_loss: 0.0765\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4879 - val_loss: 0.0787\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4796 - val_loss: 0.0809\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4837 - val_loss: 0.0752\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4437 - val_loss: 0.1193\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5086 - val_loss: 0.0868\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4477 - val_loss: 0.0718\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4015 - val_loss: 0.0734\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4235 - val_loss: 0.0734\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4707 - val_loss: 0.0934\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4748 - val_loss: 0.1127\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5172 - val_loss: 0.0640\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4019 - val_loss: 0.1050\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4091 - val_loss: 0.0674\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4453 - val_loss: 0.0706\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4764 - val_loss: 0.0813\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4134 - val_loss: 0.0623\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4396 - val_loss: 0.0666\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3953 - val_loss: 0.0605\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4230 - val_loss: 0.0683\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4206 - val_loss: 0.0834\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4138 - val_loss: 0.0676\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4045 - val_loss: 0.0847\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3947 - val_loss: 0.0661\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4424 - val_loss: 0.0937\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3935 - val_loss: 0.0716\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4120 - val_loss: 0.0590\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3803 - val_loss: 0.0635\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4017 - val_loss: 0.0562\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3283 - val_loss: 0.1348\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3992 - val_loss: 0.0617\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4181 - val_loss: 0.0631\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4079 - val_loss: 0.0546\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4295 - val_loss: 0.0652\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3415 - val_loss: 0.0652\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3723 - val_loss: 0.0811\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3690 - val_loss: 0.0638\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4008 - val_loss: 0.0697\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3629 - val_loss: 0.0658\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3861 - val_loss: 0.0633\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3578 - val_loss: 0.0630\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3114 - val_loss: 0.0600\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3566 - val_loss: 0.0748\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3395 - val_loss: 0.0510\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3285 - val_loss: 0.0704\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3652 - val_loss: 0.0914\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4038 - val_loss: 0.0775\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3786 - val_loss: 0.0504\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.2977 - val_loss: 0.0581\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3755 - val_loss: 0.0474\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3465 - val_loss: 0.0604\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3439 - val_loss: 0.0495\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3107 - val_loss: 0.0662\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3091 - val_loss: 0.0615\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3848 - val_loss: 0.0514\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3293 - val_loss: 0.0647\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3548 - val_loss: 0.0652\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3441 - val_loss: 0.0466\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3354 - val_loss: 0.0458\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3155 - val_loss: 0.0501\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.3357 - val_loss: 0.0624\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.3152 - val_loss: 0.1182\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3920 - val_loss: 0.0502\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3267 - val_loss: 0.0591\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3845 - val_loss: 0.1767\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3107 - val_loss: 0.0477\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3037 - val_loss: 0.0698\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3235 - val_loss: 0.0556\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3580 - val_loss: 0.0890\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3282 - val_loss: 0.0506\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3398 - val_loss: 0.0553\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3182 - val_loss: 0.0694\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3177 - val_loss: 0.1062\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3499 - val_loss: 0.0859\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3265 - val_loss: 0.0896\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3657 - val_loss: 0.0701\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.2980 - val_loss: 0.0921\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.2705 - val_loss: 0.0520\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3120 - val_loss: 0.0786\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3232 - val_loss: 0.0645\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3258 - val_loss: 0.0610\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3354 - val_loss: 0.0568\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3089 - val_loss: 0.0648\n",
      "Epoch 125/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3386 - val_loss: 0.1115\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3475 - val_loss: 0.0471\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.3270 - val_loss: 0.0437\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.2811 - val_loss: 0.0475\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3023 - val_loss: 0.0402\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3080 - val_loss: 0.0465\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3309 - val_loss: 0.0914\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3542 - val_loss: 0.0462\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3049 - val_loss: 0.0563\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3264 - val_loss: 0.1428\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3362 - val_loss: 0.1446\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.3484 - val_loss: 0.0625\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.2663 - val_loss: 0.0411\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3567 - val_loss: 0.0672\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.2904 - val_loss: 0.0762\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3800 - val_loss: 0.0531\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3121 - val_loss: 0.0500\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3220 - val_loss: 0.0381\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.2935 - val_loss: 0.0798\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3583 - val_loss: 0.0545\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3047 - val_loss: 0.0340\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3963 - val_loss: 0.0627\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.2795 - val_loss: 0.0465\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3088 - val_loss: 0.1207\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3314 - val_loss: 0.0435\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.2931 - val_loss: 0.0532\n",
      "7/7 [==============================] - 1s 4ms/step\n",
      "Mean Squared Error: 0.05324676674187391\n",
      "Mean Absolute Error: 0.17113914833733102\n",
      "R-squared: 0.994672010827493\n",
      "\n",
      "Fold 2:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 8s 56ms/step - loss: 38.2373 - val_loss: 31.7631\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 16.8327 - val_loss: 8.5751\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 7.6007 - val_loss: 7.7320\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.3233 - val_loss: 6.3486\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.0593 - val_loss: 4.1767\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 2.9022 - val_loss: 1.9076\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.5774 - val_loss: 1.0545\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.2229 - val_loss: 0.8911\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.1512 - val_loss: 0.8065\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.1444 - val_loss: 0.7413\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0552 - val_loss: 0.6755\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0130 - val_loss: 0.6494\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9467 - val_loss: 0.6470\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8582 - val_loss: 0.5452\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8417 - val_loss: 0.4990\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8837 - val_loss: 0.4754\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7631 - val_loss: 0.4366\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7510 - val_loss: 0.4052\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7998 - val_loss: 0.4285\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8153 - val_loss: 0.3563\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7194 - val_loss: 0.3489\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6919 - val_loss: 0.4027\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6700 - val_loss: 0.2851\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7623 - val_loss: 0.2690\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6729 - val_loss: 0.2591\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5981 - val_loss: 0.2440\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6091 - val_loss: 0.2210\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6055 - val_loss: 0.2084\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5287 - val_loss: 0.2202\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4845 - val_loss: 0.1888\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5772 - val_loss: 0.1834\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5449 - val_loss: 0.1770\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5804 - val_loss: 0.1657\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5133 - val_loss: 0.1675\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4917 - val_loss: 0.1539\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4780 - val_loss: 0.1533\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4979 - val_loss: 0.1394\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5290 - val_loss: 0.1441\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5496 - val_loss: 0.1388\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4701 - val_loss: 0.1771\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4791 - val_loss: 0.1197\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3839 - val_loss: 0.1537\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4818 - val_loss: 0.1316\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5069 - val_loss: 0.1149\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5140 - val_loss: 0.1147\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4331 - val_loss: 0.1040\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4514 - val_loss: 0.1802\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4243 - val_loss: 0.0955\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4494 - val_loss: 0.1217\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4426 - val_loss: 0.0910\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4436 - val_loss: 0.0911\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4900 - val_loss: 0.0862\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5720 - val_loss: 0.1036\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4371 - val_loss: 0.0880\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3581 - val_loss: 0.1055\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4572 - val_loss: 0.1047\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4373 - val_loss: 0.0808\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4400 - val_loss: 0.0807\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4719 - val_loss: 0.1156\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4412 - val_loss: 0.0746\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4184 - val_loss: 0.0820\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4082 - val_loss: 0.0759\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4198 - val_loss: 0.0886\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3919 - val_loss: 0.0779\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4317 - val_loss: 0.1113\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4685 - val_loss: 0.0857\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3983 - val_loss: 0.0711\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.3720 - val_loss: 0.0796\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3776 - val_loss: 0.0665\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4048 - val_loss: 0.0776\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3420 - val_loss: 0.1130\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3522 - val_loss: 0.0641\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3890 - val_loss: 0.0841\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.3374 - val_loss: 0.0958\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3948 - val_loss: 0.0995\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3898 - val_loss: 0.0632\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3798 - val_loss: 0.0635\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3707 - val_loss: 0.0647\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3804 - val_loss: 0.0808\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3642 - val_loss: 0.1164\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4156 - val_loss: 0.0596\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3839 - val_loss: 0.0750\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3806 - val_loss: 0.0626\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3745 - val_loss: 0.0702\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3411 - val_loss: 0.0881\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4530 - val_loss: 0.0710\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4343 - val_loss: 0.0754\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.3302 - val_loss: 0.0801\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3607 - val_loss: 0.0588\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3287 - val_loss: 0.0653\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3457 - val_loss: 0.0513\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.2868 - val_loss: 0.0539\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3706 - val_loss: 0.0685\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3661 - val_loss: 0.1339\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4221 - val_loss: 0.0735\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3737 - val_loss: 0.0517\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3425 - val_loss: 0.0570\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3074 - val_loss: 0.0516\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3553 - val_loss: 0.0492\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3106 - val_loss: 0.0460\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3651 - val_loss: 0.0540\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3281 - val_loss: 0.0572\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3337 - val_loss: 0.1239\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3108 - val_loss: 0.0556\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3313 - val_loss: 0.0546\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3420 - val_loss: 0.0524\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3107 - val_loss: 0.0623\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3259 - val_loss: 0.0435\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3132 - val_loss: 0.0518\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3353 - val_loss: 0.0522\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.3487 - val_loss: 0.0624\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.2941 - val_loss: 0.0621\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3879 - val_loss: 0.0454\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.3389 - val_loss: 0.0436\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3311 - val_loss: 0.1030\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3372 - val_loss: 0.0478\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3188 - val_loss: 0.0544\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.2921 - val_loss: 0.0446\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.2910 - val_loss: 0.0470\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3009 - val_loss: 0.0424\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3444 - val_loss: 0.1163\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3538 - val_loss: 0.0506\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3504 - val_loss: 0.0440\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3130 - val_loss: 0.0399\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3315 - val_loss: 0.0590\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3928 - val_loss: 0.0615\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3650 - val_loss: 0.1289\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3476 - val_loss: 0.0408\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3731 - val_loss: 0.0357\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3663 - val_loss: 0.0396\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3465 - val_loss: 0.0720\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.2959 - val_loss: 0.0633\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3025 - val_loss: 0.0510\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3017 - val_loss: 0.0388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.2960 - val_loss: 0.0344\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3279 - val_loss: 0.0313\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3013 - val_loss: 0.0442\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3235 - val_loss: 0.0344\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3292 - val_loss: 0.0356\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3262 - val_loss: 0.0416\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3372 - val_loss: 0.0301\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3294 - val_loss: 0.0431\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.2616 - val_loss: 0.0295\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3052 - val_loss: 0.0898\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3149 - val_loss: 0.0378\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.2792 - val_loss: 0.0297\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.3040 - val_loss: 0.0306\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.3209 - val_loss: 0.0364\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.2754 - val_loss: 0.0269\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3183 - val_loss: 0.0266\n",
      "7/7 [==============================] - 1s 3ms/step\n",
      "Mean Squared Error: 0.02656625794609873\n",
      "Mean Absolute Error: 0.09519637046168693\n",
      "R-squared: 0.9974516769984448\n",
      "\n",
      "Fold 3:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 7s 51ms/step - loss: 39.0336 - val_loss: 31.8183\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 18.8891 - val_loss: 7.2116\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 7.6389 - val_loss: 6.5355\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 6.4971 - val_loss: 5.3380\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.1543 - val_loss: 3.4552\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 2.9153 - val_loss: 1.3804\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.4630 - val_loss: 0.6690\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.2596 - val_loss: 0.5955\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.0739 - val_loss: 0.5291\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.9679 - val_loss: 0.4798\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.0734 - val_loss: 0.4575\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.8606 - val_loss: 0.4018\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8573 - val_loss: 0.3654\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9449 - val_loss: 0.3492\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8500 - val_loss: 0.3175\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7942 - val_loss: 0.2947\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7013 - val_loss: 0.2645\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7520 - val_loss: 0.2520\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7510 - val_loss: 0.2460\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6536 - val_loss: 0.2249\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7499 - val_loss: 0.2403\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7263 - val_loss: 0.1958\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6590 - val_loss: 0.1803\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5791 - val_loss: 0.1714\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6199 - val_loss: 0.1604\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6090 - val_loss: 0.1998\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5228 - val_loss: 0.2201\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5878 - val_loss: 0.1496\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5108 - val_loss: 0.1400\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5282 - val_loss: 0.1531\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5231 - val_loss: 0.1306\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4782 - val_loss: 0.1339\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5212 - val_loss: 0.1272\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5064 - val_loss: 0.1147\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4747 - val_loss: 0.1338\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5337 - val_loss: 0.1400\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4522 - val_loss: 0.1429\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4593 - val_loss: 0.1155\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4706 - val_loss: 0.1040\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4733 - val_loss: 0.1025\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4693 - val_loss: 0.1006\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4099 - val_loss: 0.1094\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4399 - val_loss: 0.0984\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4339 - val_loss: 0.0945\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5222 - val_loss: 0.0911\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4685 - val_loss: 0.1011\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4859 - val_loss: 0.1006\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4271 - val_loss: 0.1367\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4725 - val_loss: 0.1164\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4460 - val_loss: 0.0881\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4354 - val_loss: 0.0930\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4515 - val_loss: 0.1012\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4798 - val_loss: 0.1700\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4620 - val_loss: 0.0818\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4046 - val_loss: 0.1098\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4289 - val_loss: 0.0853\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3939 - val_loss: 0.0922\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4415 - val_loss: 0.0804\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4330 - val_loss: 0.0807\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4056 - val_loss: 0.1102\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4510 - val_loss: 0.0905\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3645 - val_loss: 0.0743\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4352 - val_loss: 0.0749\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4200 - val_loss: 0.0845\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4051 - val_loss: 0.0872\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3575 - val_loss: 0.0918\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4120 - val_loss: 0.0779\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3948 - val_loss: 0.2013\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3666 - val_loss: 0.0727\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4115 - val_loss: 0.0703\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4002 - val_loss: 0.0728\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4200 - val_loss: 0.1350\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3665 - val_loss: 0.0991\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3906 - val_loss: 0.0830\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3860 - val_loss: 0.0788\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3782 - val_loss: 0.0790\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3598 - val_loss: 0.0649\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.2978 - val_loss: 0.0668\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4634 - val_loss: 0.1214\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3878 - val_loss: 0.1036\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3866 - val_loss: 0.0674\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3969 - val_loss: 0.0650\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3632 - val_loss: 0.0661\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4242 - val_loss: 0.0621\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3699 - val_loss: 0.0652\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3755 - val_loss: 0.0751\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3727 - val_loss: 0.0792\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3265 - val_loss: 0.0621\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3625 - val_loss: 0.0545\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3653 - val_loss: 0.0938\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3577 - val_loss: 0.0577\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3983 - val_loss: 0.0886\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4199 - val_loss: 0.1190\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4200 - val_loss: 0.0582\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4352 - val_loss: 0.0531\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3862 - val_loss: 0.1075\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3778 - val_loss: 0.0763\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3973 - val_loss: 0.0605\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4281 - val_loss: 0.0522\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3646 - val_loss: 0.0463\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3102 - val_loss: 0.0477\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.4060 - val_loss: 0.0563\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3660 - val_loss: 0.0536\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3431 - val_loss: 0.0532\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.3615 - val_loss: 0.0484\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3552 - val_loss: 0.0468\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3944 - val_loss: 0.0901\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3387 - val_loss: 0.0795\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3178 - val_loss: 0.0615\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3418 - val_loss: 0.0500\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3236 - val_loss: 0.0565\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3413 - val_loss: 0.0809\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3647 - val_loss: 0.0455\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3147 - val_loss: 0.0410\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3541 - val_loss: 0.0559\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3091 - val_loss: 0.0488\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3292 - val_loss: 0.0610\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.2948 - val_loss: 0.0660\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3013 - val_loss: 0.0390\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3347 - val_loss: 0.0494\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3275 - val_loss: 0.0392\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3312 - val_loss: 0.0484\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3369 - val_loss: 0.0512\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.2963 - val_loss: 0.0455\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3521 - val_loss: 0.1252\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3211 - val_loss: 0.0376\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3012 - val_loss: 0.0446\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.2909 - val_loss: 0.0563\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3274 - val_loss: 0.0463\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3094 - val_loss: 0.0514\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3174 - val_loss: 0.0435\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3346 - val_loss: 0.0513\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3158 - val_loss: 0.0556\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3409 - val_loss: 0.0515\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3295 - val_loss: 0.0496\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.3212 - val_loss: 0.0618\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.3904 - val_loss: 0.0441\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3532 - val_loss: 0.0476\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3226 - val_loss: 0.0889\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3183 - val_loss: 0.0393\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.2879 - val_loss: 0.0865\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.2980 - val_loss: 0.0634\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.2827 - val_loss: 0.0405\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3234 - val_loss: 0.0451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3255 - val_loss: 0.0332\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.2901 - val_loss: 0.0757\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3279 - val_loss: 0.0515\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3078 - val_loss: 0.0359\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3137 - val_loss: 0.1007\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.2948 - val_loss: 0.0380\n",
      "7/7 [==============================] - 1s 3ms/step\n",
      "Mean Squared Error: 0.037960495084736104\n",
      "Mean Absolute Error: 0.12624761654962943\n",
      "R-squared: 0.9958259469556934\n",
      "\n",
      "Fold 4:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 8s 56ms/step - loss: 38.8225 - val_loss: 27.7587\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 15.9617 - val_loss: 7.8147\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 7.6094 - val_loss: 6.0913\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.5603 - val_loss: 4.6338\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2093 - val_loss: 2.6034\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 2.3319 - val_loss: 1.1664\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.3347 - val_loss: 0.8548\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0740 - val_loss: 0.7823\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.0796 - val_loss: 0.7246\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.0533 - val_loss: 0.6857\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9025 - val_loss: 0.6436\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0323 - val_loss: 0.6214\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8800 - val_loss: 0.6353\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8442 - val_loss: 0.5418\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8973 - val_loss: 0.5352\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.9090 - val_loss: 0.5221\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8466 - val_loss: 0.4594\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7250 - val_loss: 0.4373\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7665 - val_loss: 0.4396\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6969 - val_loss: 0.4130\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7177 - val_loss: 0.3710\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7479 - val_loss: 0.3470\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6839 - val_loss: 0.3290\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6787 - val_loss: 0.3226\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6183 - val_loss: 0.3031\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5922 - val_loss: 0.3165\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6686 - val_loss: 0.2692\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5485 - val_loss: 0.2710\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5431 - val_loss: 0.2517\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6462 - val_loss: 0.2621\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6154 - val_loss: 0.2436\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5403 - val_loss: 0.2244\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6039 - val_loss: 0.2234\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5081 - val_loss: 0.2168\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5215 - val_loss: 0.2030\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5069 - val_loss: 0.1986\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5351 - val_loss: 0.2103\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4557 - val_loss: 0.1840\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4892 - val_loss: 0.1819\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4868 - val_loss: 0.1746\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4525 - val_loss: 0.1705\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4404 - val_loss: 0.1747\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4782 - val_loss: 0.2360\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4410 - val_loss: 0.1573\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4151 - val_loss: 0.1623\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5427 - val_loss: 0.1603\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4617 - val_loss: 0.1526\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3608 - val_loss: 0.1538\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4558 - val_loss: 0.1429\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4758 - val_loss: 0.1426\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4161 - val_loss: 0.1403\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4854 - val_loss: 0.1398\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5041 - val_loss: 0.1400\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4268 - val_loss: 0.1466\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4590 - val_loss: 0.1511\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4968 - val_loss: 0.1405\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4442 - val_loss: 0.1433\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4335 - val_loss: 0.2126\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4111 - val_loss: 0.1287\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4553 - val_loss: 0.1531\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3913 - val_loss: 0.1384\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4120 - val_loss: 0.1294\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3870 - val_loss: 0.1314\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4424 - val_loss: 0.1567\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4018 - val_loss: 0.1386\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3961 - val_loss: 0.1210\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3978 - val_loss: 0.1253\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4312 - val_loss: 0.1605\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4260 - val_loss: 0.1277\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4174 - val_loss: 0.1441\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4550 - val_loss: 0.1223\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3714 - val_loss: 0.1178\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3906 - val_loss: 0.1206\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3750 - val_loss: 0.1231\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3996 - val_loss: 0.1077\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3832 - val_loss: 0.1272\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3815 - val_loss: 0.1201\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4076 - val_loss: 0.1789\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3805 - val_loss: 0.1112\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4243 - val_loss: 0.1054\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3880 - val_loss: 0.1212\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4019 - val_loss: 0.1516\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3958 - val_loss: 0.1347\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3426 - val_loss: 0.1269\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3809 - val_loss: 0.1098\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4186 - val_loss: 0.1100\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3580 - val_loss: 0.1060\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3664 - val_loss: 0.1170\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3496 - val_loss: 0.1060\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3371 - val_loss: 0.1030\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3802 - val_loss: 0.1006\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3640 - val_loss: 0.1018\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3592 - val_loss: 0.1185\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3355 - val_loss: 0.1043\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4131 - val_loss: 0.1094\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3584 - val_loss: 0.0992\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3645 - val_loss: 0.1040\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.3483 - val_loss: 0.1195\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3303 - val_loss: 0.0976\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3035 - val_loss: 0.0945\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3425 - val_loss: 0.0937\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3453 - val_loss: 0.0988\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3626 - val_loss: 0.0957\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3544 - val_loss: 0.1076\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3790 - val_loss: 0.0882\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3035 - val_loss: 0.1214\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3240 - val_loss: 0.0850\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3303 - val_loss: 0.0947\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3596 - val_loss: 0.0869\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3290 - val_loss: 0.1022\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3621 - val_loss: 0.1107\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3387 - val_loss: 0.0816\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3132 - val_loss: 0.0923\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3401 - val_loss: 0.0867\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3695 - val_loss: 0.0925\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3311 - val_loss: 0.0800\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3178 - val_loss: 0.0874\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3899 - val_loss: 0.1089\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3082 - val_loss: 0.1001\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3154 - val_loss: 0.0802\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3271 - val_loss: 0.0819\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3471 - val_loss: 0.0791\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3433 - val_loss: 0.0878\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3131 - val_loss: 0.0801\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3336 - val_loss: 0.0896\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3238 - val_loss: 0.0967\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3427 - val_loss: 0.1427\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3023 - val_loss: 0.0775\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3775 - val_loss: 0.0733\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3280 - val_loss: 0.0869\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3517 - val_loss: 0.1112\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3914 - val_loss: 0.0742\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3193 - val_loss: 0.0742\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3844 - val_loss: 0.0864\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3223 - val_loss: 0.0862\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.2950 - val_loss: 0.0815\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.2917 - val_loss: 0.0688\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.2994 - val_loss: 0.0694\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3051 - val_loss: 0.0911\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3034 - val_loss: 0.0961\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3445 - val_loss: 0.0708\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4123 - val_loss: 0.0845\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3367 - val_loss: 0.0615\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.2613 - val_loss: 0.1068\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3193 - val_loss: 0.0662\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3115 - val_loss: 0.0823\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3316 - val_loss: 0.0891\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3161 - val_loss: 0.0729\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3200 - val_loss: 0.0709\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.2900 - val_loss: 0.0662\n",
      "7/7 [==============================] - 1s 3ms/step\n",
      "Mean Squared Error: 0.06616854107148994\n",
      "Mean Absolute Error: 0.1163116663842652\n",
      "R-squared: 0.9922857260935013\n",
      "\n",
      "Fold 5:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 8s 56ms/step - loss: 38.5721 - val_loss: 26.2370\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 15.3929 - val_loss: 6.6244\n",
      "Epoch 3/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 14ms/step - loss: 7.6001 - val_loss: 4.9796\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.9727 - val_loss: 3.4794\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.8442 - val_loss: 1.5784\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.9957 - val_loss: 0.4189\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.2865 - val_loss: 0.2206\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.1034 - val_loss: 0.1590\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.9958 - val_loss: 0.1489\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9811 - val_loss: 0.1469\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.9582 - val_loss: 0.1110\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.9162 - val_loss: 0.0999\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8637 - val_loss: 0.0956\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7720 - val_loss: 0.1009\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8258 - val_loss: 0.0878\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7578 - val_loss: 0.1106\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8208 - val_loss: 0.1499\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8061 - val_loss: 0.0509\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.7154 - val_loss: 0.0575\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.7797 - val_loss: 0.0483\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7375 - val_loss: 0.0643\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6688 - val_loss: 0.0400\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6590 - val_loss: 0.0344\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6135 - val_loss: 0.0364\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6110 - val_loss: 0.0334\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5873 - val_loss: 0.0423\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6148 - val_loss: 0.0397\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6173 - val_loss: 0.0287\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5514 - val_loss: 0.0357\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5502 - val_loss: 0.0419\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5153 - val_loss: 0.0316\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5977 - val_loss: 0.1133\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5223 - val_loss: 0.0404\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5975 - val_loss: 0.0294\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5354 - val_loss: 0.0283\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4995 - val_loss: 0.0381\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4410 - val_loss: 0.0524\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4915 - val_loss: 0.0332\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5416 - val_loss: 0.0543\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5488 - val_loss: 0.0344\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5184 - val_loss: 0.0309\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5147 - val_loss: 0.0529\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5487 - val_loss: 0.0980\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4980 - val_loss: 0.1252\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4989 - val_loss: 0.1119\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4947 - val_loss: 0.0350\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5489 - val_loss: 0.0483\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.4799 - val_loss: 0.0331\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5094 - val_loss: 0.0586\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5340 - val_loss: 0.0452\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4392 - val_loss: 0.0356\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4498 - val_loss: 0.0347\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4607 - val_loss: 0.1226\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4634 - val_loss: 0.0361\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4394 - val_loss: 0.0493\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4971 - val_loss: 0.0396\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3749 - val_loss: 0.0378\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4752 - val_loss: 0.0298\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4586 - val_loss: 0.0329\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4318 - val_loss: 0.0329\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3848 - val_loss: 0.0432\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3812 - val_loss: 0.0537\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4019 - val_loss: 0.0318\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4701 - val_loss: 0.0352\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3997 - val_loss: 0.0275\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3630 - val_loss: 0.0511\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4241 - val_loss: 0.0969\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4068 - val_loss: 0.0451\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3903 - val_loss: 0.0302\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4815 - val_loss: 0.0326\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3798 - val_loss: 0.0595\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4183 - val_loss: 0.0264\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3992 - val_loss: 0.0234\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3820 - val_loss: 0.0521\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3757 - val_loss: 0.0252\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4408 - val_loss: 0.0370\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3553 - val_loss: 0.0320\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4432 - val_loss: 0.0287\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3994 - val_loss: 0.0989\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4531 - val_loss: 0.0344\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3478 - val_loss: 0.0287\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3742 - val_loss: 0.0369\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3395 - val_loss: 0.0263\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4002 - val_loss: 0.0362\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4361 - val_loss: 0.0275\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3389 - val_loss: 0.0329\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3536 - val_loss: 0.0259\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3593 - val_loss: 0.0438\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3122 - val_loss: 0.0515\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4076 - val_loss: 0.0238\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.3466 - val_loss: 0.0269\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3591 - val_loss: 0.0596\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3766 - val_loss: 0.0291\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3868 - val_loss: 0.0501\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3216 - val_loss: 0.0179\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3739 - val_loss: 0.0275\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3626 - val_loss: 0.0326\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3439 - val_loss: 0.0207\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3558 - val_loss: 0.0212\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3492 - val_loss: 0.0272\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3670 - val_loss: 0.0357\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4263 - val_loss: 0.0224\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3603 - val_loss: 0.0338\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.3169 - val_loss: 0.0236\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3675 - val_loss: 0.0498\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3902 - val_loss: 0.0201\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3310 - val_loss: 0.0202\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3564 - val_loss: 0.0258\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4316 - val_loss: 0.0361\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3967 - val_loss: 0.0759\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3570 - val_loss: 0.0397\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3274 - val_loss: 0.0259\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3051 - val_loss: 0.0341\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3545 - val_loss: 0.0165\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3449 - val_loss: 0.0201\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3522 - val_loss: 0.0203\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3602 - val_loss: 0.0172\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3293 - val_loss: 0.0243\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3258 - val_loss: 0.0215\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3272 - val_loss: 0.0171\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3590 - val_loss: 0.0335\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3586 - val_loss: 0.0211\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3110 - val_loss: 0.0199\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3605 - val_loss: 0.0256\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3205 - val_loss: 0.0480\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3573 - val_loss: 0.0153\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.2834 - val_loss: 0.0181\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3013 - val_loss: 0.0124\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.2787 - val_loss: 0.0177\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3271 - val_loss: 0.0133\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.2903 - val_loss: 0.0108\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3176 - val_loss: 0.0168\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3628 - val_loss: 0.0137\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.2991 - val_loss: 0.0282\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3645 - val_loss: 0.0194\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3810 - val_loss: 0.0280\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.3371 - val_loss: 0.0182\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3461 - val_loss: 0.0130\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3203 - val_loss: 0.0226\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.4013 - val_loss: 0.0294\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.3330 - val_loss: 0.0198\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.2912 - val_loss: 0.0177\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.2929 - val_loss: 0.0210\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.2918 - val_loss: 0.0409\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3186 - val_loss: 0.0190\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.2862 - val_loss: 0.0646\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3540 - val_loss: 0.0379\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.2954 - val_loss: 0.0246\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3067 - val_loss: 0.0366\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.3924 - val_loss: 0.0833\n",
      "7/7 [==============================] - 1s 3ms/step\n",
      "Mean Squared Error: 0.08328670572315545\n",
      "Mean Absolute Error: 0.25302673394407205\n",
      "R-squared: 0.9888370096103156\n",
      "\n",
      "Average scores for ticker CLNE:\n",
      "Mean Squared Error: 0.053445753313470824\n",
      "Mean Absolute Error: 0.1523843071353969\n",
      "R-squared: 0.9938144740970897\n",
      "\n",
      "Cross-validation for ticker: LAZR\n",
      "Fold 1:\n",
      "Epoch 1/150\n",
      "24/24 [==============================] - 7s 54ms/step - loss: 205.6272 - val_loss: 197.0596\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 152.0683 - val_loss: 98.9864\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 67.6266 - val_loss: 59.8896\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 54.7835 - val_loss: 57.6289\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 53.3618 - val_loss: 56.1644\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 51.6516 - val_loss: 53.5073\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 48.3999 - val_loss: 48.6039\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 42.9746 - val_loss: 39.4903\n",
      "Epoch 9/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 33.7314 - val_loss: 28.1860\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 25.9787 - val_loss: 21.6702\n",
      "Epoch 11/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 12ms/step - loss: 20.6938 - val_loss: 18.2918\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 19.0042 - val_loss: 15.7856\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 17.0278 - val_loss: 13.8920\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 15.0480 - val_loss: 12.2996\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 13.5708 - val_loss: 11.0831\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 12.8625 - val_loss: 9.9459\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 11.2497 - val_loss: 9.1008\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 10.5775 - val_loss: 8.1482\n",
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 9.7620 - val_loss: 7.3784\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 9.9795 - val_loss: 6.7903\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 8.4583 - val_loss: 6.1933\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 8.6883 - val_loss: 5.6678\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 8.3552 - val_loss: 5.2722\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 7.6207 - val_loss: 4.8062\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 7.4345 - val_loss: 4.5102\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 7.1255 - val_loss: 4.0553\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 6.5242 - val_loss: 3.7580\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 5.6732 - val_loss: 3.7425\n",
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 5.2207 - val_loss: 3.3638\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 5.0116 - val_loss: 3.0504\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 5.2016 - val_loss: 2.8230\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 4.9556 - val_loss: 2.8782\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 5.1464 - val_loss: 2.4932\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 5.2818 - val_loss: 2.3575\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 4.3955 - val_loss: 2.1910\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 4.3846 - val_loss: 2.1196\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.9146 - val_loss: 2.0118\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 3.4351 - val_loss: 1.9105\n",
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 4.0505 - val_loss: 1.7778\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.6330 - val_loss: 1.6407\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 3.6454 - val_loss: 1.5826\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 3.4598 - val_loss: 1.5144\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 3.2339 - val_loss: 1.4987\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 3.5522 - val_loss: 1.3522\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 3.3118 - val_loss: 1.3766\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 3.2332 - val_loss: 1.2346\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2.8719 - val_loss: 1.1853\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 3.0046 - val_loss: 1.1402\n",
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.1299 - val_loss: 1.1365\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.8024 - val_loss: 1.0653\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.8199 - val_loss: 1.0414\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.6466 - val_loss: 1.0099\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.5525 - val_loss: 1.1597\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.8134 - val_loss: 0.9812\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.7180 - val_loss: 1.0474\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.2565 - val_loss: 0.8929\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.2577 - val_loss: 0.9280\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.4903 - val_loss: 0.8900\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.7217 - val_loss: 0.8705\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.2070 - val_loss: 0.8296\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.5667 - val_loss: 0.8370\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1857 - val_loss: 0.7711\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.4198 - val_loss: 0.7707\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.2965 - val_loss: 0.7923\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.5452 - val_loss: 0.7184\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.7203 - val_loss: 0.7030\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.2212 - val_loss: 0.7314\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.5104 - val_loss: 0.8827\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9956 - val_loss: 0.6683\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.2311 - val_loss: 0.6247\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.2875 - val_loss: 0.6255\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.4471 - val_loss: 0.6524\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.1545 - val_loss: 0.8131\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9170 - val_loss: 0.6127\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.4710 - val_loss: 0.6056\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0559 - val_loss: 0.6211\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9930 - val_loss: 0.5511\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0243 - val_loss: 0.5338\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0030 - val_loss: 0.5692\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0013 - val_loss: 0.5370\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.3248 - val_loss: 0.7514\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8479 - val_loss: 0.8444\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.2002 - val_loss: 0.5428\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.2387 - val_loss: 0.4985\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1998 - val_loss: 0.5616\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1792 - val_loss: 0.5207\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.9513 - val_loss: 0.5606\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0675 - val_loss: 0.5179\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0665 - val_loss: 0.6154\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.9730 - val_loss: 0.4340\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1284 - val_loss: 0.4467\n",
      "Epoch 92/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9583 - val_loss: 0.4526\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.8252 - val_loss: 0.4242\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.0530 - val_loss: 0.3920\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.0611 - val_loss: 0.3902\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9564 - val_loss: 0.3731\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8723 - val_loss: 0.3692\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.7582 - val_loss: 0.3702\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.9733 - val_loss: 0.3987\n",
      "Epoch 100/150\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.8189 - val_loss: 0.6377\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.9733 - val_loss: 0.3444\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9879 - val_loss: 0.3656\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.7274 - val_loss: 0.4107\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.6615 - val_loss: 0.3532\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8303 - val_loss: 0.3353\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9960 - val_loss: 0.3258\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6876 - val_loss: 0.3861\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.7976 - val_loss: 0.3521\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8807 - val_loss: 0.3046\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8783 - val_loss: 0.2875\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.9210 - val_loss: 0.2966\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.5021 - val_loss: 0.2770\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.7466 - val_loss: 0.3079\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0257 - val_loss: 0.3112\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6485 - val_loss: 0.3571\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0311 - val_loss: 0.3192\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.9465 - val_loss: 0.2742\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6394 - val_loss: 0.2643\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.6787 - val_loss: 0.2404\n",
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.8266 - val_loss: 0.2692\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8178 - val_loss: 0.2688\n",
      "Epoch 122/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.6505 - val_loss: 0.2526\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.5838 - val_loss: 0.2433\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.9476 - val_loss: 0.2411\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8127 - val_loss: 0.3049\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7730 - val_loss: 0.2393\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.4710 - val_loss: 0.2837\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8624 - val_loss: 0.3153\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.5372 - val_loss: 0.2705\n",
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.7111 - val_loss: 0.4321\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7541 - val_loss: 0.3483\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.4857 - val_loss: 0.3048\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9795 - val_loss: 0.2185\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.3715 - val_loss: 0.2092\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7994 - val_loss: 0.1932\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6523 - val_loss: 0.1959\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6757 - val_loss: 0.2344\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.5509 - val_loss: 0.1877\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.7546 - val_loss: 0.2782\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.8700 - val_loss: 0.2158\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.7490 - val_loss: 0.2257\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.5825 - val_loss: 0.3294\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6400 - val_loss: 0.2162\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.6940 - val_loss: 0.2403\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9208 - val_loss: 0.3458\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6408 - val_loss: 0.1932\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.4844 - val_loss: 0.2007\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.8355 - val_loss: 0.2142\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6547 - val_loss: 0.2045\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6193 - val_loss: 0.2379\n",
      "6/6 [==============================] - 1s 4ms/step\n",
      "Mean Squared Error: 0.23789188668061442\n",
      "Mean Absolute Error: 0.36784059554338455\n",
      "R-squared: 0.9961259145387025\n",
      "\n",
      "Fold 2:\n",
      "Epoch 1/150\n",
      "24/24 [==============================] - 7s 63ms/step - loss: 206.2576 - val_loss: 190.2323\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 147.7099 - val_loss: 86.5054\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 67.6238 - val_loss: 49.0264\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 55.9713 - val_loss: 46.8329\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 53.6025 - val_loss: 44.9757\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 50.2479 - val_loss: 41.6241\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 44.8671 - val_loss: 34.9913\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 35.5182 - val_loss: 25.4092\n",
      "Epoch 9/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 27.2085 - val_loss: 18.7577\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 21.6980 - val_loss: 15.3838\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 18.9052 - val_loss: 13.2025\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 17.4614 - val_loss: 11.5245\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 15.0026 - val_loss: 10.2114\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 13.6989 - val_loss: 9.2029\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 12.1089 - val_loss: 8.3168\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 11.3358 - val_loss: 7.5039\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 11.2517 - val_loss: 6.7970\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 9.4888 - val_loss: 6.2341\n",
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 9.9574 - val_loss: 5.6907\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 9.0622 - val_loss: 5.2222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 8.2741 - val_loss: 4.7499\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 7.2615 - val_loss: 4.4377\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 7.1688 - val_loss: 4.0558\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 6.6603 - val_loss: 3.7465\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 6.0406 - val_loss: 3.4454\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 5.8178 - val_loss: 3.2540\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 5.8719 - val_loss: 2.9844\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 5.1882 - val_loss: 2.7825\n",
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 5.4024 - val_loss: 2.5616\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 4.9202 - val_loss: 2.4079\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 4.9011 - val_loss: 2.2214\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 4.6385 - val_loss: 2.0968\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 4.0197 - val_loss: 1.9483\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.8180 - val_loss: 1.8695\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.8678 - val_loss: 1.8074\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 4.1539 - val_loss: 1.8234\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.4006 - val_loss: 1.5738\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.4550 - val_loss: 1.5585\n",
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.5700 - val_loss: 1.3916\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.3564 - val_loss: 1.3934\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.3853 - val_loss: 1.3250\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.1413 - val_loss: 1.2456\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.2613 - val_loss: 1.3751\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.0437 - val_loss: 1.1634\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.4522 - val_loss: 1.1487\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.9065 - val_loss: 1.1374\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.2339 - val_loss: 1.2020\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.8718 - val_loss: 0.9778\n",
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.1267 - val_loss: 1.1224\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.6149 - val_loss: 0.9832\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.5256 - val_loss: 0.8589\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.6526 - val_loss: 0.8422\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.7335 - val_loss: 0.8321\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.1100 - val_loss: 0.8349\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.8043 - val_loss: 0.7566\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.4783 - val_loss: 0.8854\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.7399 - val_loss: 0.7498\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.5581 - val_loss: 0.7082\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.4076 - val_loss: 0.8970\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.4577 - val_loss: 0.6974\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.4007 - val_loss: 0.6495\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.1708 - val_loss: 0.6816\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0166 - val_loss: 0.8069\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.6013 - val_loss: 0.6390\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 2.3037 - val_loss: 0.7073\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1391 - val_loss: 0.6355\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2.3658 - val_loss: 0.5808\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0842 - val_loss: 0.6060\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.5527 - val_loss: 0.6191\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.4376 - val_loss: 0.5396\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0827 - val_loss: 0.5568\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1787 - val_loss: 0.5281\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.2270 - val_loss: 0.5194\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.1533 - val_loss: 0.5011\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.2725 - val_loss: 0.4931\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.4487 - val_loss: 0.5268\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.1326 - val_loss: 0.4672\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.2649 - val_loss: 0.4737\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1244 - val_loss: 0.4625\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9397 - val_loss: 0.4389\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.0880 - val_loss: 0.4478\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1711 - val_loss: 0.4673\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.8059 - val_loss: 0.4283\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1123 - val_loss: 0.6149\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9636 - val_loss: 0.5756\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.8979 - val_loss: 0.4236\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.0885 - val_loss: 0.3857\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1186 - val_loss: 0.4194\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.2457 - val_loss: 0.4273\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.4952 - val_loss: 0.4673\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.1725 - val_loss: 0.3693\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8402 - val_loss: 0.3982\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6943 - val_loss: 0.4030\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.8929 - val_loss: 0.3352\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0330 - val_loss: 0.3403\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8286 - val_loss: 0.3739\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.6563 - val_loss: 0.4202\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8407 - val_loss: 0.2819\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9695 - val_loss: 0.3741\n",
      "Epoch 100/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8529 - val_loss: 0.4151\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.1059 - val_loss: 0.2970\n",
      "Epoch 102/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6141 - val_loss: 0.4095\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.7440 - val_loss: 0.2907\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9816 - val_loss: 0.2836\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6749 - val_loss: 0.2525\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8022 - val_loss: 0.2345\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8528 - val_loss: 0.2146\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8525 - val_loss: 0.2308\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8021 - val_loss: 0.2823\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9888 - val_loss: 0.2392\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7394 - val_loss: 0.2332\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8174 - val_loss: 0.3245\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8568 - val_loss: 0.2564\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.9440 - val_loss: 0.1918\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.7810 - val_loss: 0.1837\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6288 - val_loss: 0.2051\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.4651 - val_loss: 0.2191\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7418 - val_loss: 0.4252\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7731 - val_loss: 0.2911\n",
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.7562 - val_loss: 0.1931\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.6648 - val_loss: 0.2259\n",
      "Epoch 122/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6393 - val_loss: 0.1995\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.6615 - val_loss: 0.2558\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.4851 - val_loss: 0.2629\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8233 - val_loss: 0.2223\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.7236 - val_loss: 0.2406\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.6109 - val_loss: 0.1623\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.5455 - val_loss: 0.1550\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.7823 - val_loss: 0.3285\n",
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6461 - val_loss: 0.1724\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.4788 - val_loss: 0.2069\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8999 - val_loss: 0.2006\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.4845 - val_loss: 0.2034\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6686 - val_loss: 0.1719\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.5232 - val_loss: 0.1657\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7190 - val_loss: 0.1633\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.9776 - val_loss: 0.1804\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.5059 - val_loss: 0.1670\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.5302 - val_loss: 0.1204\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.3641 - val_loss: 0.1248\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.5721 - val_loss: 0.1401\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.6388 - val_loss: 0.1996\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.4426 - val_loss: 0.2448\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.4435 - val_loss: 0.1524\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6911 - val_loss: 0.1154\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6412 - val_loss: 0.2021\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.5706 - val_loss: 0.1521\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6155 - val_loss: 0.1717\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.3828 - val_loss: 0.1689\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6160 - val_loss: 0.1521\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Mean Squared Error: 0.15211686654244153\n",
      "Mean Absolute Error: 0.2509865935560296\n",
      "R-squared: 0.997012681297847\n",
      "\n",
      "Fold 3:\n",
      "Epoch 1/150\n",
      "24/24 [==============================] - 8s 59ms/step - loss: 205.8175 - val_loss: 187.7679\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 148.9643 - val_loss: 92.3067\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 71.9077 - val_loss: 53.7164\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 57.9134 - val_loss: 49.6323\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 56.6790 - val_loss: 48.3033\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 54.9835 - val_loss: 46.7491\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 51.4691 - val_loss: 43.5637\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 47.7254 - val_loss: 37.2282\n",
      "Epoch 9/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 38.1626 - val_loss: 27.7737\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 28.4605 - val_loss: 20.2878\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 22.8522 - val_loss: 16.9255\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 19.1940 - val_loss: 14.7668\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 17.2458 - val_loss: 13.0885\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 15.8885 - val_loss: 11.8995\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 13.7268 - val_loss: 10.7911\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 13.8500 - val_loss: 9.9148\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 12.4950 - val_loss: 9.2031\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 12.1737 - val_loss: 8.3918\n",
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 10.3432 - val_loss: 7.9283\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 9.4356 - val_loss: 7.1124\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 8.9862 - val_loss: 6.5705\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 8.4381 - val_loss: 6.1628\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 7.3524 - val_loss: 5.7639\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 6.8931 - val_loss: 5.4196\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 6.6908 - val_loss: 5.0303\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 7.0608 - val_loss: 4.7066\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 6.3055 - val_loss: 4.5852\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 5.5656 - val_loss: 4.1498\n",
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 5.3971 - val_loss: 3.8845\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.2393 - val_loss: 3.6815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 5.3027 - val_loss: 3.5734\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 5.2870 - val_loss: 3.3266\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 4.6926 - val_loss: 3.1309\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 4.4126 - val_loss: 2.9296\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 4.1718 - val_loss: 2.8952\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 4.2926 - val_loss: 2.6324\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 4.1349 - val_loss: 2.5250\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.5371 - val_loss: 2.4329\n",
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.7893 - val_loss: 2.3312\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.4092 - val_loss: 2.1989\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 3.5662 - val_loss: 2.2092\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.4982 - val_loss: 2.0321\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.1325 - val_loss: 2.1735\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.4144 - val_loss: 1.8829\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 3.1908 - val_loss: 1.8118\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2.8027 - val_loss: 1.7966\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2.8776 - val_loss: 1.7617\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.9338 - val_loss: 1.6606\n",
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.9962 - val_loss: 1.5810\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.7008 - val_loss: 1.5010\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.8231 - val_loss: 1.5087\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.7289 - val_loss: 1.4271\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.8635 - val_loss: 1.4004\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2423 - val_loss: 1.3330\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.6228 - val_loss: 1.2908\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2.6685 - val_loss: 1.3214\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.4418 - val_loss: 1.2383\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.5519 - val_loss: 1.2203\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2.3203 - val_loss: 1.2202\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.2910 - val_loss: 1.2123\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.5917 - val_loss: 1.0935\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.3651 - val_loss: 1.0754\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2.1663 - val_loss: 1.1200\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.6754 - val_loss: 1.0565\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.6468 - val_loss: 1.0352\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1866 - val_loss: 0.9931\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.3258 - val_loss: 0.9892\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1583 - val_loss: 0.9412\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.5834 - val_loss: 0.9099\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.2087 - val_loss: 0.8922\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2.0194 - val_loss: 0.8783\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.4372 - val_loss: 0.8561\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.5015 - val_loss: 0.8446\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9640 - val_loss: 0.8894\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.1489 - val_loss: 0.9071\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8719 - val_loss: 0.8344\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1757 - val_loss: 0.7718\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.2179 - val_loss: 0.7657\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2.0581 - val_loss: 0.8378\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.0033 - val_loss: 0.7274\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8528 - val_loss: 0.7789\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.3197 - val_loss: 0.8735\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8617 - val_loss: 0.7663\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2.1102 - val_loss: 0.7384\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.9684 - val_loss: 0.7361\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.1469 - val_loss: 0.6557\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8347 - val_loss: 0.6504\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9629 - val_loss: 0.6573\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9382 - val_loss: 0.7762\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2.0322 - val_loss: 0.6431\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6887 - val_loss: 0.5988\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9479 - val_loss: 0.5681\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9282 - val_loss: 0.5714\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0317 - val_loss: 0.5446\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9180 - val_loss: 0.5908\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.6427 - val_loss: 0.6570\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.6987 - val_loss: 0.5454\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7692 - val_loss: 0.5370\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7179 - val_loss: 0.5533\n",
      "Epoch 100/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.7898 - val_loss: 0.5765\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8406 - val_loss: 0.4901\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.9447 - val_loss: 0.4945\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.2446 - val_loss: 0.5804\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9238 - val_loss: 0.5368\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.8203 - val_loss: 0.5393\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.9390 - val_loss: 0.4513\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7863 - val_loss: 0.5527\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9251 - val_loss: 0.4399\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0268 - val_loss: 0.4838\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8635 - val_loss: 0.4234\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5938 - val_loss: 0.4828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9822 - val_loss: 0.4307\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8632 - val_loss: 0.4477\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.5922 - val_loss: 0.3761\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7053 - val_loss: 0.3487\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.3992 - val_loss: 0.4429\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7302 - val_loss: 0.3617\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 2.1453 - val_loss: 0.3398\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.7736 - val_loss: 0.4311\n",
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.6154 - val_loss: 0.5360\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.7104 - val_loss: 0.3202\n",
      "Epoch 122/150\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.6598 - val_loss: 0.4629\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.5702 - val_loss: 0.3400\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.5731 - val_loss: 0.3702\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7347 - val_loss: 0.5403\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8255 - val_loss: 0.3122\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.3333 - val_loss: 0.3624\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6874 - val_loss: 0.3064\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.7227 - val_loss: 0.3077\n",
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.6185 - val_loss: 0.2949\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 6ms/step - loss: 1.3877 - val_loss: 0.4525\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.4941 - val_loss: 0.3565\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.7119 - val_loss: 0.3430\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.5330 - val_loss: 0.2935\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6930 - val_loss: 0.3001\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.7984 - val_loss: 0.3869\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.5556 - val_loss: 0.3684\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.5894 - val_loss: 0.3446\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5453 - val_loss: 0.2654\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.5452 - val_loss: 0.4827\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.7476 - val_loss: 0.3318\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.6162 - val_loss: 0.2693\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.5371 - val_loss: 0.3097\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7238 - val_loss: 0.3136\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.4780 - val_loss: 0.4847\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.5611 - val_loss: 0.2876\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.5227 - val_loss: 0.3464\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.5201 - val_loss: 0.2965\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.3800 - val_loss: 0.2765\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.5338 - val_loss: 0.2512\n",
      "6/6 [==============================] - 1s 4ms/step\n",
      "Mean Squared Error: 0.25120180615445264\n",
      "Mean Absolute Error: 0.1976744754152149\n",
      "R-squared: 0.9950969792867059\n",
      "\n",
      "Fold 4:\n",
      "Epoch 1/150\n",
      "24/24 [==============================] - 7s 80ms/step - loss: 206.4440 - val_loss: 184.3698\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 145.9904 - val_loss: 90.1246\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 65.4618 - val_loss: 62.1375\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 52.4076 - val_loss: 62.2759\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 52.2664 - val_loss: 60.5994\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 51.2489 - val_loss: 57.3783\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 47.6029 - val_loss: 50.6467\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 39.9667 - val_loss: 38.3124\n",
      "Epoch 9/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 30.4955 - val_loss: 28.1748\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 23.7570 - val_loss: 22.5383\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 19.6320 - val_loss: 19.5979\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 17.0218 - val_loss: 17.5209\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 14.8705 - val_loss: 15.7312\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 13.9637 - val_loss: 14.3144\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 12.5836 - val_loss: 12.9811\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 11.8351 - val_loss: 11.8907\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 10.9147 - val_loss: 10.7555\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 9.5456 - val_loss: 10.0517\n",
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 9.6797 - val_loss: 9.2855\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 8.4833 - val_loss: 8.4302\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 7.3829 - val_loss: 7.8311\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 7.4047 - val_loss: 7.2447\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 7.4490 - val_loss: 6.6975\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 6.8609 - val_loss: 6.2418\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 6.1862 - val_loss: 5.8140\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 5.6791 - val_loss: 5.4414\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 6.0035 - val_loss: 5.0823\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 5.7231 - val_loss: 4.6474\n",
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 5.5378 - val_loss: 4.4400\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 5.3265 - val_loss: 4.1185\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 4.9898 - val_loss: 3.8912\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 4.4873 - val_loss: 3.6109\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 4.7444 - val_loss: 3.3095\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 4.0975 - val_loss: 3.1173\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 4.0621 - val_loss: 2.9546\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.9919 - val_loss: 2.7936\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 4.2285 - val_loss: 2.7189\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.7250 - val_loss: 2.5371\n",
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.5692 - val_loss: 2.3664\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.5879 - val_loss: 2.2655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.5524 - val_loss: 2.1611\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.7089 - val_loss: 2.1273\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 3.2966 - val_loss: 2.0256\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 3.5610 - val_loss: 2.1395\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.0860 - val_loss: 1.7745\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.0556 - val_loss: 1.7496\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.0616 - val_loss: 1.6807\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.7267 - val_loss: 1.5788\n",
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.0798 - val_loss: 1.5053\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.7101 - val_loss: 1.6789\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.9273 - val_loss: 1.4229\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.9356 - val_loss: 1.6133\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.7402 - val_loss: 1.3276\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.8320 - val_loss: 1.3581\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.7042 - val_loss: 1.2881\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.5909 - val_loss: 1.2294\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.6124 - val_loss: 1.3698\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.2949 - val_loss: 1.1966\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.5087 - val_loss: 1.1076\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.1441 - val_loss: 1.1079\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.4587 - val_loss: 1.0157\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.2727 - val_loss: 1.0283\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.6200 - val_loss: 1.0186\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.6013 - val_loss: 0.9848\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.3705 - val_loss: 1.1622\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2.5558 - val_loss: 1.0310\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 2.1561 - val_loss: 0.9098\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.6175 - val_loss: 0.9894\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.2333 - val_loss: 0.8294\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.9852 - val_loss: 0.8449\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.1367 - val_loss: 0.9168\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 2.4455 - val_loss: 0.7810\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 2.2900 - val_loss: 0.9072\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.2317 - val_loss: 0.7726\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9189 - val_loss: 0.9088\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0461 - val_loss: 0.6865\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8098 - val_loss: 0.6816\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.9385 - val_loss: 0.7708\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0329 - val_loss: 0.6211\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.1437 - val_loss: 0.6699\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0118 - val_loss: 0.8969\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.4457 - val_loss: 0.6981\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.1771 - val_loss: 0.6121\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.0686 - val_loss: 0.5977\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9663 - val_loss: 0.5690\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0869 - val_loss: 0.6494\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0795 - val_loss: 0.5794\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.7911 - val_loss: 0.5660\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.7671 - val_loss: 0.5231\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.2288 - val_loss: 0.6426\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8942 - val_loss: 0.4940\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.8698 - val_loss: 0.4671\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.8635 - val_loss: 0.4605\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8089 - val_loss: 0.4390\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.7644 - val_loss: 0.4991\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.9649 - val_loss: 0.4681\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 10ms/step - loss: 1.8021 - val_loss: 0.4443\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8671 - val_loss: 0.3750\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.1658 - val_loss: 0.3671\n",
      "Epoch 100/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8731 - val_loss: 0.3920\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7942 - val_loss: 0.3605\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8688 - val_loss: 0.3534\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0499 - val_loss: 0.3732\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7997 - val_loss: 0.3390\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.5121 - val_loss: 0.3262\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.9713 - val_loss: 0.4230\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.7799 - val_loss: 0.3412\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.0337 - val_loss: 0.3895\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6620 - val_loss: 0.3640\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.7623 - val_loss: 0.3892\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7661 - val_loss: 0.2941\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.7152 - val_loss: 0.3082\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6341 - val_loss: 0.3832\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.8224 - val_loss: 0.2630\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6265 - val_loss: 0.3679\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.9961 - val_loss: 0.4516\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.7117 - val_loss: 0.2642\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.7241 - val_loss: 0.2889\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.5500 - val_loss: 0.3092\n",
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6498 - val_loss: 0.2354\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6103 - val_loss: 0.3086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.5004 - val_loss: 0.2600\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7239 - val_loss: 0.2520\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7690 - val_loss: 0.2189\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5449 - val_loss: 0.3257\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9390 - val_loss: 0.2466\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.1109 - val_loss: 0.2317\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6513 - val_loss: 0.3339\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5953 - val_loss: 0.2403\n",
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6562 - val_loss: 0.3884\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6103 - val_loss: 0.2066\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.8214 - val_loss: 0.2088\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.8920 - val_loss: 0.1962\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.4784 - val_loss: 0.1931\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.4477 - val_loss: 0.2413\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6735 - val_loss: 0.3103\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7518 - val_loss: 0.3018\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6608 - val_loss: 0.3714\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6869 - val_loss: 0.1789\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.5437 - val_loss: 0.2205\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6399 - val_loss: 0.2230\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.4033 - val_loss: 0.2184\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.5788 - val_loss: 0.2368\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.1337 - val_loss: 0.5017\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6981 - val_loss: 0.2000\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.5172 - val_loss: 0.1928\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.5892 - val_loss: 0.3490\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.4769 - val_loss: 0.2997\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.8185 - val_loss: 0.1634\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6702 - val_loss: 0.2217\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Mean Squared Error: 0.22174696573209515\n",
      "Mean Absolute Error: 0.34150151931802647\n",
      "R-squared: 0.9966203255248148\n",
      "\n",
      "Fold 5:\n",
      "Epoch 1/150\n",
      "24/24 [==============================] - 7s 56ms/step - loss: 207.2326 - val_loss: 188.9569\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 151.5365 - val_loss: 92.0284\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 69.4055 - val_loss: 54.7488\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 55.0022 - val_loss: 51.9736\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 53.7291 - val_loss: 50.3209\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 51.3501 - val_loss: 46.9795\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 47.0888 - val_loss: 40.9325\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 38.5089 - val_loss: 32.0258\n",
      "Epoch 9/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 28.8657 - val_loss: 23.8889\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 22.4708 - val_loss: 19.9089\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 20.3369 - val_loss: 17.3274\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 17.3109 - val_loss: 15.4334\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 16.1363 - val_loss: 13.9857\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 13.7836 - val_loss: 12.5847\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 13.3791 - val_loss: 11.5145\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 12.5224 - val_loss: 10.4622\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 11.3743 - val_loss: 9.6018\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 10.2788 - val_loss: 8.8403\n",
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 9.9065 - val_loss: 8.0468\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 9.0141 - val_loss: 7.4201\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 9.0170 - val_loss: 6.8760\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 7.5476 - val_loss: 6.3291\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 7.9785 - val_loss: 5.9560\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 7.4351 - val_loss: 5.3880\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 6.7050 - val_loss: 5.1192\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 6.2325 - val_loss: 4.7120\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 6.0795 - val_loss: 4.3106\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 5.3627 - val_loss: 4.0360\n",
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 5.1470 - val_loss: 3.9436\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 5.3829 - val_loss: 3.5596\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 4.5031 - val_loss: 3.3194\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 5.1298 - val_loss: 3.0553\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 4.5098 - val_loss: 3.0319\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 4.2198 - val_loss: 2.7773\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 4.2924 - val_loss: 2.7733\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 4.0366 - val_loss: 2.4547\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 4.4000 - val_loss: 2.5850\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.9300 - val_loss: 2.1826\n",
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 4.1457 - val_loss: 2.0562\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 3.5752 - val_loss: 2.0037\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.5738 - val_loss: 1.8530\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.2569 - val_loss: 1.7388\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 3.4226 - val_loss: 1.7145\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.3324 - val_loss: 1.5714\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.0214 - val_loss: 1.5917\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.3631 - val_loss: 1.6463\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.1105 - val_loss: 1.4529\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.9516 - val_loss: 1.3954\n",
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 3.2939 - val_loss: 1.4218\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.7132 - val_loss: 1.2864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.4558 - val_loss: 1.2288\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.5798 - val_loss: 1.1841\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.6143 - val_loss: 1.2423\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.4833 - val_loss: 1.1577\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.6104 - val_loss: 1.2753\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.8932 - val_loss: 1.0252\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.2073 - val_loss: 1.0693\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.8699 - val_loss: 1.1117\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.6877 - val_loss: 0.9689\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.7174 - val_loss: 0.9105\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.2723 - val_loss: 0.9827\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.7720 - val_loss: 0.8857\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.3515 - val_loss: 0.9593\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.7020 - val_loss: 0.8928\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.3031 - val_loss: 0.8738\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.4268 - val_loss: 0.8864\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.4332 - val_loss: 0.7905\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.2625 - val_loss: 0.7935\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.6300 - val_loss: 0.7453\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.2472 - val_loss: 0.7061\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.4702 - val_loss: 0.8674\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.1885 - val_loss: 0.7037\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0209 - val_loss: 0.7090\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.3066 - val_loss: 0.7069\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.1215 - val_loss: 0.6520\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0488 - val_loss: 0.6920\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1784 - val_loss: 0.7435\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1040 - val_loss: 0.6264\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.2692 - val_loss: 0.8463\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1803 - val_loss: 0.6185\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1618 - val_loss: 0.6523\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9070 - val_loss: 0.5776\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9919 - val_loss: 0.8976\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0377 - val_loss: 0.5628\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.9310 - val_loss: 0.5607\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0856 - val_loss: 0.5457\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.3009 - val_loss: 0.6234\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0531 - val_loss: 0.5933\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.4017 - val_loss: 0.5799\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8809 - val_loss: 0.5677\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.3406 - val_loss: 0.4923\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.8739 - val_loss: 0.6425\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0250 - val_loss: 0.5984\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.1298 - val_loss: 0.4734\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.8405 - val_loss: 0.4488\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8826 - val_loss: 0.4843\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9047 - val_loss: 0.4867\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7952 - val_loss: 0.4953\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.7246 - val_loss: 0.4497\n",
      "Epoch 100/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.9397 - val_loss: 0.4364\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 2.1026 - val_loss: 0.4761\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.9408 - val_loss: 0.4648\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 2.0171 - val_loss: 0.4044\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.9343 - val_loss: 0.5083\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0638 - val_loss: 0.5176\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0285 - val_loss: 0.4473\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.5380 - val_loss: 0.3732\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6011 - val_loss: 0.4258\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0189 - val_loss: 0.4084\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6587 - val_loss: 0.3711\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0555 - val_loss: 0.4990\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8750 - val_loss: 0.4606\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.7851 - val_loss: 0.3516\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.6756 - val_loss: 0.4331\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.9184 - val_loss: 0.4738\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7999 - val_loss: 0.4404\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.7667 - val_loss: 0.3526\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.8983 - val_loss: 0.3725\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0422 - val_loss: 0.3338\n",
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5738 - val_loss: 0.3465\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 2.0413 - val_loss: 0.3198\n",
      "Epoch 122/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7818 - val_loss: 0.3643\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6227 - val_loss: 0.4610\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.8983 - val_loss: 0.2978\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 9ms/step - loss: 1.4955 - val_loss: 0.2894\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 8ms/step - loss: 1.4645 - val_loss: 0.3790\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.8967 - val_loss: 0.3191\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 11ms/step - loss: 1.6683 - val_loss: 0.3666\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6565 - val_loss: 0.2893\n",
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.6496 - val_loss: 0.2957\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.8541 - val_loss: 0.3012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.6207 - val_loss: 0.2818\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6613 - val_loss: 0.3026\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.7716 - val_loss: 0.2775\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.7661 - val_loss: 0.2517\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6202 - val_loss: 0.4354\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.7701 - val_loss: 0.2844\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.7115 - val_loss: 0.3145\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.5843 - val_loss: 0.2444\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.7624 - val_loss: 0.2552\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.5628 - val_loss: 0.3485\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6763 - val_loss: 0.2641\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6979 - val_loss: 0.2347\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.4481 - val_loss: 0.2373\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.4324 - val_loss: 0.2366\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.5145 - val_loss: 0.4269\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.6437 - val_loss: 0.2545\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.7923 - val_loss: 0.3188\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 14ms/step - loss: 1.5047 - val_loss: 0.2379\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.7259 - val_loss: 0.2375\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "Mean Squared Error: 0.23746561203768635\n",
      "Mean Absolute Error: 0.2530720708257865\n",
      "R-squared: 0.9957027279677462\n",
      "\n",
      "Average scores for ticker LAZR:\n",
      "Mean Squared Error: 0.22008462742945803\n",
      "Mean Absolute Error: 0.2822150509316884\n",
      "R-squared: 0.9961117257231631\n",
      "\n",
      "Cross-validation for ticker: AMWL\n",
      "Fold 1:\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 8s 70ms/step - loss: 160.8387 - val_loss: 157.8489\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 127.6612 - val_loss: 101.6099\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 83.1811 - val_loss: 80.1769\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 74.8439 - val_loss: 69.8794\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 61.5748 - val_loss: 53.5345\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 42.6859 - val_loss: 35.4588\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 30.5150 - val_loss: 26.6759\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 25.1966 - val_loss: 22.5693\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 22.6233 - val_loss: 19.5876\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 19.3529 - val_loss: 16.9539\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 17.3860 - val_loss: 14.7044\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 14.8389 - val_loss: 13.0630\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 14.9011 - val_loss: 11.2047\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 13.3447 - val_loss: 9.9830\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 11.5463 - val_loss: 8.5860\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 10.3279 - val_loss: 7.5650\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 9.3994 - val_loss: 6.6911\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 8.3384 - val_loss: 5.9150\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 7.5624 - val_loss: 5.2349\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 7.1596 - val_loss: 4.6350\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 6.4110 - val_loss: 4.1345\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 6.1346 - val_loss: 3.7159\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 6.2475 - val_loss: 3.2720\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 5.4068 - val_loss: 2.9368\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 4.9703 - val_loss: 2.7088\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 4.8052 - val_loss: 2.4167\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 4.6908 - val_loss: 2.2104\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.8853 - val_loss: 2.0431\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 3.7959 - val_loss: 1.9889\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 4.1501 - val_loss: 1.7615\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 4.0676 - val_loss: 1.6995\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.7389 - val_loss: 1.5564\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.4454 - val_loss: 1.5329\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.3511 - val_loss: 1.5096\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.2994 - val_loss: 1.3828\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.3881 - val_loss: 1.3175\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.9532 - val_loss: 1.2748\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.0244 - val_loss: 1.2313\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.4928 - val_loss: 1.2385\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.2818 - val_loss: 1.4095\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.9057 - val_loss: 1.1285\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.0538 - val_loss: 1.1278\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 3.1336 - val_loss: 1.0932\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.6436 - val_loss: 1.0560\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.6955 - val_loss: 1.1258\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.4285 - val_loss: 1.0567\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.4416 - val_loss: 1.0529\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.5095 - val_loss: 0.9933\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.6864 - val_loss: 0.9342\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 2.6726 - val_loss: 0.8979\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 2.4697 - val_loss: 0.9920\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.2960 - val_loss: 0.9508\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.4236 - val_loss: 0.9525\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 2.2894 - val_loss: 0.9077\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.9124 - val_loss: 0.8234\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 2.1160 - val_loss: 0.8066\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 2.4538 - val_loss: 0.8964\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.1934 - val_loss: 0.9480\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.5481 - val_loss: 0.9039\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.4225 - val_loss: 0.7533\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0758 - val_loss: 0.7598\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.9946 - val_loss: 0.7249\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.2453 - val_loss: 0.7124\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.2533 - val_loss: 0.7255\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.2875 - val_loss: 0.7318\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.1512 - val_loss: 0.9157\n",
      "Epoch 67/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.9164 - val_loss: 0.6616\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8767 - val_loss: 0.6790\n",
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.5516 - val_loss: 0.6665\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.1656 - val_loss: 0.6525\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.2857 - val_loss: 0.6348\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.9227 - val_loss: 0.8167\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.0138 - val_loss: 0.7004\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.1669 - val_loss: 0.7314\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 2.0993 - val_loss: 0.6257\n",
      "Epoch 76/150\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 2.2216 - val_loss: 0.6868\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 2.2185 - val_loss: 0.6752\n",
      "Epoch 78/150\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 2.0566 - val_loss: 0.5668\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9981 - val_loss: 0.5735\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 2.3470 - val_loss: 0.8739\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.2538 - val_loss: 0.7400\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1342 - val_loss: 0.5341\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 2.0800 - val_loss: 0.5750\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1490 - val_loss: 0.5144\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.2148 - val_loss: 0.7177\n",
      "Epoch 86/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.6400 - val_loss: 0.5447\n",
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.8154 - val_loss: 0.5862\n",
      "Epoch 88/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 2.0981 - val_loss: 0.5108\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.6146 - val_loss: 0.4865\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7663 - val_loss: 0.4603\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8468 - val_loss: 0.4503\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.0610 - val_loss: 0.4299\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.7792 - val_loss: 0.4198\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.8713 - val_loss: 0.4395\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 1.8833 - val_loss: 0.6155\n",
      "Epoch 96/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0558 - val_loss: 0.4482\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.9525 - val_loss: 0.4820\n",
      "Epoch 98/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.8788 - val_loss: 0.5459\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6056 - val_loss: 0.4226\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.1357 - val_loss: 0.4546\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.6901 - val_loss: 0.3447\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9546 - val_loss: 0.3851\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.8426 - val_loss: 0.3887\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5523 - val_loss: 0.3564\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8556 - val_loss: 0.4570\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8419 - val_loss: 0.4303\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8387 - val_loss: 0.4314\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.9207 - val_loss: 0.3328\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0035 - val_loss: 0.5489\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.6420 - val_loss: 0.3137\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7551 - val_loss: 0.3524\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9957 - val_loss: 0.5401\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.2584 - val_loss: 0.3015\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8642 - val_loss: 0.2768\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.6894 - val_loss: 0.2671\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7924 - val_loss: 0.3151\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.5478 - val_loss: 0.4537\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.6186 - val_loss: 0.3443\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.7688 - val_loss: 0.3074\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.4022 - val_loss: 0.3448\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.9013 - val_loss: 0.3100\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.5878 - val_loss: 0.2995\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6102 - val_loss: 0.2596\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8020 - val_loss: 0.2474\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.6692 - val_loss: 0.4724\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7144 - val_loss: 0.2655\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8993 - val_loss: 0.3395\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8255 - val_loss: 0.2903\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6778 - val_loss: 0.2780\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7349 - val_loss: 0.2605\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.4198 - val_loss: 0.2220\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.4260 - val_loss: 0.2441\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.3543 - val_loss: 0.2427\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0357 - val_loss: 0.4170\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.4050 - val_loss: 0.2473\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.6863 - val_loss: 0.2695\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.5095 - val_loss: 0.1921\n",
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.5604 - val_loss: 0.2549\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7018 - val_loss: 0.3138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7938 - val_loss: 0.2572\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.6179 - val_loss: 0.2160\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.3935 - val_loss: 0.1806\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.6221 - val_loss: 0.4424\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.5381 - val_loss: 0.2945\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6195 - val_loss: 0.1912\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7225 - val_loss: 0.2649\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.6748 - val_loss: 0.2206\n",
      "Epoch 148/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.2856 - val_loss: 0.2955\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6600 - val_loss: 0.1753\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.3861 - val_loss: 0.1937\n",
      "6/6 [==============================] - 1s 4ms/step\n",
      "Mean Squared Error: 0.19374114051776023\n",
      "Mean Absolute Error: 0.30485812511788796\n",
      "R-squared: 0.9978742064354696\n",
      "\n",
      "Fold 2:\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 7s 61ms/step - loss: 161.1415 - val_loss: 168.8759\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 137.2851 - val_loss: 121.2142\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 93.4270 - val_loss: 88.5657\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 79.9035 - val_loss: 83.8593\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 75.3260 - val_loss: 74.9041\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 63.8954 - val_loss: 60.4594\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 48.3896 - val_loss: 44.2952\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 37.9406 - val_loss: 35.5453\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 32.0466 - val_loss: 30.5156\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 28.1207 - val_loss: 26.8848\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 24.0652 - val_loss: 23.9098\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 22.6426 - val_loss: 21.3058\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 19.7644 - val_loss: 19.0027\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 18.3108 - val_loss: 17.0002\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 15.9013 - val_loss: 15.0825\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 14.6786 - val_loss: 13.5002\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 13.7376 - val_loss: 12.0782\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 11.6331 - val_loss: 10.8073\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 10.7986 - val_loss: 9.7113\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 9.9738 - val_loss: 8.7102\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 9.3831 - val_loss: 7.8662\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 8.4277 - val_loss: 7.0529\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 8.0591 - val_loss: 6.3188\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 7.2578 - val_loss: 5.7705\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 6.4057 - val_loss: 5.3028\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 5.9523 - val_loss: 4.7659\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 5.3432 - val_loss: 4.3946\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 5.5704 - val_loss: 4.0241\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 4.9511 - val_loss: 3.6984\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 4.5446 - val_loss: 3.4537\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 4.2105 - val_loss: 3.1586\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 4.5929 - val_loss: 2.9930\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 4.4361 - val_loss: 2.8792\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 4.1441 - val_loss: 2.6184\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 4.0580 - val_loss: 2.5168\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.8548 - val_loss: 2.4111\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.8185 - val_loss: 2.2211\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.5251 - val_loss: 2.1740\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.7479 - val_loss: 2.0369\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.3920 - val_loss: 1.9287\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.3787 - val_loss: 1.8758\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.0879 - val_loss: 1.7908\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.9058 - val_loss: 1.7482\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.1790 - val_loss: 1.6428\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.9798 - val_loss: 1.5698\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.4394 - val_loss: 1.5296\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.5283 - val_loss: 1.5580\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.6362 - val_loss: 1.4900\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.2822 - val_loss: 1.4073\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.0055 - val_loss: 1.3894\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.2755 - val_loss: 1.3477\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.5563 - val_loss: 1.2728\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.8647 - val_loss: 1.3027\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.4955 - val_loss: 1.2713\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.4341 - val_loss: 1.2251\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.4609 - val_loss: 1.1630\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.3162 - val_loss: 1.1438\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0961 - val_loss: 1.1288\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.4298 - val_loss: 1.1303\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.5566 - val_loss: 1.0573\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.2803 - val_loss: 1.0419\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.5387 - val_loss: 1.0012\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.1472 - val_loss: 0.9729\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.7033 - val_loss: 1.0405\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.9314 - val_loss: 0.9418\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.3616 - val_loss: 0.9666\n",
      "Epoch 67/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.2511 - val_loss: 0.9493\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7637 - val_loss: 0.9673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1940 - val_loss: 1.0428\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1999 - val_loss: 0.8202\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.2415 - val_loss: 0.9274\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.2702 - val_loss: 0.8242\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9167 - val_loss: 0.8557\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9845 - val_loss: 0.8372\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1640 - val_loss: 0.7698\n",
      "Epoch 76/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1341 - val_loss: 0.7431\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.6985 - val_loss: 0.7345\n",
      "Epoch 78/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.2165 - val_loss: 0.7607\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0148 - val_loss: 0.7213\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.1443 - val_loss: 0.7118\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.9583 - val_loss: 0.7136\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.4466 - val_loss: 0.7638\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0408 - val_loss: 0.7459\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1196 - val_loss: 0.6712\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0190 - val_loss: 0.6756\n",
      "Epoch 86/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7887 - val_loss: 0.6178\n",
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.9961 - val_loss: 0.6940\n",
      "Epoch 88/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.2965 - val_loss: 0.7157\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.8539 - val_loss: 0.6505\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.6654 - val_loss: 0.6061\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.0984 - val_loss: 0.5903\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7609 - val_loss: 0.5718\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.6759 - val_loss: 0.5587\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8106 - val_loss: 0.5467\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.7477 - val_loss: 0.5380\n",
      "Epoch 96/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.1331 - val_loss: 0.5775\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.8582 - val_loss: 0.5088\n",
      "Epoch 98/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.4921 - val_loss: 0.5569\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6100 - val_loss: 0.4979\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6957 - val_loss: 0.5209\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8235 - val_loss: 0.4975\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8919 - val_loss: 0.7497\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8303 - val_loss: 0.7563\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8716 - val_loss: 0.6922\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7228 - val_loss: 0.6806\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7276 - val_loss: 0.4732\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0484 - val_loss: 0.6088\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9369 - val_loss: 0.5136\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.3472 - val_loss: 0.4496\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.9626 - val_loss: 0.4813\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7678 - val_loss: 0.4106\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7433 - val_loss: 0.4011\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.5237 - val_loss: 0.4208\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.6741 - val_loss: 0.5332\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8146 - val_loss: 0.5258\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7509 - val_loss: 0.3789\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.6586 - val_loss: 0.4317\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.5884 - val_loss: 0.4403\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.4405 - val_loss: 0.3628\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.7716 - val_loss: 0.4367\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.4230 - val_loss: 0.3619\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7431 - val_loss: 0.3583\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.5040 - val_loss: 0.3675\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.6428 - val_loss: 0.5702\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8737 - val_loss: 0.4511\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7659 - val_loss: 0.3573\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7922 - val_loss: 0.3735\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6480 - val_loss: 0.3320\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.4897 - val_loss: 0.3385\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.1772 - val_loss: 0.3903\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6702 - val_loss: 0.4059\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8267 - val_loss: 0.2965\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8225 - val_loss: 1.0909\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7688 - val_loss: 0.3030\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.5651 - val_loss: 0.3209\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8820 - val_loss: 0.4183\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.6937 - val_loss: 0.5745\n",
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.4713 - val_loss: 0.3876\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.5775 - val_loss: 0.6527\n",
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.5615 - val_loss: 0.3859\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7357 - val_loss: 0.3893\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.4653 - val_loss: 0.3046\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.4193 - val_loss: 0.2912\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.3151 - val_loss: 0.3020\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8096 - val_loss: 0.3205\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.5959 - val_loss: 0.3801\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.3315 - val_loss: 0.2957\n",
      "Epoch 148/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6777 - val_loss: 0.2972\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.3084 - val_loss: 0.2563\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.7294 - val_loss: 0.3584\n",
      "6/6 [==============================] - 1s 4ms/step\n",
      "Mean Squared Error: 0.358374295779636\n",
      "Mean Absolute Error: 0.41437981273188734\n",
      "R-squared: 0.996159340752003\n",
      "\n",
      "Fold 3:\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 8s 66ms/step - loss: 165.0249 - val_loss: 148.3871\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 133.8162 - val_loss: 96.8952\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 87.8755 - val_loss: 74.5402\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 77.6942 - val_loss: 66.7793\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 66.1508 - val_loss: 51.9686\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 48.3209 - val_loss: 35.5976\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 34.1565 - val_loss: 26.1572\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 27.8813 - val_loss: 22.2182\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 24.1271 - val_loss: 19.5730\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 21.3103 - val_loss: 17.2303\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 18.8528 - val_loss: 15.3365\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 16.9461 - val_loss: 13.6800\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 14.8767 - val_loss: 12.1539\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 13.7575 - val_loss: 10.9457\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 12.0976 - val_loss: 9.8525\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 11.2907 - val_loss: 8.7630\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 10.4115 - val_loss: 7.8991\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 8.6928 - val_loss: 7.1734\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 8.2849 - val_loss: 6.4488\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 8.3467 - val_loss: 5.8985\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 6.8416 - val_loss: 5.5127\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 7.0251 - val_loss: 4.9114\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 5.9496 - val_loss: 4.4517\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 5.6941 - val_loss: 4.2308\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 4.7617 - val_loss: 3.8456\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 4.1549 - val_loss: 3.5439\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 4.3134 - val_loss: 3.4118\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 4.8438 - val_loss: 3.1626\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 4.0215 - val_loss: 2.9159\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 4.6533 - val_loss: 2.8739\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 3.4515 - val_loss: 2.8005\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.5405 - val_loss: 2.5688\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.6624 - val_loss: 2.4264\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.6153 - val_loss: 2.3187\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.4671 - val_loss: 2.2121\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.9881 - val_loss: 2.1306\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.2680 - val_loss: 2.1329\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.1031 - val_loss: 1.9803\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.1081 - val_loss: 1.9375\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.6450 - val_loss: 1.8753\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.9274 - val_loss: 1.8109\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.4470 - val_loss: 1.8942\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.1939 - val_loss: 1.7383\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.1423 - val_loss: 1.6749\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.6898 - val_loss: 1.6917\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.4306 - val_loss: 1.5450\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.6239 - val_loss: 1.5336\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.7645 - val_loss: 1.4658\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.5746 - val_loss: 1.4574\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.5046 - val_loss: 1.4117\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.0507 - val_loss: 1.5355\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.3482 - val_loss: 1.4402\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.5214 - val_loss: 1.3259\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.5957 - val_loss: 1.3017\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9954 - val_loss: 1.2418\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.4821 - val_loss: 1.2810\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.4141 - val_loss: 1.1909\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.1475 - val_loss: 1.1881\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.2372 - val_loss: 1.3223\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.7130 - val_loss: 1.1240\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.5633 - val_loss: 1.2837\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.7378 - val_loss: 1.0791\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8934 - val_loss: 1.0914\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.4200 - val_loss: 1.0333\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.9552 - val_loss: 1.0026\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.6064 - val_loss: 1.0955\n",
      "Epoch 67/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9141 - val_loss: 1.2561\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.4731 - val_loss: 0.9810\n",
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.4159 - val_loss: 0.9231\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0447 - val_loss: 0.9821\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1354 - val_loss: 1.0668\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.3285 - val_loss: 0.9321\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7742 - val_loss: 0.9313\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 2.3240 - val_loss: 0.8967\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8925 - val_loss: 0.9572\n",
      "Epoch 76/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.8597 - val_loss: 0.8748\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0428 - val_loss: 0.9487\n",
      "Epoch 78/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 14ms/step - loss: 2.1321 - val_loss: 0.7868\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.0205 - val_loss: 0.7655\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.1499 - val_loss: 0.7763\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0250 - val_loss: 0.9376\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0177 - val_loss: 0.7680\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.3496 - val_loss: 0.8208\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.2555 - val_loss: 0.7581\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9030 - val_loss: 0.7533\n",
      "Epoch 86/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8663 - val_loss: 0.7850\n",
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9123 - val_loss: 0.6599\n",
      "Epoch 88/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9912 - val_loss: 0.6413\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8751 - val_loss: 0.6657\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.3071 - val_loss: 0.6579\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.0764 - val_loss: 0.6330\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.2385 - val_loss: 0.6252\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0310 - val_loss: 0.5865\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7880 - val_loss: 0.6069\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.9230 - val_loss: 0.6276\n",
      "Epoch 96/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.1042 - val_loss: 0.5324\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.7184 - val_loss: 0.5286\n",
      "Epoch 98/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.9834 - val_loss: 0.5937\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.5540 - val_loss: 0.6559\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8227 - val_loss: 0.5393\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7681 - val_loss: 0.5634\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7357 - val_loss: 0.6125\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.6747 - val_loss: 0.5280\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.9932 - val_loss: 0.4709\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0724 - val_loss: 0.4684\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7936 - val_loss: 0.4894\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8620 - val_loss: 0.5602\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8111 - val_loss: 0.4913\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.0698 - val_loss: 0.4448\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7331 - val_loss: 0.6367\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0751 - val_loss: 0.4089\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.6428 - val_loss: 0.3754\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7894 - val_loss: 0.3905\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8025 - val_loss: 0.3775\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8260 - val_loss: 0.4097\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 1.4957 - val_loss: 0.4361\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 1.8443 - val_loss: 0.6478\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.3848 - val_loss: 0.3846\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.5575 - val_loss: 0.3718\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6066 - val_loss: 0.3992\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8577 - val_loss: 0.4091\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.4784 - val_loss: 0.3996\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8583 - val_loss: 0.4137\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.8172 - val_loss: 0.3217\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.4273 - val_loss: 0.3180\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7276 - val_loss: 0.3413\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6952 - val_loss: 0.3604\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6162 - val_loss: 0.3056\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.4925 - val_loss: 0.3388\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6055 - val_loss: 0.3178\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.6537 - val_loss: 0.2893\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.7713 - val_loss: 0.3006\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6242 - val_loss: 0.3117\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6586 - val_loss: 0.5419\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8004 - val_loss: 0.6738\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.4176 - val_loss: 0.3217\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8384 - val_loss: 0.2957\n",
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8550 - val_loss: 0.5083\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6217 - val_loss: 0.3472\n",
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.5661 - val_loss: 0.5050\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.4387 - val_loss: 0.2597\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.5747 - val_loss: 0.2691\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.5813 - val_loss: 0.2733\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.3791 - val_loss: 0.2475\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5647 - val_loss: 0.3046\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.4455 - val_loss: 0.4263\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.9057 - val_loss: 0.3060\n",
      "Epoch 148/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.5453 - val_loss: 0.3041\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8998 - val_loss: 0.3763\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.4769 - val_loss: 0.1870\n",
      "6/6 [==============================] - 1s 4ms/step\n",
      "Mean Squared Error: 0.18698767321197834\n",
      "Mean Absolute Error: 0.26200188867973556\n",
      "R-squared: 0.9977529623008446\n",
      "\n",
      "Fold 4:\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 8s 75ms/step - loss: 171.9907 - val_loss: 112.6290\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 139.1400 - val_loss: 70.7316\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 90.6909 - val_loss: 60.5306\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 80.8632 - val_loss: 54.4290\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 68.0862 - val_loss: 39.4793\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 52.6816 - val_loss: 25.4810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 37.2428 - val_loss: 17.3144\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 30.0199 - val_loss: 14.4551\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 25.0498 - val_loss: 12.5991\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 23.2000 - val_loss: 11.1130\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 20.6865 - val_loss: 9.7391\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 17.8463 - val_loss: 8.5684\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 16.2442 - val_loss: 7.5325\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 14.2656 - val_loss: 6.6815\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 13.1463 - val_loss: 6.0058\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 11.5744 - val_loss: 5.2980\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 10.4106 - val_loss: 4.8408\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 9.5080 - val_loss: 4.3145\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 9.0014 - val_loss: 3.9575\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 8.0416 - val_loss: 3.5253\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 7.8483 - val_loss: 3.1258\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 6.6485 - val_loss: 2.8426\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 7.3068 - val_loss: 2.6108\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 6.5297 - val_loss: 2.5033\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 5.7500 - val_loss: 2.1460\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 5.0699 - val_loss: 1.9914\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 4.4620 - val_loss: 2.1314\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 4.7886 - val_loss: 1.8538\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 4.5281 - val_loss: 1.6664\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 4.0689 - val_loss: 1.5402\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.9150 - val_loss: 1.5076\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.8284 - val_loss: 1.5072\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.4845 - val_loss: 1.4599\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.4850 - val_loss: 1.3311\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.4284 - val_loss: 1.2517\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.8900 - val_loss: 1.4108\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.4892 - val_loss: 1.2459\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.3727 - val_loss: 1.1946\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.8171 - val_loss: 1.1358\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.0784 - val_loss: 1.0715\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.6381 - val_loss: 1.0842\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.1664 - val_loss: 1.0552\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.7672 - val_loss: 0.9874\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.9315 - val_loss: 1.0108\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.8577 - val_loss: 0.9735\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.7626 - val_loss: 0.9463\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.7511 - val_loss: 0.9027\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.7657 - val_loss: 0.8797\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.1193 - val_loss: 0.8780\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.5885 - val_loss: 0.8886\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 2.9822 - val_loss: 0.9104\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 3.1107 - val_loss: 0.8189\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.7517 - val_loss: 0.7866\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 2.8705 - val_loss: 0.8117\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.5728 - val_loss: 0.8181\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.3084 - val_loss: 0.7259\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 2.6683 - val_loss: 0.7610\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.3404 - val_loss: 0.7359\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0066 - val_loss: 0.7224\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.6283 - val_loss: 0.7249\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.6570 - val_loss: 0.6798\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.2518 - val_loss: 0.7118\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 2.6350 - val_loss: 0.7426\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.1979 - val_loss: 0.6230\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.2856 - val_loss: 0.6417\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.3815 - val_loss: 0.6208\n",
      "Epoch 67/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.3993 - val_loss: 0.6327\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.6118 - val_loss: 0.7256\n",
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.6147 - val_loss: 0.5646\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.3683 - val_loss: 0.5851\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.3525 - val_loss: 0.5704\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.3504 - val_loss: 0.5626\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1954 - val_loss: 0.5957\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.3388 - val_loss: 0.5333\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0427 - val_loss: 0.5294\n",
      "Epoch 76/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1153 - val_loss: 0.5288\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 8ms/step - loss: 2.1654 - val_loss: 0.4651\n",
      "Epoch 78/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.3225 - val_loss: 1.0606\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.1284 - val_loss: 0.5155\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8367 - val_loss: 0.5779\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.5490 - val_loss: 0.4594\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8443 - val_loss: 0.4597\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.0454 - val_loss: 0.4653\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.2197 - val_loss: 0.5050\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.9254 - val_loss: 0.7401\n",
      "Epoch 86/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0354 - val_loss: 0.4235\n",
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.9436 - val_loss: 0.4367\n",
      "Epoch 88/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0496 - val_loss: 0.4213\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.5334 - val_loss: 0.4510\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8949 - val_loss: 0.3995\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1675 - val_loss: 0.3689\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1756 - val_loss: 0.4400\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7829 - val_loss: 0.3665\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0247 - val_loss: 0.3308\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.2316 - val_loss: 0.4745\n",
      "Epoch 96/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.4341 - val_loss: 0.3748\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9698 - val_loss: 0.3683\n",
      "Epoch 98/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7049 - val_loss: 0.3095\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.4566 - val_loss: 0.4665\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.2044 - val_loss: 0.6600\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.9401 - val_loss: 0.3824\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9636 - val_loss: 0.4717\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.0235 - val_loss: 0.4205\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.0707 - val_loss: 0.3197\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7826 - val_loss: 0.3243\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0485 - val_loss: 0.3238\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0016 - val_loss: 0.4343\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8973 - val_loss: 0.2681\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7199 - val_loss: 0.4304\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0319 - val_loss: 0.3890\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7842 - val_loss: 0.3420\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.6279 - val_loss: 0.2707\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7538 - val_loss: 0.2889\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.5562 - val_loss: 0.2875\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8249 - val_loss: 0.2686\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.1301 - val_loss: 0.3233\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0114 - val_loss: 0.2839\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9818 - val_loss: 0.2845\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7372 - val_loss: 0.2535\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.9789 - val_loss: 0.2419\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8786 - val_loss: 0.2567\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.9635 - val_loss: 0.2685\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.2027 - val_loss: 0.3518\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.6937 - val_loss: 0.4239\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8234 - val_loss: 0.2405\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8755 - val_loss: 0.2488\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8831 - val_loss: 0.3799\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.9255 - val_loss: 0.4626\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.7179 - val_loss: 0.2119\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8647 - val_loss: 0.2414\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6044 - val_loss: 0.2323\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9601 - val_loss: 0.2127\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.6224 - val_loss: 0.2421\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7589 - val_loss: 0.2077\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.6051 - val_loss: 0.1506\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.9422 - val_loss: 0.2025\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6660 - val_loss: 0.1556\n",
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.7621 - val_loss: 0.2100\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.9397 - val_loss: 0.2187\n",
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0302 - val_loss: 0.3798\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7083 - val_loss: 0.1231\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6894 - val_loss: 0.1377\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8049 - val_loss: 0.1203\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9020 - val_loss: 0.2506\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6728 - val_loss: 0.1361\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6945 - val_loss: 0.1294\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.5712 - val_loss: 0.1850\n",
      "Epoch 148/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.6152 - val_loss: 0.1188\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.5658 - val_loss: 0.1399\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.6606 - val_loss: 0.1469\n",
      "6/6 [==============================] - 1s 3ms/step\n",
      "Mean Squared Error: 0.14691874664916046\n",
      "Mean Absolute Error: 0.2452756108659687\n",
      "R-squared: 0.9978054537638976\n",
      "\n",
      "Fold 5:\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 8s 69ms/step - loss: 158.1443 - val_loss: 185.0908\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 134.0685 - val_loss: 131.7274\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 87.8401 - val_loss: 96.3065\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 76.8549 - val_loss: 90.6549\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 69.5179 - val_loss: 80.7245\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 57.3173 - val_loss: 62.4764\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 40.5386 - val_loss: 47.2171\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 30.4880 - val_loss: 39.4983\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 26.1019 - val_loss: 34.8325\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 23.6635 - val_loss: 31.1858\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 19.7006 - val_loss: 28.1058\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 17.6084 - val_loss: 25.2025\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 16.1651 - val_loss: 22.7439\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 14.4068 - val_loss: 20.5362\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 13.4294 - val_loss: 18.5246\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 11.5944 - val_loss: 16.8141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 10.7306 - val_loss: 15.3173\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 10.2431 - val_loss: 13.8854\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 8.1146 - val_loss: 12.6958\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 8.0103 - val_loss: 11.5808\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 7.2442 - val_loss: 10.6876\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 6.6515 - val_loss: 9.8253\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 6.4184 - val_loss: 9.0143\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 5.8666 - val_loss: 8.3152\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 5.4256 - val_loss: 7.6806\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 4.8721 - val_loss: 7.0984\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 4.8083 - val_loss: 6.6034\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 4.6859 - val_loss: 6.1412\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 4.1468 - val_loss: 5.8067\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 4.5778 - val_loss: 5.4675\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.8323 - val_loss: 5.1560\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.6632 - val_loss: 4.7632\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.2823 - val_loss: 4.6274\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.4758 - val_loss: 4.2851\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 3.6502 - val_loss: 4.1084\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.6329 - val_loss: 3.9202\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.2115 - val_loss: 3.7083\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.4064 - val_loss: 3.5239\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 3.0006 - val_loss: 3.4431\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.8757 - val_loss: 3.2947\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.7126 - val_loss: 3.2515\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.6557 - val_loss: 3.0831\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.9059 - val_loss: 3.1030\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.8612 - val_loss: 2.8745\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.0616 - val_loss: 2.8443\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 2.5821 - val_loss: 2.7221\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.7972 - val_loss: 2.6210\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.5002 - val_loss: 2.7344\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.6205 - val_loss: 2.5356\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.9603 - val_loss: 2.6134\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.6426 - val_loss: 2.6400\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.7980 - val_loss: 2.4774\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.3719 - val_loss: 2.6438\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.2467 - val_loss: 2.3274\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.2779 - val_loss: 2.3496\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.1940 - val_loss: 2.3265\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.4500 - val_loss: 2.1542\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.4006 - val_loss: 2.1474\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.2865 - val_loss: 2.1592\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.9369 - val_loss: 2.0265\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8514 - val_loss: 2.0108\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.1929 - val_loss: 1.9803\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.4479 - val_loss: 1.9083\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9961 - val_loss: 1.9170\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.3940 - val_loss: 2.0210\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1360 - val_loss: 1.8793\n",
      "Epoch 67/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1613 - val_loss: 1.8409\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.4367 - val_loss: 1.8968\n",
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.2532 - val_loss: 1.9184\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9882 - val_loss: 1.7691\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.2494 - val_loss: 1.8084\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0641 - val_loss: 1.9668\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.2219 - val_loss: 1.6874\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.1563 - val_loss: 1.8273\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8367 - val_loss: 1.8093\n",
      "Epoch 76/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0069 - val_loss: 1.6008\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.4772 - val_loss: 1.6751\n",
      "Epoch 78/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8410 - val_loss: 1.8622\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.9835 - val_loss: 1.5673\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9698 - val_loss: 1.4890\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0851 - val_loss: 1.4191\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7381 - val_loss: 1.4814\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.6431 - val_loss: 1.4022\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.0810 - val_loss: 1.4459\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9578 - val_loss: 1.3663\n",
      "Epoch 86/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.9695 - val_loss: 1.3398\n",
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.8887 - val_loss: 1.3667\n",
      "Epoch 88/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7199 - val_loss: 1.2997\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.1378 - val_loss: 1.2817\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.5095 - val_loss: 1.2581\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7141 - val_loss: 1.2464\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8404 - val_loss: 1.3185\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.7841 - val_loss: 1.4473\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.9189 - val_loss: 1.2619\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.6682 - val_loss: 1.3266\n",
      "Epoch 96/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7917 - val_loss: 1.2826\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7951 - val_loss: 1.1618\n",
      "Epoch 98/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 16ms/step - loss: 1.5599 - val_loss: 1.1553\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.5839 - val_loss: 1.2194\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.9704 - val_loss: 1.1276\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.5907 - val_loss: 1.1094\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9597 - val_loss: 1.4205\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8377 - val_loss: 1.1869\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8272 - val_loss: 1.0791\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9713 - val_loss: 1.1255\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8307 - val_loss: 1.0517\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.4451 - val_loss: 1.0410\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7467 - val_loss: 1.0058\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.5405 - val_loss: 0.9900\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.6271 - val_loss: 1.0781\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6794 - val_loss: 1.0490\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 1.4079 - val_loss: 1.0622\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 2.2345 - val_loss: 1.0374\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.5821 - val_loss: 0.9537\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.4980 - val_loss: 0.9839\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7561 - val_loss: 0.9944\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.4407 - val_loss: 1.0843\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8587 - val_loss: 0.9624\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.9231 - val_loss: 0.8816\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.5742 - val_loss: 0.9384\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.4464 - val_loss: 1.0121\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5755 - val_loss: 0.8723\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7079 - val_loss: 0.8944\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7567 - val_loss: 0.9161\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.6644 - val_loss: 0.9025\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4357 - val_loss: 0.8508\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.3926 - val_loss: 0.8725\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.3899 - val_loss: 1.0204\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7578 - val_loss: 0.8461\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.4235 - val_loss: 0.7803\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.7002 - val_loss: 0.7908\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.3459 - val_loss: 0.8044\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.4991 - val_loss: 0.8438\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.4682 - val_loss: 0.8316\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.8210 - val_loss: 0.7661\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.5149 - val_loss: 0.7313\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.5277 - val_loss: 0.7585\n",
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.4324 - val_loss: 0.7150\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.3671 - val_loss: 0.7178\n",
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.5690 - val_loss: 0.8519\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.4445 - val_loss: 0.7753\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.2329 - val_loss: 0.8641\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.6867 - val_loss: 0.7431\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.3175 - val_loss: 1.0408\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 1.5545 - val_loss: 0.6797\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7361 - val_loss: 0.6919\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7538 - val_loss: 0.6879\n",
      "Epoch 148/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.2924 - val_loss: 0.7289\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.5323 - val_loss: 0.7362\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.4645 - val_loss: 0.7013\n",
      "6/6 [==============================] - 1s 5ms/step\n",
      "Mean Squared Error: 0.7012581429890246\n",
      "Mean Absolute Error: 0.41079468149127385\n",
      "R-squared: 0.9933240569276705\n",
      "\n",
      "Average scores for ticker AMWL:\n",
      "Mean Squared Error: 0.3174559998295119\n",
      "Mean Absolute Error: 0.3274620237773506\n",
      "R-squared: 0.9965832040359771\n",
      "\n",
      "Cross-validation for ticker: GEO\n",
      "Fold 1:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 8s 57ms/step - loss: 79.4204 - val_loss: 57.1796\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 32.1859 - val_loss: 5.1830\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.4483 - val_loss: 5.3034\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.7401 - val_loss: 4.3889\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.3427 - val_loss: 4.1039\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.9453 - val_loss: 3.6059\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.5495 - val_loss: 3.0467\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.9213 - val_loss: 2.2888\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.1685 - val_loss: 1.5504\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 2.6830 - val_loss: 1.0087\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 2.2037 - val_loss: 0.7695\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.6332 - val_loss: 0.6833\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.7707 - val_loss: 0.6261\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.7218 - val_loss: 0.5708\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.5631 - val_loss: 0.5211\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.5467 - val_loss: 0.4878\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.6036 - val_loss: 0.4512\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.4196 - val_loss: 0.4063\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.4159 - val_loss: 0.3766\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.2954 - val_loss: 0.3459\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.1512 - val_loss: 0.3223\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.2599 - val_loss: 0.2964\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.2357 - val_loss: 0.3026\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.2197 - val_loss: 0.2625\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.1723 - val_loss: 0.2441\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.1508 - val_loss: 0.2236\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.0367 - val_loss: 0.2072\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9345 - val_loss: 0.2072\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.1874 - val_loss: 0.2171\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0052 - val_loss: 0.2093\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.9876 - val_loss: 0.1535\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.9515 - val_loss: 0.1771\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9796 - val_loss: 0.1529\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8382 - val_loss: 0.1633\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8851 - val_loss: 0.1031\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9450 - val_loss: 0.0983\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8064 - val_loss: 0.1274\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8705 - val_loss: 0.0917\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.7393 - val_loss: 0.0795\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7818 - val_loss: 0.0730\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8053 - val_loss: 0.0693\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7536 - val_loss: 0.0998\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7933 - val_loss: 0.1329\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7438 - val_loss: 0.0762\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7447 - val_loss: 0.0720\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8708 - val_loss: 0.0613\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8296 - val_loss: 0.0553\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8308 - val_loss: 0.0759\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7184 - val_loss: 0.0469\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7963 - val_loss: 0.0894\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7718 - val_loss: 0.0640\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7500 - val_loss: 0.0412\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7616 - val_loss: 0.0514\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6585 - val_loss: 0.0389\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7500 - val_loss: 0.0792\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6535 - val_loss: 0.0405\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.7010 - val_loss: 0.0538\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6631 - val_loss: 0.0311\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6790 - val_loss: 0.0514\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7022 - val_loss: 0.0292\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6831 - val_loss: 0.0294\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7289 - val_loss: 0.0482\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6911 - val_loss: 0.0538\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7763 - val_loss: 0.0344\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6522 - val_loss: 0.0265\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6724 - val_loss: 0.0425\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7080 - val_loss: 0.0285\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6142 - val_loss: 0.0292\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6022 - val_loss: 0.0410\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6894 - val_loss: 0.0730\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6616 - val_loss: 0.0513\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6583 - val_loss: 0.0318\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6869 - val_loss: 0.1386\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6831 - val_loss: 0.0233\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6323 - val_loss: 0.1590\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6640 - val_loss: 0.0297\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6451 - val_loss: 0.0257\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7204 - val_loss: 0.0279\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6566 - val_loss: 0.0687\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6518 - val_loss: 0.0293\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6218 - val_loss: 0.0266\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6161 - val_loss: 0.0278\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5894 - val_loss: 0.0219\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5466 - val_loss: 0.0472\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6591 - val_loss: 0.0263\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6727 - val_loss: 0.0307\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6109 - val_loss: 0.0197\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6003 - val_loss: 0.0295\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5764 - val_loss: 0.0248\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5638 - val_loss: 0.0850\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6642 - val_loss: 0.0287\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6656 - val_loss: 0.0598\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5854 - val_loss: 0.0198\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5558 - val_loss: 0.0780\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6341 - val_loss: 0.0191\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6062 - val_loss: 0.0521\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5973 - val_loss: 0.0271\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5447 - val_loss: 0.0252\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5871 - val_loss: 0.0196\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5624 - val_loss: 0.0259\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5726 - val_loss: 0.0391\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.6411 - val_loss: 0.0252\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5879 - val_loss: 0.0223\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5507 - val_loss: 0.0223\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5915 - val_loss: 0.0461\n",
      "Epoch 106/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 11ms/step - loss: 0.6129 - val_loss: 0.0188\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5041 - val_loss: 0.0227\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5287 - val_loss: 0.0206\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5730 - val_loss: 0.0194\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5333 - val_loss: 0.0163\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6009 - val_loss: 0.0170\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5191 - val_loss: 0.0162\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5808 - val_loss: 0.0336\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5015 - val_loss: 0.0189\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5565 - val_loss: 0.0208\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5385 - val_loss: 0.0359\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6210 - val_loss: 0.0548\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5624 - val_loss: 0.0180\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.5774 - val_loss: 0.0301\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5773 - val_loss: 0.0177\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5714 - val_loss: 0.0373\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5698 - val_loss: 0.0219\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5725 - val_loss: 0.0606\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4933 - val_loss: 0.0223\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6188 - val_loss: 0.0208\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4558 - val_loss: 0.0222\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5219 - val_loss: 0.0195\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5510 - val_loss: 0.0312\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5468 - val_loss: 0.0267\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5058 - val_loss: 0.0157\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5355 - val_loss: 0.0191\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5631 - val_loss: 0.0742\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5395 - val_loss: 0.0287\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5453 - val_loss: 0.0265\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5626 - val_loss: 0.0198\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5302 - val_loss: 0.0219\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5571 - val_loss: 0.0207\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5267 - val_loss: 0.0181\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5327 - val_loss: 0.0218\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5133 - val_loss: 0.0350\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5382 - val_loss: 0.0261\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5083 - val_loss: 0.0145\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5128 - val_loss: 0.0686\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5164 - val_loss: 0.0225\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5066 - val_loss: 0.0152\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5114 - val_loss: 0.0488\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5874 - val_loss: 0.0297\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4798 - val_loss: 0.0208\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5062 - val_loss: 0.0214\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5119 - val_loss: 0.0212\n",
      "7/7 [==============================] - 1s 3ms/step\n",
      "Mean Squared Error: 0.021153456778465286\n",
      "Mean Absolute Error: 0.09541339779374615\n",
      "R-squared: 0.9963622073949006\n",
      "\n",
      "Fold 2:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 7s 56ms/step - loss: 77.9232 - val_loss: 65.7219\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 34.7049 - val_loss: 8.7356\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.8604 - val_loss: 5.8639\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.6565 - val_loss: 5.4548\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.3940 - val_loss: 5.1870\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.2426 - val_loss: 4.7693\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 4.4370 - val_loss: 4.1566\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.9822 - val_loss: 3.3309\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.1078 - val_loss: 2.2964\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 2.3595 - val_loss: 1.5341\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 2.0036 - val_loss: 1.2815\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.7006 - val_loss: 1.1815\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.7444 - val_loss: 1.1348\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.5686 - val_loss: 0.9984\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.5523 - val_loss: 0.9350\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.5147 - val_loss: 0.8865\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.5845 - val_loss: 0.8991\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.5045 - val_loss: 0.7959\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3578 - val_loss: 0.7331\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 1.2560 - val_loss: 0.6755\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.3886 - val_loss: 0.6738\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.2715 - val_loss: 0.6142\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.2037 - val_loss: 0.5733\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.1582 - val_loss: 0.5461\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.2048 - val_loss: 0.4903\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.1159 - val_loss: 0.4575\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0237 - val_loss: 0.4606\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.2079 - val_loss: 0.3786\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0520 - val_loss: 0.3840\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9665 - val_loss: 0.3337\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9154 - val_loss: 0.2994\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8290 - val_loss: 0.2808\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.9549 - val_loss: 0.2513\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.9241 - val_loss: 0.2407\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0257 - val_loss: 0.2316\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8557 - val_loss: 0.2178\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8597 - val_loss: 0.2204\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8344 - val_loss: 0.1912\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8604 - val_loss: 0.1846\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.9047 - val_loss: 0.1611\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7788 - val_loss: 0.1542\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8031 - val_loss: 0.1329\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8149 - val_loss: 0.2015\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8034 - val_loss: 0.1232\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7784 - val_loss: 0.1189\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6847 - val_loss: 0.1053\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6681 - val_loss: 0.1118\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6721 - val_loss: 0.1022\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8213 - val_loss: 0.0960\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7573 - val_loss: 0.0877\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7851 - val_loss: 0.0732\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6393 - val_loss: 0.0786\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7037 - val_loss: 0.0708\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6586 - val_loss: 0.0675\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6415 - val_loss: 0.0697\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7224 - val_loss: 0.0754\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6325 - val_loss: 0.0687\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6389 - val_loss: 0.0786\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6578 - val_loss: 0.0640\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6350 - val_loss: 0.0835\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7010 - val_loss: 0.0909\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6254 - val_loss: 0.0639\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6109 - val_loss: 0.0591\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6041 - val_loss: 0.1150\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6654 - val_loss: 0.0628\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5717 - val_loss: 0.0674\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5780 - val_loss: 0.0484\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6031 - val_loss: 0.0901\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6516 - val_loss: 0.0518\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5688 - val_loss: 0.0516\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5662 - val_loss: 0.0868\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5992 - val_loss: 0.0613\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5519 - val_loss: 0.0531\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5926 - val_loss: 0.0489\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5435 - val_loss: 0.0455\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5954 - val_loss: 0.1124\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6588 - val_loss: 0.0641\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6097 - val_loss: 0.0452\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5797 - val_loss: 0.0519\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5625 - val_loss: 0.0377\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6001 - val_loss: 0.0439\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5662 - val_loss: 0.0372\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6001 - val_loss: 0.0413\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5919 - val_loss: 0.0792\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5557 - val_loss: 0.0378\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5402 - val_loss: 0.0469\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5106 - val_loss: 0.0612\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5918 - val_loss: 0.0358\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5702 - val_loss: 0.0596\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5881 - val_loss: 0.0632\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5447 - val_loss: 0.0497\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5806 - val_loss: 0.0557\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5567 - val_loss: 0.0496\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5658 - val_loss: 0.0517\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5310 - val_loss: 0.0387\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5326 - val_loss: 0.0419\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6023 - val_loss: 0.0420\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5609 - val_loss: 0.0474\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5684 - val_loss: 0.0751\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5542 - val_loss: 0.0951\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5878 - val_loss: 0.0487\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5601 - val_loss: 0.0391\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5451 - val_loss: 0.0383\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5391 - val_loss: 0.0302\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5221 - val_loss: 0.0310\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5691 - val_loss: 0.0462\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5145 - val_loss: 0.0424\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5066 - val_loss: 0.0367\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5496 - val_loss: 0.0393\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4996 - val_loss: 0.0757\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5406 - val_loss: 0.0840\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5398 - val_loss: 0.0484\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5458 - val_loss: 0.0357\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5402 - val_loss: 0.0358\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5045 - val_loss: 0.0585\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 10ms/step - loss: 0.5535 - val_loss: 0.0705\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5312 - val_loss: 0.0835\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5036 - val_loss: 0.0855\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5629 - val_loss: 0.0863\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5137 - val_loss: 0.0523\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4814 - val_loss: 0.0419\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5312 - val_loss: 0.0322\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4897 - val_loss: 0.0440\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5225 - val_loss: 0.0537\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.4926 - val_loss: 0.0384\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5313 - val_loss: 0.0435\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5081 - val_loss: 0.0468\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5402 - val_loss: 0.0411\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4997 - val_loss: 0.0618\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5569 - val_loss: 0.0378\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5042 - val_loss: 0.0439\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4864 - val_loss: 0.0602\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5118 - val_loss: 0.0476\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5882 - val_loss: 0.0625\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4947 - val_loss: 0.0435\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4814 - val_loss: 0.0442\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5264 - val_loss: 0.0439\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4720 - val_loss: 0.0365\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5156 - val_loss: 0.0327\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4905 - val_loss: 0.0360\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4858 - val_loss: 0.0628\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5615 - val_loss: 0.0358\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5004 - val_loss: 0.0413\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4697 - val_loss: 0.0442\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5025 - val_loss: 0.0504\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4996 - val_loss: 0.0638\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5569 - val_loss: 0.0380\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.4681 - val_loss: 0.0582\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4772 - val_loss: 0.0666\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4720 - val_loss: 0.0447\n",
      "7/7 [==============================] - 1s 3ms/step\n",
      "Mean Squared Error: 0.044690435453156305\n",
      "Mean Absolute Error: 0.133636571874666\n",
      "R-squared: 0.9936166226989628\n",
      "\n",
      "Fold 3:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 8s 57ms/step - loss: 80.2087 - val_loss: 66.6716\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 36.4437 - val_loss: 7.1073\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 6.2021 - val_loss: 5.9052\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 5.2491 - val_loss: 5.1254\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.9979 - val_loss: 4.7326\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.5025 - val_loss: 4.0729\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 3.8975 - val_loss: 3.2209\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.4871 - val_loss: 2.1601\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 2.5388 - val_loss: 1.2991\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 2.0127 - val_loss: 0.9297\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.9209 - val_loss: 0.8362\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.7647 - val_loss: 0.7827\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.7358 - val_loss: 0.7439\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.5945 - val_loss: 0.6604\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.5574 - val_loss: 0.6157\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.4880 - val_loss: 0.5685\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3584 - val_loss: 0.5190\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.2726 - val_loss: 0.4807\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.3101 - val_loss: 0.4449\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.1672 - val_loss: 0.4163\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.2447 - val_loss: 0.3770\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.2615 - val_loss: 0.3580\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.1807 - val_loss: 0.3529\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.1366 - val_loss: 0.2977\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.0770 - val_loss: 0.2785\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.9985 - val_loss: 0.2649\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.9982 - val_loss: 0.2729\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.9845 - val_loss: 0.2230\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9829 - val_loss: 0.1960\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0051 - val_loss: 0.1835\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.0709 - val_loss: 0.1642\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0271 - val_loss: 0.1569\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8730 - val_loss: 0.1345\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.9638 - val_loss: 0.1461\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8544 - val_loss: 0.1857\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9083 - val_loss: 0.1099\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.8271 - val_loss: 0.0973\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7980 - val_loss: 0.1148\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8666 - val_loss: 0.0906\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8185 - val_loss: 0.0860\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7952 - val_loss: 0.0804\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7786 - val_loss: 0.0829\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8426 - val_loss: 0.0939\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7610 - val_loss: 0.0627\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6942 - val_loss: 0.0807\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8277 - val_loss: 0.0571\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7265 - val_loss: 0.0495\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7025 - val_loss: 0.0558\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7044 - val_loss: 0.0517\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6873 - val_loss: 0.0470\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6609 - val_loss: 0.0591\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6781 - val_loss: 0.0595\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6673 - val_loss: 0.0399\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7662 - val_loss: 0.0492\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8093 - val_loss: 0.0383\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6927 - val_loss: 0.0532\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6738 - val_loss: 0.0345\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5750 - val_loss: 0.0346\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.6777 - val_loss: 0.0486\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5872 - val_loss: 0.0629\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.6288 - val_loss: 0.0297\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6611 - val_loss: 0.0295\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6099 - val_loss: 0.0279\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.5816 - val_loss: 0.0272\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.6463 - val_loss: 0.0343\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6135 - val_loss: 0.0411\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6387 - val_loss: 0.0453\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6445 - val_loss: 0.0646\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6492 - val_loss: 0.0342\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6057 - val_loss: 0.0230\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5705 - val_loss: 0.0281\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7158 - val_loss: 0.1273\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6850 - val_loss: 0.0348\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6863 - val_loss: 0.0297\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5182 - val_loss: 0.0332\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6024 - val_loss: 0.0291\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5214 - val_loss: 0.0342\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5962 - val_loss: 0.0289\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6072 - val_loss: 0.0284\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5326 - val_loss: 0.0357\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5838 - val_loss: 0.0192\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6074 - val_loss: 0.0237\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5742 - val_loss: 0.0193\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5868 - val_loss: 0.0168\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5247 - val_loss: 0.0261\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.6020 - val_loss: 0.0361\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5584 - val_loss: 0.0297\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.5888 - val_loss: 0.0203\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5370 - val_loss: 0.0420\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5940 - val_loss: 0.0161\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5428 - val_loss: 0.0234\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5690 - val_loss: 0.0267\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5836 - val_loss: 0.0374\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5423 - val_loss: 0.0211\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5844 - val_loss: 0.0214\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5726 - val_loss: 0.0295\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5561 - val_loss: 0.0282\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6457 - val_loss: 0.0173\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5807 - val_loss: 0.0172\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6542 - val_loss: 0.0133\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.5527 - val_loss: 0.0211\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5828 - val_loss: 0.0573\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.6284 - val_loss: 0.0156\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.6317 - val_loss: 0.0360\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.5851 - val_loss: 0.0255\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5705 - val_loss: 0.0258\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5282 - val_loss: 0.0225\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5132 - val_loss: 0.0163\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4983 - val_loss: 0.0180\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5837 - val_loss: 0.0193\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5401 - val_loss: 0.0536\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5957 - val_loss: 0.0600\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.5341 - val_loss: 0.0130\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5770 - val_loss: 0.0146\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5230 - val_loss: 0.0200\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4887 - val_loss: 0.0208\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5335 - val_loss: 0.0162\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5928 - val_loss: 0.0406\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5205 - val_loss: 0.0150\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4985 - val_loss: 0.0139\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5289 - val_loss: 0.0116\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5553 - val_loss: 0.0136\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5434 - val_loss: 0.0120\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5070 - val_loss: 0.0212\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5470 - val_loss: 0.0108\n",
      "Epoch 126/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5239 - val_loss: 0.0189\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5557 - val_loss: 0.0512\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4450 - val_loss: 0.0173\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5511 - val_loss: 0.0435\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5719 - val_loss: 0.0220\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5579 - val_loss: 0.0255\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5186 - val_loss: 0.0243\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5260 - val_loss: 0.0131\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5417 - val_loss: 0.0265\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5692 - val_loss: 0.0195\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5290 - val_loss: 0.0122\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4871 - val_loss: 0.0214\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5510 - val_loss: 0.0194\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5118 - val_loss: 0.0181\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5406 - val_loss: 0.0338\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5257 - val_loss: 0.0234\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4762 - val_loss: 0.0329\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5474 - val_loss: 0.0134\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5662 - val_loss: 0.0156\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4707 - val_loss: 0.0150\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5136 - val_loss: 0.0155\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4900 - val_loss: 0.0216\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5765 - val_loss: 0.0207\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5145 - val_loss: 0.0238\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5349 - val_loss: 0.0123\n",
      "7/7 [==============================] - 1s 3ms/step\n",
      "Mean Squared Error: 0.012258601624209445\n",
      "Mean Absolute Error: 0.07520400944040784\n",
      "R-squared: 0.9982145917773845\n",
      "\n",
      "Fold 4:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 7s 59ms/step - loss: 81.8379 - val_loss: 67.8921\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 42.9343 - val_loss: 9.0809\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 6.7804 - val_loss: 4.2858\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 5.9534 - val_loss: 3.7372\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.4228 - val_loss: 3.4809\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.2281 - val_loss: 3.1350\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.7306 - val_loss: 2.4800\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.5817 - val_loss: 1.6315\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 2.8529 - val_loss: 1.0999\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 2.1104 - val_loss: 0.8336\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 2.0253 - val_loss: 0.7116\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.7505 - val_loss: 0.6551\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.6624 - val_loss: 0.5991\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.7338 - val_loss: 0.5753\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.7242 - val_loss: 0.5215\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.6291 - val_loss: 0.4654\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.5250 - val_loss: 0.4214\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.5413 - val_loss: 0.3978\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.2949 - val_loss: 0.3702\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.3550 - val_loss: 0.3362\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.3366 - val_loss: 0.3085\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.1570 - val_loss: 0.3446\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.2651 - val_loss: 0.2784\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.1679 - val_loss: 0.2561\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.0922 - val_loss: 0.2491\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0561 - val_loss: 0.2211\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.1594 - val_loss: 0.2102\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.1088 - val_loss: 0.2058\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0292 - val_loss: 0.1759\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9731 - val_loss: 0.2049\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0389 - val_loss: 0.1845\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.9987 - val_loss: 0.1417\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 1.0736 - val_loss: 0.1428\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.8848 - val_loss: 0.1789\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.8497 - val_loss: 0.1156\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8250 - val_loss: 0.1041\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.9207 - val_loss: 0.1536\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8927 - val_loss: 0.1168\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.8983 - val_loss: 0.1236\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.7806 - val_loss: 0.0883\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8491 - val_loss: 0.0740\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7545 - val_loss: 0.0833\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7431 - val_loss: 0.0912\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8230 - val_loss: 0.0776\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6948 - val_loss: 0.0752\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7837 - val_loss: 0.0578\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7275 - val_loss: 0.0561\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7099 - val_loss: 0.1322\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.7940 - val_loss: 0.0687\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7269 - val_loss: 0.0505\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6918 - val_loss: 0.0574\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.7702 - val_loss: 0.0505\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.7335 - val_loss: 0.0440\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6798 - val_loss: 0.0626\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6839 - val_loss: 0.0757\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.7194 - val_loss: 0.0383\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7303 - val_loss: 0.0368\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7631 - val_loss: 0.0403\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6572 - val_loss: 0.0325\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7145 - val_loss: 0.0324\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6834 - val_loss: 0.0566\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6702 - val_loss: 0.0292\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5861 - val_loss: 0.0495\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6019 - val_loss: 0.0369\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6032 - val_loss: 0.0297\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6162 - val_loss: 0.0321\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6819 - val_loss: 0.0264\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7127 - val_loss: 0.0350\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6585 - val_loss: 0.0249\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5937 - val_loss: 0.0342\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6190 - val_loss: 0.0302\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6461 - val_loss: 0.0758\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6057 - val_loss: 0.0358\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6210 - val_loss: 0.0380\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5440 - val_loss: 0.0232\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5683 - val_loss: 0.0294\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6333 - val_loss: 0.0236\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5810 - val_loss: 0.0312\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5898 - val_loss: 0.0205\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6043 - val_loss: 0.0292\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5875 - val_loss: 0.0358\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7045 - val_loss: 0.0203\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6179 - val_loss: 0.0830\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6119 - val_loss: 0.0252\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6142 - val_loss: 0.0304\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5542 - val_loss: 0.0212\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5788 - val_loss: 0.0241\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5506 - val_loss: 0.0194\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5272 - val_loss: 0.0256\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4827 - val_loss: 0.0282\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5335 - val_loss: 0.0269\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5307 - val_loss: 0.0211\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5657 - val_loss: 0.0593\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6042 - val_loss: 0.0189\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5734 - val_loss: 0.0217\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5446 - val_loss: 0.0149\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5785 - val_loss: 0.0168\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5702 - val_loss: 0.0373\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5279 - val_loss: 0.0352\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5473 - val_loss: 0.0677\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5124 - val_loss: 0.0170\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4954 - val_loss: 0.0154\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5494 - val_loss: 0.0215\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5155 - val_loss: 0.0889\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5554 - val_loss: 0.0265\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5014 - val_loss: 0.0149\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5343 - val_loss: 0.0313\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5138 - val_loss: 0.0224\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5290 - val_loss: 0.0206\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5524 - val_loss: 0.0148\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5739 - val_loss: 0.0175\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5226 - val_loss: 0.0259\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5730 - val_loss: 0.0316\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5957 - val_loss: 0.0169\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5442 - val_loss: 0.0160\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5779 - val_loss: 0.0190\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5763 - val_loss: 0.0752\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5747 - val_loss: 0.0157\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6113 - val_loss: 0.0264\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5428 - val_loss: 0.0189\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5143 - val_loss: 0.0659\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5402 - val_loss: 0.0478\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4803 - val_loss: 0.0143\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5241 - val_loss: 0.0178\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5123 - val_loss: 0.0337\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5402 - val_loss: 0.0142\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5131 - val_loss: 0.0179\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5474 - val_loss: 0.0143\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5387 - val_loss: 0.0161\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5619 - val_loss: 0.0136\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5408 - val_loss: 0.0154\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5979 - val_loss: 0.0220\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5237 - val_loss: 0.0519\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5741 - val_loss: 0.0168\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5221 - val_loss: 0.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5261 - val_loss: 0.0257\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5547 - val_loss: 0.0245\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4842 - val_loss: 0.0201\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4537 - val_loss: 0.0448\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5572 - val_loss: 0.0955\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5888 - val_loss: 0.0158\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4992 - val_loss: 0.0298\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5925 - val_loss: 0.0164\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4910 - val_loss: 0.0144\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5949 - val_loss: 0.0150\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4597 - val_loss: 0.0256\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5881 - val_loss: 0.0893\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5192 - val_loss: 0.0202\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4677 - val_loss: 0.0444\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5020 - val_loss: 0.0123\n",
      "7/7 [==============================] - 1s 3ms/step\n",
      "Mean Squared Error: 0.012304646493744055\n",
      "Mean Absolute Error: 0.07120750673967809\n",
      "R-squared: 0.9974198198796705\n",
      "\n",
      "Fold 5:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 8s 53ms/step - loss: 77.5280 - val_loss: 64.9116\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 31.5005 - val_loss: 6.7229\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 6.1426 - val_loss: 5.6563\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 5.2651 - val_loss: 5.2577\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.8730 - val_loss: 4.8139\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.5168 - val_loss: 4.2411\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.1527 - val_loss: 3.4756\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.2791 - val_loss: 2.5103\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 2.6468 - val_loss: 1.6300\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 2.0413 - val_loss: 1.1437\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 1.7829 - val_loss: 1.0087\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.7119 - val_loss: 0.9380\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.7049 - val_loss: 0.8673\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.6418 - val_loss: 0.8093\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.5873 - val_loss: 0.7572\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.4697 - val_loss: 0.6925\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3754 - val_loss: 0.6489\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.3796 - val_loss: 0.6254\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.1925 - val_loss: 0.5718\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.2509 - val_loss: 0.5330\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.3538 - val_loss: 0.4949\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.0970 - val_loss: 0.5289\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.1916 - val_loss: 0.4541\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.1550 - val_loss: 0.4230\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.1296 - val_loss: 0.4278\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.1736 - val_loss: 0.3671\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.0411 - val_loss: 0.3533\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0432 - val_loss: 0.3250\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.0883 - val_loss: 0.3084\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.0984 - val_loss: 0.2715\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.9077 - val_loss: 0.2689\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8505 - val_loss: 0.2558\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9207 - val_loss: 0.2454\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.0259 - val_loss: 0.2176\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8842 - val_loss: 0.2190\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8578 - val_loss: 0.1896\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.8361 - val_loss: 0.1704\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.9196 - val_loss: 0.1875\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8223 - val_loss: 0.1567\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.8340 - val_loss: 0.1707\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8240 - val_loss: 0.1350\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7597 - val_loss: 0.1350\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8257 - val_loss: 0.1829\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7187 - val_loss: 0.1558\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7490 - val_loss: 0.1129\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7879 - val_loss: 0.1008\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7158 - val_loss: 0.1111\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6764 - val_loss: 0.0915\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7631 - val_loss: 0.1179\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7604 - val_loss: 0.0825\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6920 - val_loss: 0.0859\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.7015 - val_loss: 0.0745\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6941 - val_loss: 0.0755\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6355 - val_loss: 0.0893\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6539 - val_loss: 0.0738\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6336 - val_loss: 0.0649\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6599 - val_loss: 0.1396\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.7417 - val_loss: 0.0808\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6717 - val_loss: 0.0688\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6284 - val_loss: 0.0730\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.6730 - val_loss: 0.0584\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6917 - val_loss: 0.0530\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6013 - val_loss: 0.0641\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6231 - val_loss: 0.0612\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6010 - val_loss: 0.0512\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6584 - val_loss: 0.0512\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6340 - val_loss: 0.0422\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6351 - val_loss: 0.0435\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.6527 - val_loss: 0.0412\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6402 - val_loss: 0.0425\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6445 - val_loss: 0.0377\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6814 - val_loss: 0.0882\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.6689 - val_loss: 0.0458\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5571 - val_loss: 0.0408\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6063 - val_loss: 0.0380\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6843 - val_loss: 0.0816\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5804 - val_loss: 0.0396\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5840 - val_loss: 0.0356\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5609 - val_loss: 0.0564\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5909 - val_loss: 0.0613\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5577 - val_loss: 0.0371\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5735 - val_loss: 0.0768\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5673 - val_loss: 0.0464\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5703 - val_loss: 0.0365\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6326 - val_loss: 0.0355\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5600 - val_loss: 0.0662\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5210 - val_loss: 0.0450\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5747 - val_loss: 0.0478\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5733 - val_loss: 0.0638\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5235 - val_loss: 0.0553\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5607 - val_loss: 0.0358\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6238 - val_loss: 0.0386\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6081 - val_loss: 0.0418\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5688 - val_loss: 0.0638\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5963 - val_loss: 0.1045\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5791 - val_loss: 0.0297\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5493 - val_loss: 0.0464\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5441 - val_loss: 0.0407\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5654 - val_loss: 0.0371\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5721 - val_loss: 0.0384\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5785 - val_loss: 0.0304\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6391 - val_loss: 0.0347\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5439 - val_loss: 0.0989\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5383 - val_loss: 0.0344\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6070 - val_loss: 0.0643\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5464 - val_loss: 0.0310\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5825 - val_loss: 0.0297\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5124 - val_loss: 0.0483\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5848 - val_loss: 0.0361\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6141 - val_loss: 0.0323\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5340 - val_loss: 0.0362\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5294 - val_loss: 0.0321\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5624 - val_loss: 0.0430\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4872 - val_loss: 0.0330\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5171 - val_loss: 0.0256\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5137 - val_loss: 0.0294\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5531 - val_loss: 0.0490\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5673 - val_loss: 0.0557\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4944 - val_loss: 0.0437\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4997 - val_loss: 0.0325\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5329 - val_loss: 0.0403\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5277 - val_loss: 0.0462\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5101 - val_loss: 0.0360\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5692 - val_loss: 0.0430\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4961 - val_loss: 0.0470\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5480 - val_loss: 0.0243\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5094 - val_loss: 0.0552\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5260 - val_loss: 0.0261\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5209 - val_loss: 0.0446\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4694 - val_loss: 0.0274\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5002 - val_loss: 0.0230\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4948 - val_loss: 0.0381\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5575 - val_loss: 0.0877\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5199 - val_loss: 0.0314\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4645 - val_loss: 0.0277\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4939 - val_loss: 0.0401\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5582 - val_loss: 0.0294\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4579 - val_loss: 0.0554\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5073 - val_loss: 0.0360\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4980 - val_loss: 0.0335\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5393 - val_loss: 0.0474\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5100 - val_loss: 0.0314\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5378 - val_loss: 0.0254\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5304 - val_loss: 0.0430\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4977 - val_loss: 0.0226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4693 - val_loss: 0.0231\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4958 - val_loss: 0.0306\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4601 - val_loss: 0.0470\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4739 - val_loss: 0.0520\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5216 - val_loss: 0.0285\n",
      "7/7 [==============================] - 1s 4ms/step\n",
      "Mean Squared Error: 0.028456055824172745\n",
      "Mean Absolute Error: 0.1227345300551078\n",
      "R-squared: 0.9958384665717769\n",
      "\n",
      "Average scores for ticker GEO:\n",
      "Mean Squared Error: 0.023772639234749565\n",
      "Mean Absolute Error: 0.09963920318072117\n",
      "R-squared: 0.9962903416645391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('dataset.csv').dropna()\n",
    "\n",
    "# Define K-fold cross-validation function for each ticker\n",
    "def kfold_cross_validation_per_ticker(df, n_splits=5):\n",
    "    tickers = df['level_0'].unique()\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        print(f\"Cross-validation for ticker: {ticker}\")\n",
    "        ticker_df = df[df['level_0'] == ticker]\n",
    "        \n",
    "        # Define features and target variable for this ticker\n",
    "        X = ticker_df[['Open', 'High', 'Low', 'Close', 'Volume','Daily Returns','Volatility','RSI', '%K', '%D','Sentiment Score','Movement']].values\n",
    "        y = ticker_df['PreviousDayClose'].values\n",
    "\n",
    "        # Perform K-Fold cross-validation\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        fold = 1\n",
    "        mse_scores, mae_scores, r2_scores = [], [], []\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            print(f'Fold {fold}:')\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # Normalize features\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "            # Reshape input data for GRU (samples, time steps, features)\n",
    "            X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "            X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "            # Create and train GRU model\n",
    "            model = Sequential()\n",
    "            model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(GRU(units=50, return_sequences=True))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(GRU(units=50))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(units=1))\n",
    "            model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "            history = model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "            # Evaluate model\n",
    "            predictions = model.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, predictions)\n",
    "            mae = mean_absolute_error(y_test, predictions)\n",
    "            r2 = r2_score(y_test, predictions)\n",
    "\n",
    "            print(f'Mean Squared Error: {mse}')\n",
    "            print(f'Mean Absolute Error: {mae}')\n",
    "            print(f'R-squared: {r2}\\n')\n",
    "\n",
    "            mse_scores.append(mse)\n",
    "            mae_scores.append(mae)\n",
    "            r2_scores.append(r2)\n",
    "\n",
    "            fold += 1\n",
    "\n",
    "        # Print average scores for the current ticker\n",
    "        print('Average scores for ticker {}:'.format(ticker))\n",
    "        print(f'Mean Squared Error: {np.mean(mse_scores)}')\n",
    "        print(f'Mean Absolute Error: {np.mean(mae_scores)}')\n",
    "        print(f'R-squared: {np.mean(r2_scores)}\\n')\n",
    "\n",
    "# Perform K-fold cross-validation per ticker\n",
    "kfold_cross_validation_per_ticker(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9370ab13",
   "metadata": {},
   "source": [
    "Current Day close price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19f43f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation for ticker: SAVE\n",
      "Fold 1:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 108ms/step - loss: 530.5832 - val_loss: 508.9993\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 403.7511 - val_loss: 288.1057\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 223.6239 - val_loss: 185.2761\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 157.0494 - val_loss: 146.4202\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 126.5765 - val_loss: 121.3973\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 106.0921 - val_loss: 103.3493\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 90.7015 - val_loss: 90.1964\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 81.8480 - val_loss: 80.7525\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 72.8997 - val_loss: 73.6302\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 64.9573 - val_loss: 68.1667\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 62.7392 - val_loss: 64.4149\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 61.0763 - val_loss: 61.6227\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 57.8738 - val_loss: 59.8311\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 56.4291 - val_loss: 58.6204\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 56.5668 - val_loss: 57.8814\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 55.6139 - val_loss: 57.2174\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 55.5670 - val_loss: 56.8466\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 56.0551 - val_loss: 56.6008\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 54.4009 - val_loss: 56.3518\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 55.4270 - val_loss: 56.1841\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 54.7938 - val_loss: 56.0229\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 53.9688 - val_loss: 55.6768\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 54.2527 - val_loss: 55.2981\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 53.7632 - val_loss: 54.5249\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 52.7151 - val_loss: 51.9663\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 47.0504 - val_loss: 44.2297\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 38.2805 - val_loss: 36.1502\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 33.9427 - val_loss: 32.2139\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 30.7556 - val_loss: 29.0700\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 29.0059 - val_loss: 26.2173\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 26.0163 - val_loss: 23.9763\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 23.9357 - val_loss: 22.0464\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 23.2373 - val_loss: 20.0196\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 20.6006 - val_loss: 18.4554\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 18.5675 - val_loss: 17.5861\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 19.3484 - val_loss: 16.2547\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 17.1090 - val_loss: 14.7554\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 16.5042 - val_loss: 13.9813\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 16.0031 - val_loss: 13.2009\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 16.2370 - val_loss: 12.3736\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 15.3129 - val_loss: 11.5030\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 15.3895 - val_loss: 10.8535\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 13.0176 - val_loss: 9.9929\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 13.4431 - val_loss: 9.4027\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 12.6308 - val_loss: 9.0630\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 12.4808 - val_loss: 8.3587\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 11.7060 - val_loss: 7.6707\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 11.3177 - val_loss: 7.0812\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 9.7471 - val_loss: 6.9489\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 10.8938 - val_loss: 6.3061\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 9.0947 - val_loss: 5.9293\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 10.4509 - val_loss: 5.5896\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 9.2349 - val_loss: 5.2079\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 9.7844 - val_loss: 4.7553\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 8.6274 - val_loss: 4.4958\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 8.4393 - val_loss: 5.3464\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 8.0837 - val_loss: 4.0903\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.5706 - val_loss: 3.6654\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.8267 - val_loss: 3.4506\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.8575 - val_loss: 3.3876\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.8480 - val_loss: 3.1606\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.7485 - val_loss: 2.9428\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.1830 - val_loss: 2.8908\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 6.1293 - val_loss: 2.6466\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.1970 - val_loss: 2.5077\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.7506 - val_loss: 2.4502\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 6.2031 - val_loss: 2.6705\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 6.2010 - val_loss: 2.2417\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.7735 - val_loss: 2.1004\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.7013 - val_loss: 2.2622\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.5375 - val_loss: 1.8894\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.6585 - val_loss: 1.8373\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8788 - val_loss: 1.7039\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8797 - val_loss: 1.6798\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.3925 - val_loss: 1.6752\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.9277 - val_loss: 1.5930\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.4688 - val_loss: 1.6392\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.0531 - val_loss: 1.5219\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.9224 - val_loss: 1.4284\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5035 - val_loss: 1.4324\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.0299 - val_loss: 1.3056\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.7819 - val_loss: 1.2497\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.7356 - val_loss: 1.3485\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0801 - val_loss: 1.2814\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.3391 - val_loss: 1.1426\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0690 - val_loss: 1.1546\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.7151 - val_loss: 1.1068\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.3427 - val_loss: 1.0474\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.1676 - val_loss: 1.0977\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.0373 - val_loss: 1.1878\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.8075 - val_loss: 0.9652\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9364 - val_loss: 1.2762\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.3712 - val_loss: 0.9344\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.3172 - val_loss: 0.9183\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2771 - val_loss: 0.9409\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.3460 - val_loss: 1.4283\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2766 - val_loss: 0.8323\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.4585 - val_loss: 0.8081\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8679 - val_loss: 0.8005\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8899 - val_loss: 1.1303\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1548 - val_loss: 1.2677\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0347 - val_loss: 1.0452\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2504 - val_loss: 0.7541\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6932 - val_loss: 0.8319\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6740 - val_loss: 1.0682\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.3455 - val_loss: 0.7546\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8537 - val_loss: 0.7073\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9202 - val_loss: 0.7407\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.3895 - val_loss: 0.6310\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8017 - val_loss: 0.8155\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6691 - val_loss: 0.8066\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.6752 - val_loss: 0.8499\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.6064 - val_loss: 0.8444\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6094 - val_loss: 0.6039\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5483 - val_loss: 0.5941\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7449 - val_loss: 0.6549\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8930 - val_loss: 0.5927\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4386 - val_loss: 1.1208\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3533 - val_loss: 0.6733\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4855 - val_loss: 0.8157\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5505 - val_loss: 0.5725\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.6375 - val_loss: 0.5697\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6657 - val_loss: 0.5299\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5353 - val_loss: 0.5803\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3217 - val_loss: 0.4878\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4645 - val_loss: 0.4917\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3221 - val_loss: 0.5942\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5613 - val_loss: 0.4545\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7523 - val_loss: 0.4927\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.2821 - val_loss: 0.9623\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8299 - val_loss: 0.5816\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8305 - val_loss: 0.4535\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7712 - val_loss: 0.4545\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.2905 - val_loss: 0.8228\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9268 - val_loss: 0.4649\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5091 - val_loss: 0.4729\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.3949 - val_loss: 0.4952\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.1341 - val_loss: 0.4079\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.3901 - val_loss: 0.4517\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7605 - val_loss: 0.4555\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4790 - val_loss: 0.3758\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.1216 - val_loss: 0.4200\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.2627 - val_loss: 0.4817\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5269 - val_loss: 0.4507\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.1465 - val_loss: 0.3707\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.0524 - val_loss: 0.3663\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.3841 - val_loss: 0.3274\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8189 - val_loss: 0.4065\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.2879 - val_loss: 0.5727\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3656 - val_loss: 0.5441\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.5441055930654172\n",
      "Mean Absolute Error: 0.5538210797665724\n",
      "R-squared: 0.990322806495981\n",
      "\n",
      "Fold 2:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 104ms/step - loss: 523.6621 - val_loss: 517.2225\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 372.5227 - val_loss: 254.3782\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 174.8990 - val_loss: 152.9565\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 119.0204 - val_loss: 120.8227\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 97.0092 - val_loss: 101.4602\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 81.8871 - val_loss: 88.9025\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 71.3463 - val_loss: 79.1326\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 66.2435 - val_loss: 72.9122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 60.9643 - val_loss: 68.5820\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 57.3153 - val_loss: 65.3493\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 56.9114 - val_loss: 63.1024\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 55.3174 - val_loss: 61.9553\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 53.4940 - val_loss: 61.0951\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 52.9089 - val_loss: 60.4139\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 52.8362 - val_loss: 59.8787\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 53.0625 - val_loss: 59.4618\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 52.7916 - val_loss: 59.0654\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 51.2819 - val_loss: 58.3852\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 50.2969 - val_loss: 57.1177\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 48.7224 - val_loss: 54.7702\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 45.0041 - val_loss: 49.7352\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 38.8816 - val_loss: 42.0680\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 32.9184 - val_loss: 36.0769\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 29.7136 - val_loss: 31.9949\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 26.7524 - val_loss: 29.2020\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 26.2225 - val_loss: 26.0818\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 22.7561 - val_loss: 24.2653\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 21.9845 - val_loss: 21.9064\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 20.0609 - val_loss: 20.1116\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 18.1371 - val_loss: 18.6451\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 17.1623 - val_loss: 17.5613\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 17.7985 - val_loss: 16.2267\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 15.7472 - val_loss: 15.2120\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 16.0726 - val_loss: 14.0534\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 13.7573 - val_loss: 13.0853\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 14.0806 - val_loss: 12.2458\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 13.6922 - val_loss: 11.3840\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 12.9431 - val_loss: 10.6968\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 11.8044 - val_loss: 10.1611\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 11.7269 - val_loss: 9.3461\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 11.0748 - val_loss: 8.7971\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 11.3077 - val_loss: 8.2479\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 9.5203 - val_loss: 7.6089\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 9.9945 - val_loss: 7.1601\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 9.7517 - val_loss: 6.7901\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 9.3964 - val_loss: 6.3207\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 8.9057 - val_loss: 6.0064\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 8.3748 - val_loss: 5.5939\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.6243 - val_loss: 5.3503\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.7584 - val_loss: 5.0472\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.8441 - val_loss: 4.6556\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.2288 - val_loss: 4.5077\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.2983 - val_loss: 4.1877\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.2101 - val_loss: 4.0380\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.2345 - val_loss: 3.8096\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.7876 - val_loss: 3.7926\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.0398 - val_loss: 3.3329\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.2495 - val_loss: 3.1429\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.3277 - val_loss: 2.9997\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.9998 - val_loss: 2.8309\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.4631 - val_loss: 2.6768\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.2967 - val_loss: 2.6337\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.7388 - val_loss: 2.4576\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.7626 - val_loss: 2.3466\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.4832 - val_loss: 2.2870\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.4658 - val_loss: 2.1090\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.1503 - val_loss: 2.0934\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.8613 - val_loss: 1.9192\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5761 - val_loss: 1.8887\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.9375 - val_loss: 1.9298\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.9757 - val_loss: 1.9287\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.8041 - val_loss: 1.6027\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.8444 - val_loss: 1.5420\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.7179 - val_loss: 1.5135\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.8168 - val_loss: 1.4730\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.8236 - val_loss: 1.4186\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.9078 - val_loss: 1.3053\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.1062 - val_loss: 1.2910\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.9155 - val_loss: 1.3044\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.6517 - val_loss: 1.3623\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5950 - val_loss: 1.2527\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.6212 - val_loss: 1.1520\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.7263 - val_loss: 1.0826\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1218 - val_loss: 1.0368\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5618 - val_loss: 1.0036\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.4122 - val_loss: 0.9693\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.5426 - val_loss: 1.1093\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.5058 - val_loss: 1.0043\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 4.2515 - val_loss: 0.8902\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6684 - val_loss: 0.9061\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.4579 - val_loss: 0.8878\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.3193 - val_loss: 0.8223\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.8295 - val_loss: 0.8249\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.8653 - val_loss: 0.8605\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9212 - val_loss: 0.7917\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.4743 - val_loss: 0.9605\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.3202 - val_loss: 0.7319\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7157 - val_loss: 0.7189\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.4005 - val_loss: 0.7014\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1161 - val_loss: 0.6940\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.5336 - val_loss: 0.7520\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 3.6741 - val_loss: 1.0469\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.1922 - val_loss: 0.6204\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.1033 - val_loss: 0.7430\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9130 - val_loss: 0.7202\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7430 - val_loss: 0.6994\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.8300 - val_loss: 0.9715\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 1s 21ms/step - loss: 4.1177 - val_loss: 0.5684\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.6407 - val_loss: 0.6182\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5617 - val_loss: 0.5965\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.7895 - val_loss: 0.6717\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8966 - val_loss: 0.5165\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5615 - val_loss: 0.5155\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8198 - val_loss: 0.5206\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4618 - val_loss: 0.5608\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.9592 - val_loss: 0.4792\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0025 - val_loss: 0.4614\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1449 - val_loss: 0.5223\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7457 - val_loss: 0.4990\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5614 - val_loss: 0.4503\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2286 - val_loss: 0.4271\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5863 - val_loss: 0.4274\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.7106 - val_loss: 0.4377\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3099 - val_loss: 0.6040\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6056 - val_loss: 0.4906\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9981 - val_loss: 0.5165\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.1687 - val_loss: 0.5382\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5779 - val_loss: 0.4297\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9360 - val_loss: 0.3725\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8518 - val_loss: 0.3781\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4284 - val_loss: 0.4517\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.7237 - val_loss: 0.3657\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 2.9485 - val_loss: 0.5002\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.6841 - val_loss: 0.3593\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7686 - val_loss: 0.5167\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3431 - val_loss: 0.3746\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6614 - val_loss: 0.4502\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8187 - val_loss: 0.4195\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6462 - val_loss: 0.4617\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0052 - val_loss: 0.3281\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.2070 - val_loss: 0.3756\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.0822 - val_loss: 0.3093\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.0684 - val_loss: 0.3483\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6499 - val_loss: 0.3220\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3962 - val_loss: 0.3285\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.2632 - val_loss: 0.4448\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.1952 - val_loss: 0.3295\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.2104 - val_loss: 0.3916\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8095 - val_loss: 0.2820\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4011 - val_loss: 0.2918\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.29180711062345743\n",
      "Mean Absolute Error: 0.32023144242775375\n",
      "R-squared: 0.995069376229744\n",
      "\n",
      "Fold 3:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 132ms/step - loss: 524.5575 - val_loss: 502.1194\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 374.7556 - val_loss: 256.4019\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 186.9091 - val_loss: 155.7305\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 130.2617 - val_loss: 122.3831\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 105.7306 - val_loss: 102.0993\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 88.3329 - val_loss: 87.9103\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 78.9141 - val_loss: 77.9028\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 71.1564 - val_loss: 70.8099\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 65.5292 - val_loss: 65.5604\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 60.7025 - val_loss: 61.7564\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 59.7523 - val_loss: 59.3261\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 56.5550 - val_loss: 57.5900\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 58.3467 - val_loss: 56.5121\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 54.9977 - val_loss: 55.5611\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 56.3930 - val_loss: 55.1048\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 54.4374 - val_loss: 54.5703\n",
      "Epoch 17/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 17ms/step - loss: 54.6570 - val_loss: 54.1949\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 55.1042 - val_loss: 53.7296\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 54.5444 - val_loss: 53.2090\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 53.3830 - val_loss: 52.3967\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 52.8710 - val_loss: 50.7345\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 49.0830 - val_loss: 47.3182\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 46.0622 - val_loss: 41.3834\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 37.8173 - val_loss: 33.9884\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 33.1228 - val_loss: 28.9211\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 29.5446 - val_loss: 25.9504\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 27.3303 - val_loss: 23.6208\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 24.7872 - val_loss: 21.4496\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 22.9220 - val_loss: 19.5466\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 22.4881 - val_loss: 17.9441\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 20.2374 - val_loss: 17.0126\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 19.1380 - val_loss: 15.4698\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 18.1700 - val_loss: 14.1877\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 16.8327 - val_loss: 13.3254\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 17.2318 - val_loss: 12.1962\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 15.1087 - val_loss: 12.1838\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 14.3473 - val_loss: 10.7558\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 13.4648 - val_loss: 10.1159\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 12.5842 - val_loss: 9.4825\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 11.8298 - val_loss: 8.8636\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 12.7016 - val_loss: 8.6413\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 11.6710 - val_loss: 7.9009\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 12.1156 - val_loss: 7.9910\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 10.7701 - val_loss: 7.0221\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 9.8441 - val_loss: 6.5590\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 10.5423 - val_loss: 6.0517\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 9.7914 - val_loss: 5.7570\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 9.2033 - val_loss: 5.4841\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 9.7187 - val_loss: 5.0334\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.8917 - val_loss: 4.6607\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.8666 - val_loss: 4.4244\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 8.1709 - val_loss: 4.1941\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.3909 - val_loss: 3.9967\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.3761 - val_loss: 3.8894\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 7.5350 - val_loss: 3.6478\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.4788 - val_loss: 3.7421\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.4599 - val_loss: 3.1731\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.0014 - val_loss: 3.1650\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 6.0279 - val_loss: 3.1332\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.6845 - val_loss: 2.8096\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.6316 - val_loss: 2.5889\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.9439 - val_loss: 2.4861\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.3222 - val_loss: 2.3435\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.3176 - val_loss: 2.2790\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.4831 - val_loss: 2.1401\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.7360 - val_loss: 2.0404\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.4048 - val_loss: 1.9908\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.3099 - val_loss: 1.9589\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.9336 - val_loss: 1.8140\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8432 - val_loss: 1.7629\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.8112 - val_loss: 1.8544\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.0559 - val_loss: 1.6874\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.1020 - val_loss: 1.5809\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.3538 - val_loss: 1.5637\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.6578 - val_loss: 1.5560\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5441 - val_loss: 1.8344\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.4498 - val_loss: 1.4010\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.9968 - val_loss: 1.4174\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.4443 - val_loss: 1.4795\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 4.5490 - val_loss: 1.4129\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5407 - val_loss: 1.2938\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5837 - val_loss: 1.2003\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.8242 - val_loss: 1.4380\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.3448 - val_loss: 1.1696\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0494 - val_loss: 1.1052\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1744 - val_loss: 1.2079\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.3661 - val_loss: 1.0695\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9915 - val_loss: 1.1234\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.9580 - val_loss: 1.0532\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.5120 - val_loss: 1.1311\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8309 - val_loss: 0.9533\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.0838 - val_loss: 0.9160\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1429 - val_loss: 0.9246\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8889 - val_loss: 1.1252\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.0772 - val_loss: 0.9417\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0009 - val_loss: 0.9269\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.2015 - val_loss: 0.9480\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2326 - val_loss: 0.9539\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9146 - val_loss: 0.8116\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8709 - val_loss: 0.8411\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1170 - val_loss: 0.7737\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.9317 - val_loss: 0.8383\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.6859 - val_loss: 0.7386\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6247 - val_loss: 1.1044\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.6848 - val_loss: 0.7381\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9055 - val_loss: 0.8828\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.6141 - val_loss: 0.7451\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0551 - val_loss: 0.7258\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.0291 - val_loss: 0.8409\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6913 - val_loss: 0.6603\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7760 - val_loss: 0.6550\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7791 - val_loss: 0.5995\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7202 - val_loss: 0.5934\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.6901 - val_loss: 0.6991\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.8877 - val_loss: 0.5613\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7802 - val_loss: 0.5454\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4160 - val_loss: 0.6367\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.6805 - val_loss: 0.5595\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7866 - val_loss: 0.6540\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7185 - val_loss: 0.5805\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.3660 - val_loss: 0.6589\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.2949 - val_loss: 0.5626\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1976 - val_loss: 0.6319\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.0716 - val_loss: 1.1359\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.5430 - val_loss: 0.4703\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.3752 - val_loss: 0.4924\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7553 - val_loss: 0.5286\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6916 - val_loss: 0.4705\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8578 - val_loss: 0.4849\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.3906 - val_loss: 0.5515\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7258 - val_loss: 0.3971\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7842 - val_loss: 0.5005\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.6978 - val_loss: 0.4210\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6007 - val_loss: 0.3679\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6803 - val_loss: 0.5261\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4011 - val_loss: 0.3930\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.2850 - val_loss: 0.3899\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6734 - val_loss: 0.4034\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4175 - val_loss: 0.3303\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5455 - val_loss: 0.3520\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.6171 - val_loss: 0.6256\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.1578 - val_loss: 0.4556\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3124 - val_loss: 0.3168\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3836 - val_loss: 0.3933\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4752 - val_loss: 0.5829\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7114 - val_loss: 0.2920\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4419 - val_loss: 0.3464\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.3628 - val_loss: 0.2893\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6263 - val_loss: 0.5530\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.1939 - val_loss: 0.2735\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.27345981601013747\n",
      "Mean Absolute Error: 0.3172522445223224\n",
      "R-squared: 0.9949689181015942\n",
      "\n",
      "Fold 4:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 103ms/step - loss: 544.5867 - val_loss: 448.0501\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 395.8073 - val_loss: 206.6907\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 184.6030 - val_loss: 108.9818\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 123.9245 - val_loss: 82.6989\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 98.8245 - val_loss: 67.8340\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 86.3459 - val_loss: 57.9923\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 74.5699 - val_loss: 52.0735\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 68.0028 - val_loss: 48.6028\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 64.1578 - val_loss: 46.3219\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 61.6419 - val_loss: 45.1294\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 59.0827 - val_loss: 44.5416\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 58.8800 - val_loss: 44.3318\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 56.8778 - val_loss: 44.2823\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 57.2019 - val_loss: 44.3565\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 56.5529 - val_loss: 44.3687\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 56.3969 - val_loss: 44.1709\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 55.4302 - val_loss: 43.7253\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 56.2197 - val_loss: 43.0694\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 55.8776 - val_loss: 40.9452\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 50.6095 - val_loss: 36.1939\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 46.3430 - val_loss: 29.0431\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 39.1250 - val_loss: 22.1961\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 34.0890 - val_loss: 19.8049\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 30.2603 - val_loss: 17.3145\n",
      "Epoch 25/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 17ms/step - loss: 28.2776 - val_loss: 15.3492\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 26.1675 - val_loss: 14.4472\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 23.7440 - val_loss: 13.3409\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 21.9720 - val_loss: 11.7577\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 22.1297 - val_loss: 10.8823\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 19.0275 - val_loss: 10.2042\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 18.3384 - val_loss: 9.4311\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 18.5871 - val_loss: 8.6606\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 16.5591 - val_loss: 8.0109\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 16.2194 - val_loss: 7.4886\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 15.0383 - val_loss: 7.2657\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 13.3200 - val_loss: 6.3420\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 13.0637 - val_loss: 5.9361\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 12.4854 - val_loss: 5.4839\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 12.5136 - val_loss: 5.1736\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 11.9755 - val_loss: 5.0164\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 10.8719 - val_loss: 4.4197\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 10.9319 - val_loss: 4.2336\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 10.4428 - val_loss: 3.8527\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 9.2273 - val_loss: 3.5829\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 9.1097 - val_loss: 3.3973\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 8.5438 - val_loss: 3.0499\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 9.6157 - val_loss: 3.0944\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 8.9652 - val_loss: 2.6875\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.7679 - val_loss: 2.6407\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.9166 - val_loss: 2.3720\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.7604 - val_loss: 2.2042\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.7590 - val_loss: 2.0719\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.0442 - val_loss: 1.9062\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.1882 - val_loss: 1.8228\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.7692 - val_loss: 1.7175\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.1121 - val_loss: 1.6300\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.6142 - val_loss: 1.7236\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.0513 - val_loss: 1.7343\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.7220 - val_loss: 1.3554\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.0731 - val_loss: 1.3527\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.9676 - val_loss: 1.2797\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.2980 - val_loss: 1.3166\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.4854 - val_loss: 1.2766\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.2779 - val_loss: 1.1693\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.8422 - val_loss: 1.0610\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.4090 - val_loss: 1.3788\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.2857 - val_loss: 1.0257\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.6489 - val_loss: 0.9263\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.0802 - val_loss: 0.9163\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.0973 - val_loss: 1.0030\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.7487 - val_loss: 0.8687\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.3345 - val_loss: 1.0881\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5658 - val_loss: 0.9508\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.5337 - val_loss: 0.8328\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.5134 - val_loss: 0.8831\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.6297 - val_loss: 0.7324\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.4558 - val_loss: 0.6948\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.6003 - val_loss: 0.7294\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.7303 - val_loss: 0.6627\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.7419 - val_loss: 0.6957\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.4566 - val_loss: 0.6212\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1682 - val_loss: 0.6374\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.4500 - val_loss: 0.9324\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.9559 - val_loss: 0.8270\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.6476 - val_loss: 1.1140\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.8224 - val_loss: 0.7773\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1018 - val_loss: 0.5511\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9252 - val_loss: 0.6574\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.5096 - val_loss: 0.5201\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2937 - val_loss: 0.6109\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.8466 - val_loss: 0.5064\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0229 - val_loss: 0.5646\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1478 - val_loss: 0.5418\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.4888 - val_loss: 0.6470\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0376 - val_loss: 0.5858\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.4171 - val_loss: 0.4794\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1382 - val_loss: 0.5746\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.9647 - val_loss: 0.5150\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.2966 - val_loss: 0.4469\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2850 - val_loss: 0.4710\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.5123 - val_loss: 0.6729\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.3371 - val_loss: 0.5369\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1735 - val_loss: 0.4293\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.3457 - val_loss: 0.4173\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9669 - val_loss: 0.4429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.9951 - val_loss: 0.5063\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.6412 - val_loss: 0.3669\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0291 - val_loss: 0.3651\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.0570 - val_loss: 0.8313\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8166 - val_loss: 0.4283\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9387 - val_loss: 0.3496\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7213 - val_loss: 0.3559\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9663 - val_loss: 1.0360\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5270 - val_loss: 0.7913\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8435 - val_loss: 0.3962\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 4.0867 - val_loss: 0.3337\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.3838 - val_loss: 0.3835\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 3.5795 - val_loss: 0.3829\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.3782 - val_loss: 0.4004\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.7662 - val_loss: 0.3171\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8419 - val_loss: 0.4662\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4726 - val_loss: 0.2742\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8835 - val_loss: 0.3132\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.6716 - val_loss: 0.2961\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.2051 - val_loss: 0.4477\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 3.5709 - val_loss: 0.3089\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.7733 - val_loss: 0.3027\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1483 - val_loss: 0.2642\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6091 - val_loss: 0.2992\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1754 - val_loss: 0.3212\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6970 - val_loss: 0.3236\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6502 - val_loss: 0.3699\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7558 - val_loss: 0.4416\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6615 - val_loss: 0.2552\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5816 - val_loss: 0.2323\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.5354 - val_loss: 0.2460\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7995 - val_loss: 0.4785\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.3414 - val_loss: 0.3050\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3239 - val_loss: 0.3466\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5576 - val_loss: 0.2359\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7532 - val_loss: 0.3411\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5759 - val_loss: 0.6221\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6868 - val_loss: 0.4720\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6019 - val_loss: 0.3173\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6247 - val_loss: 0.2203\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4758 - val_loss: 0.2054\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4229 - val_loss: 0.2081\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.5214 - val_loss: 0.2617\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.8501 - val_loss: 0.3785\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 3.4414 - val_loss: 0.2470\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.24695238602216057\n",
      "Mean Absolute Error: 0.368174116409833\n",
      "R-squared: 0.9945078197235104\n",
      "\n",
      "Fold 5:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 108ms/step - loss: 535.6118 - val_loss: 481.8361\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 402.3500 - val_loss: 252.6543\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 206.5784 - val_loss: 144.5825\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 137.2065 - val_loss: 110.0269\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 109.0663 - val_loss: 89.8493\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 94.0762 - val_loss: 76.8173\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 79.9412 - val_loss: 67.2919\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 72.4749 - val_loss: 60.8736\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 66.8258 - val_loss: 56.5842\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 62.4296 - val_loss: 53.6369\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 59.6459 - val_loss: 51.7627\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 58.1770 - val_loss: 50.4818\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 58.1725 - val_loss: 49.6545\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 58.5118 - val_loss: 49.1971\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 56.2546 - val_loss: 48.9458\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 56.8415 - val_loss: 48.7697\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 56.3246 - val_loss: 48.5759\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 55.9847 - val_loss: 48.3310\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 56.7450 - val_loss: 47.9047\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 54.7868 - val_loss: 46.9572\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 53.4909 - val_loss: 44.6404\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 49.3679 - val_loss: 39.9017\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 44.0021 - val_loss: 32.2703\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 36.7774 - val_loss: 27.5330\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 32.3600 - val_loss: 24.4019\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 28.2143 - val_loss: 21.8821\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 26.6411 - val_loss: 19.4065\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 24.4597 - val_loss: 17.8216\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 22.6885 - val_loss: 16.3122\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 20.9705 - val_loss: 14.9387\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 20.0048 - val_loss: 13.9783\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 18.8047 - val_loss: 12.9711\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 18.7850 - val_loss: 12.0026\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 16.6536 - val_loss: 11.2926\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 15.1407 - val_loss: 10.9481\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 14.9252 - val_loss: 9.9120\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 14.6310 - val_loss: 9.8043\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 13.9232 - val_loss: 8.6596\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 13.3096 - val_loss: 8.0611\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 12.5646 - val_loss: 7.5765\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 12.3611 - val_loss: 7.1047\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 11.8902 - val_loss: 7.1151\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 10.7369 - val_loss: 6.3998\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 10.6418 - val_loss: 6.0545\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 9.6576 - val_loss: 5.7575\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 8.9420 - val_loss: 5.1832\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 9.5976 - val_loss: 4.9391\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.9188 - val_loss: 4.6609\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 8.0726 - val_loss: 4.3436\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 9.1465 - val_loss: 4.4357\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 8.7424 - val_loss: 4.1585\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.5240 - val_loss: 3.7085\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.8535 - val_loss: 3.4545\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.4309 - val_loss: 3.3080\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.1131 - val_loss: 3.3987\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.5839 - val_loss: 2.9606\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 7.7668 - val_loss: 2.9823\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.7403 - val_loss: 2.6917\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.4968 - val_loss: 2.4587\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.4569 - val_loss: 2.4148\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.4821 - val_loss: 2.2678\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.9262 - val_loss: 2.5252\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 6.0793 - val_loss: 2.3451\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.8077 - val_loss: 2.0120\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.9221 - val_loss: 1.8731\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.4638 - val_loss: 1.7977\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.6477 - val_loss: 1.7674\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.5019 - val_loss: 1.6581\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.9561 - val_loss: 1.6646\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.4958 - val_loss: 1.5421\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 5.1365 - val_loss: 1.6095\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.2554 - val_loss: 1.4265\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 5.1405 - val_loss: 1.4169\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.0314 - val_loss: 1.6745\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.6251 - val_loss: 1.6775\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.8876 - val_loss: 1.3253\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.4873 - val_loss: 1.3673\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 4.7473 - val_loss: 1.1808\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.7780 - val_loss: 1.1508\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.8754 - val_loss: 1.7039\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.7080 - val_loss: 1.3306\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.4523 - val_loss: 1.1102\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.9737 - val_loss: 1.3350\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.4212 - val_loss: 1.4156\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.8217 - val_loss: 1.0045\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.7020 - val_loss: 0.9936\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7641 - val_loss: 0.9081\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.0769 - val_loss: 0.9332\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.0725 - val_loss: 1.3193\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.4992 - val_loss: 0.8595\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.0593 - val_loss: 0.8167\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.4851 - val_loss: 0.8859\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.9339 - val_loss: 0.9081\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.9002 - val_loss: 0.8100\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.3512 - val_loss: 0.7441\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1543 - val_loss: 0.7437\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7867 - val_loss: 0.8324\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1537 - val_loss: 0.7767\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.2727 - val_loss: 0.6634\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.9994 - val_loss: 0.6569\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.0428 - val_loss: 0.7014\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.3301 - val_loss: 0.6172\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.4107 - val_loss: 0.5991\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.6778 - val_loss: 0.6010\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1958 - val_loss: 0.6395\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5408 - val_loss: 0.6056\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8030 - val_loss: 0.5722\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0387 - val_loss: 0.5917\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.8377 - val_loss: 0.5206\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1193 - val_loss: 0.6247\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7402 - val_loss: 0.5078\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4633 - val_loss: 0.5381\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.6353 - val_loss: 0.4833\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4992 - val_loss: 0.4555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.6641 - val_loss: 0.5037\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.9412 - val_loss: 0.5094\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5291 - val_loss: 0.4310\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.6847 - val_loss: 0.5256\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.6081 - val_loss: 0.4055\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.8810 - val_loss: 0.5858\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4453 - val_loss: 1.1004\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.0302 - val_loss: 0.4621\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5220 - val_loss: 0.4979\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4196 - val_loss: 0.3877\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.5374 - val_loss: 0.4161\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.4719 - val_loss: 0.3515\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6862 - val_loss: 0.4013\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.6669 - val_loss: 0.3445\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5710 - val_loss: 0.3390\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.5688 - val_loss: 0.3277\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.6987 - val_loss: 0.6452\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.8093 - val_loss: 0.5014\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.1102 - val_loss: 0.4674\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.6197 - val_loss: 0.3960\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.7081 - val_loss: 0.2848\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4956 - val_loss: 0.6437\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.8160 - val_loss: 0.5017\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4128 - val_loss: 0.2926\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4070 - val_loss: 0.2724\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.5107 - val_loss: 0.2735\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.3270 - val_loss: 0.3192\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5855 - val_loss: 0.2362\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4306 - val_loss: 0.4645\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3397 - val_loss: 0.3203\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4445 - val_loss: 0.2978\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.3961 - val_loss: 0.3288\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.3340 - val_loss: 0.2274\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.4784 - val_loss: 0.2311\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 3.4036 - val_loss: 0.2350\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5104 - val_loss: 0.2418\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.2417616130778559\n",
      "Mean Absolute Error: 0.2792313608957167\n",
      "R-squared: 0.9950980005107694\n",
      "\n",
      "Average scores for ticker SAVE:\n",
      "Mean Squared Error: 0.3196173037598057\n",
      "Mean Absolute Error: 0.36774204880443967\n",
      "R-squared: 0.9939933842123198\n",
      "\n",
      "Cross-validation for ticker: CLNE\n",
      "Fold 1:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 14s 103ms/step - loss: 36.3557 - val_loss: 33.0987\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 14.1932 - val_loss: 8.2274\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 7.2164 - val_loss: 7.3474\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.3878 - val_loss: 5.2623\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.7263 - val_loss: 3.0493\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 2.1067 - val_loss: 1.3909\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.1144 - val_loss: 0.8304\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0166 - val_loss: 0.7095\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.0146 - val_loss: 0.6290\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0230 - val_loss: 0.5701\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8047 - val_loss: 0.5311\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7651 - val_loss: 0.5102\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7477 - val_loss: 0.5419\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7854 - val_loss: 0.4860\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6849 - val_loss: 0.4274\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6472 - val_loss: 0.3937\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7437 - val_loss: 0.3946\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6863 - val_loss: 0.3766\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6362 - val_loss: 0.3648\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6965 - val_loss: 0.3225\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7078 - val_loss: 0.3491\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6709 - val_loss: 0.2996\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5991 - val_loss: 0.2756\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5530 - val_loss: 0.2650\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6011 - val_loss: 0.2752\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5332 - val_loss: 0.2423\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5285 - val_loss: 0.2352\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5840 - val_loss: 0.2285\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5441 - val_loss: 0.2493\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5296 - val_loss: 0.2711\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5276 - val_loss: 0.2071\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4909 - val_loss: 0.2094\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5246 - val_loss: 0.2036\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5802 - val_loss: 0.2267\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5399 - val_loss: 0.3058\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5145 - val_loss: 0.1869\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5155 - val_loss: 0.1884\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4894 - val_loss: 0.1735\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5282 - val_loss: 0.1555\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5130 - val_loss: 0.1586\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5153 - val_loss: 0.1554\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3976 - val_loss: 0.1481\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4729 - val_loss: 0.1625\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4395 - val_loss: 0.1438\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4486 - val_loss: 0.1604\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4203 - val_loss: 0.1527\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4237 - val_loss: 0.1302\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4602 - val_loss: 0.1597\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4528 - val_loss: 0.1272\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3711 - val_loss: 0.1429\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4266 - val_loss: 0.1296\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4401 - val_loss: 0.1290\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4230 - val_loss: 0.1297\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4314 - val_loss: 0.1380\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4386 - val_loss: 0.1190\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3739 - val_loss: 0.1170\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3830 - val_loss: 0.1137\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4239 - val_loss: 0.1213\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3858 - val_loss: 0.1097\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4300 - val_loss: 0.1094\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3921 - val_loss: 0.1103\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3455 - val_loss: 0.1184\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3763 - val_loss: 0.1100\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4235 - val_loss: 0.1132\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3413 - val_loss: 0.1233\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3525 - val_loss: 0.0931\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3468 - val_loss: 0.1271\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4337 - val_loss: 0.1032\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4125 - val_loss: 0.1089\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3741 - val_loss: 0.0865\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3597 - val_loss: 0.1021\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3443 - val_loss: 0.0998\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3126 - val_loss: 0.0794\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3579 - val_loss: 0.0946\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3550 - val_loss: 0.0819\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3625 - val_loss: 0.1612\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3719 - val_loss: 0.0792\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3351 - val_loss: 0.0881\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3613 - val_loss: 0.0838\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3950 - val_loss: 0.0796\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4003 - val_loss: 0.0950\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3392 - val_loss: 0.0791\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3709 - val_loss: 0.1049\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3762 - val_loss: 0.1223\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3284 - val_loss: 0.0880\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3278 - val_loss: 0.0723\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3168 - val_loss: 0.0813\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3200 - val_loss: 0.0866\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3405 - val_loss: 0.0884\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3558 - val_loss: 0.0999\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3498 - val_loss: 0.0860\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3149 - val_loss: 0.0949\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3278 - val_loss: 0.0801\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2841 - val_loss: 0.0861\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3173 - val_loss: 0.0633\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3336 - val_loss: 0.1104\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3136 - val_loss: 0.0731\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3560 - val_loss: 0.0695\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3495 - val_loss: 0.0674\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3699 - val_loss: 0.0667\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3042 - val_loss: 0.0628\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3017 - val_loss: 0.0551\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3515 - val_loss: 0.0546\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3479 - val_loss: 0.0825\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3223 - val_loss: 0.1534\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3522 - val_loss: 0.0713\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.2944 - val_loss: 0.0679\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.2585 - val_loss: 0.0637\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2963 - val_loss: 0.0573\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3133 - val_loss: 0.0803\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3547 - val_loss: 0.1134\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4056 - val_loss: 0.1069\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3888 - val_loss: 0.0746\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3044 - val_loss: 0.0841\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3533 - val_loss: 0.0819\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.2691 - val_loss: 0.0623\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2923 - val_loss: 0.0724\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.2755 - val_loss: 0.0582\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3323 - val_loss: 0.0931\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3157 - val_loss: 0.1186\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3344 - val_loss: 0.0928\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3039 - val_loss: 0.0519\n",
      "Epoch 123/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3274 - val_loss: 0.0469\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2586 - val_loss: 0.0531\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3003 - val_loss: 0.0759\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3665 - val_loss: 0.0505\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2889 - val_loss: 0.0475\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2885 - val_loss: 0.1128\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3174 - val_loss: 0.0629\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3070 - val_loss: 0.0449\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2766 - val_loss: 0.0573\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2818 - val_loss: 0.0495\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2683 - val_loss: 0.0497\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2543 - val_loss: 0.0429\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3016 - val_loss: 0.0441\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2924 - val_loss: 0.0623\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2500 - val_loss: 0.1230\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3493 - val_loss: 0.0804\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2926 - val_loss: 0.0435\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2745 - val_loss: 0.0470\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2991 - val_loss: 0.0424\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2856 - val_loss: 0.0604\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2978 - val_loss: 0.0396\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2824 - val_loss: 0.0526\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3294 - val_loss: 0.0527\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3368 - val_loss: 0.0929\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2839 - val_loss: 0.0749\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3504 - val_loss: 0.0568\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2646 - val_loss: 0.0445\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3117 - val_loss: 0.0529\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.05293921477311403\n",
      "Mean Absolute Error: 0.16640537769640262\n",
      "R-squared: 0.9951438351087449\n",
      "\n",
      "Fold 2:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 16s 138ms/step - loss: 38.5608 - val_loss: 32.3414\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 17.6675 - val_loss: 8.3561\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 7.9626 - val_loss: 7.4996\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 6.2399 - val_loss: 6.1702\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.9364 - val_loss: 4.0346\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 2.9809 - val_loss: 1.9397\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.6561 - val_loss: 1.0305\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.3668 - val_loss: 0.7613\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.2623 - val_loss: 0.6650\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.0875 - val_loss: 0.6027\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.0514 - val_loss: 0.5455\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9681 - val_loss: 0.4879\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.9662 - val_loss: 0.4425\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8648 - val_loss: 0.4107\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9093 - val_loss: 0.3819\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8666 - val_loss: 0.3439\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7763 - val_loss: 0.3185\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8650 - val_loss: 0.2989\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7927 - val_loss: 0.2795\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7507 - val_loss: 0.2828\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7284 - val_loss: 0.2409\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7475 - val_loss: 0.2430\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6742 - val_loss: 0.2174\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6257 - val_loss: 0.3207\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6613 - val_loss: 0.1973\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6262 - val_loss: 0.1763\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5554 - val_loss: 0.1729\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6557 - val_loss: 0.1814\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6009 - val_loss: 0.1713\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6023 - val_loss: 0.1841\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5689 - val_loss: 0.1447\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5785 - val_loss: 0.1703\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5281 - val_loss: 0.1365\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5906 - val_loss: 0.1492\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5500 - val_loss: 0.1616\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5563 - val_loss: 0.1495\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5708 - val_loss: 0.1432\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5826 - val_loss: 0.1660\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5345 - val_loss: 0.1190\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5195 - val_loss: 0.1035\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4945 - val_loss: 0.1048\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4819 - val_loss: 0.0994\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5018 - val_loss: 0.1240\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4766 - val_loss: 0.1418\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5448 - val_loss: 0.1204\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4455 - val_loss: 0.1242\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4779 - val_loss: 0.1011\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4355 - val_loss: 0.0880\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4312 - val_loss: 0.0827\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5024 - val_loss: 0.0827\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4056 - val_loss: 0.0948\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4374 - val_loss: 0.1088\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4130 - val_loss: 0.0768\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3664 - val_loss: 0.1037\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4317 - val_loss: 0.0821\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4614 - val_loss: 0.0740\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4021 - val_loss: 0.0813\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4389 - val_loss: 0.0993\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3975 - val_loss: 0.0676\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3906 - val_loss: 0.0723\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4232 - val_loss: 0.0750\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3964 - val_loss: 0.0737\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3955 - val_loss: 0.0776\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4973 - val_loss: 0.0788\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3810 - val_loss: 0.0735\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4220 - val_loss: 0.0629\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4111 - val_loss: 0.0762\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4314 - val_loss: 0.0589\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4437 - val_loss: 0.0592\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.0874\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3832 - val_loss: 0.0539\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3965 - val_loss: 0.0646\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3889 - val_loss: 0.1814\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4681 - val_loss: 0.0621\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3338 - val_loss: 0.0532\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3721 - val_loss: 0.0546\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3572 - val_loss: 0.0861\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3964 - val_loss: 0.0557\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3420 - val_loss: 0.0677\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3557 - val_loss: 0.0641\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3743 - val_loss: 0.0595\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3294 - val_loss: 0.0506\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3527 - val_loss: 0.0575\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3667 - val_loss: 0.0525\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3864 - val_loss: 0.0709\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3419 - val_loss: 0.0423\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3781 - val_loss: 0.0770\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3202 - val_loss: 0.0805\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3045 - val_loss: 0.0518\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3684 - val_loss: 0.0522\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2869 - val_loss: 0.0630\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3277 - val_loss: 0.0909\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3281 - val_loss: 0.0488\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3576 - val_loss: 0.0434\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3227 - val_loss: 0.0551\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3765 - val_loss: 0.0471\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3250 - val_loss: 0.0461\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3296 - val_loss: 0.0388\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3418 - val_loss: 0.0460\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3236 - val_loss: 0.0376\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3461 - val_loss: 0.0614\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3197 - val_loss: 0.0358\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3426 - val_loss: 0.0386\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3204 - val_loss: 0.0482\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3700 - val_loss: 0.0624\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3519 - val_loss: 0.0532\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3330 - val_loss: 0.1041\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3668 - val_loss: 0.0484\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3347 - val_loss: 0.0332\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3299 - val_loss: 0.0380\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3055 - val_loss: 0.0487\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.2789 - val_loss: 0.0843\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3452 - val_loss: 0.0340\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2667 - val_loss: 0.0349\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3241 - val_loss: 0.0282\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3134 - val_loss: 0.0328\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3359 - val_loss: 0.0426\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3107 - val_loss: 0.0323\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3102 - val_loss: 0.0342\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3164 - val_loss: 0.0645\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3358 - val_loss: 0.0289\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3004 - val_loss: 0.0398\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.2775 - val_loss: 0.0265\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3330 - val_loss: 0.0476\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3450 - val_loss: 0.0332\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3152 - val_loss: 0.0254\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.3113 - val_loss: 0.0330\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3042 - val_loss: 0.0399\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2902 - val_loss: 0.0373\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2942 - val_loss: 0.0752\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3026 - val_loss: 0.0346\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3194 - val_loss: 0.0261\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.2991 - val_loss: 0.0564\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3406 - val_loss: 0.0510\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2980 - val_loss: 0.0303\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3131 - val_loss: 0.0629\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3282 - val_loss: 0.0416\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3328 - val_loss: 0.0364\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2752 - val_loss: 0.0347\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3265 - val_loss: 0.0559\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3244 - val_loss: 0.0378\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3050 - val_loss: 0.0353\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3153 - val_loss: 0.0336\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2985 - val_loss: 0.0302\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3064 - val_loss: 0.0301\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.2681 - val_loss: 0.0436\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2767 - val_loss: 0.0307\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2769 - val_loss: 0.0245\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2964 - val_loss: 0.0512\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3142 - val_loss: 0.0298\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.029798556895526785\n",
      "Mean Absolute Error: 0.12790005064722315\n",
      "R-squared: 0.9970858391805391\n",
      "\n",
      "Fold 3:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 14s 102ms/step - loss: 37.8660 - val_loss: 27.3803\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 14.3079 - val_loss: 6.8034\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.5979 - val_loss: 5.1257\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.1092 - val_loss: 3.3641\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.2533 - val_loss: 1.4795\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.5758 - val_loss: 0.5153\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0285 - val_loss: 0.3514\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9950 - val_loss: 0.3115\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.9150 - val_loss: 0.2880\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.9426 - val_loss: 0.2655\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7364 - val_loss: 0.2549\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7084 - val_loss: 0.2331\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8121 - val_loss: 0.2255\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7537 - val_loss: 0.2438\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7586 - val_loss: 0.2132\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7374 - val_loss: 0.1915\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6668 - val_loss: 0.1834\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7865 - val_loss: 0.1878\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6724 - val_loss: 0.1595\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6741 - val_loss: 0.1497\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6525 - val_loss: 0.1419\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5989 - val_loss: 0.1386\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6109 - val_loss: 0.1405\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5786 - val_loss: 0.1310\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5594 - val_loss: 0.1258\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6100 - val_loss: 0.1299\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6305 - val_loss: 0.1326\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5823 - val_loss: 0.1370\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5251 - val_loss: 0.1040\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6153 - val_loss: 0.1244\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5475 - val_loss: 0.1117\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4968 - val_loss: 0.0985\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4818 - val_loss: 0.1065\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5180 - val_loss: 0.1048\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5848 - val_loss: 0.1095\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4597 - val_loss: 0.0918\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4721 - val_loss: 0.0921\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5319 - val_loss: 0.0893\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4723 - val_loss: 0.0888\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.5402 - val_loss: 0.0872\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5277 - val_loss: 0.0899\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4596 - val_loss: 0.0893\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4978 - val_loss: 0.0850\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4737 - val_loss: 0.0800\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4435 - val_loss: 0.0992\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4666 - val_loss: 0.0830\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4277 - val_loss: 0.0849\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4931 - val_loss: 0.1562\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5054 - val_loss: 0.1002\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4562 - val_loss: 0.0811\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4467 - val_loss: 0.0771\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4365 - val_loss: 0.0847\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4018 - val_loss: 0.0723\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4368 - val_loss: 0.0759\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4510 - val_loss: 0.1595\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4531 - val_loss: 0.0760\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4058 - val_loss: 0.0710\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4126 - val_loss: 0.0653\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3740 - val_loss: 0.0654\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4924 - val_loss: 0.0656\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3868 - val_loss: 0.0669\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4749 - val_loss: 0.0726\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3927 - val_loss: 0.0615\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3885 - val_loss: 0.0625\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4209 - val_loss: 0.0660\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4039 - val_loss: 0.0859\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3626 - val_loss: 0.0611\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3816 - val_loss: 0.0884\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4172 - val_loss: 0.0583\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4336 - val_loss: 0.0640\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4897 - val_loss: 0.0634\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3659 - val_loss: 0.0581\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3788 - val_loss: 0.0566\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3263 - val_loss: 0.0594\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3926 - val_loss: 0.0540\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3905 - val_loss: 0.0915\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.3313 - val_loss: 0.1381\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3603 - val_loss: 0.0595\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3703 - val_loss: 0.1177\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3856 - val_loss: 0.0513\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3523 - val_loss: 0.0740\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4031 - val_loss: 0.0502\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3764 - val_loss: 0.0521\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3436 - val_loss: 0.0505\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3488 - val_loss: 0.0752\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3766 - val_loss: 0.0731\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3853 - val_loss: 0.0529\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3643 - val_loss: 0.0449\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3755 - val_loss: 0.0552\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3953 - val_loss: 0.0631\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3656 - val_loss: 0.0492\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4231 - val_loss: 0.0615\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2945 - val_loss: 0.0423\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3199 - val_loss: 0.0435\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.3801 - val_loss: 0.0976\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3391 - val_loss: 0.0433\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3478 - val_loss: 0.0418\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.2912 - val_loss: 0.0403\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3073 - val_loss: 0.0660\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3621 - val_loss: 0.0394\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3343 - val_loss: 0.0702\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3808 - val_loss: 0.1185\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3510 - val_loss: 0.0847\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3124 - val_loss: 0.0380\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3266 - val_loss: 0.0401\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3136 - val_loss: 0.0763\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2978 - val_loss: 0.0514\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3707 - val_loss: 0.0448\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4104 - val_loss: 0.0577\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3030 - val_loss: 0.0636\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3060 - val_loss: 0.0448\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3040 - val_loss: 0.0415\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3290 - val_loss: 0.0457\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.3125 - val_loss: 0.0606\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2874 - val_loss: 0.0673\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3084 - val_loss: 0.0475\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.2813 - val_loss: 0.0497\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3110 - val_loss: 0.0863\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3191 - val_loss: 0.0390\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3216 - val_loss: 0.0379\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3471 - val_loss: 0.0474\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.2887 - val_loss: 0.0590\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3164 - val_loss: 0.0595\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3086 - val_loss: 0.0338\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3110 - val_loss: 0.0451\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3475 - val_loss: 0.0585\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3424 - val_loss: 0.1106\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3040 - val_loss: 0.0333\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3014 - val_loss: 0.0475\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3306 - val_loss: 0.0413\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3179 - val_loss: 0.0318\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3112 - val_loss: 0.0484\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2888 - val_loss: 0.0413\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3266 - val_loss: 0.1142\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3636 - val_loss: 0.0742\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4036 - val_loss: 0.0347\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3111 - val_loss: 0.0716\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2910 - val_loss: 0.1275\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3356 - val_loss: 0.1031\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3190 - val_loss: 0.0426\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2768 - val_loss: 0.0378\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.2970 - val_loss: 0.0530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3307 - val_loss: 0.0284\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2600 - val_loss: 0.0255\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3404 - val_loss: 0.0347\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3338 - val_loss: 0.0303\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2688 - val_loss: 0.0273\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2819 - val_loss: 0.0362\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3297 - val_loss: 0.0541\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3261 - val_loss: 0.0439\n",
      "7/7 [==============================] - 2s 4ms/step\n",
      "Mean Squared Error: 0.04387141746505711\n",
      "Mean Absolute Error: 0.16446494937536135\n",
      "R-squared: 0.995038739563782\n",
      "\n",
      "Fold 4:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 103ms/step - loss: 38.6626 - val_loss: 27.3395\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 16.1541 - val_loss: 6.4265\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 6.7949 - val_loss: 5.0134\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.2391 - val_loss: 3.4789\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.5689 - val_loss: 1.6514\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.7570 - val_loss: 0.7333\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.2176 - val_loss: 0.5574\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.0703 - val_loss: 0.5007\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.0515 - val_loss: 0.4560\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.9609 - val_loss: 0.4010\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8901 - val_loss: 0.3857\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9129 - val_loss: 0.3480\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8454 - val_loss: 0.3140\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7094 - val_loss: 0.3184\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7654 - val_loss: 0.2795\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.7080 - val_loss: 0.2641\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7952 - val_loss: 0.2692\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7396 - val_loss: 0.2169\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6913 - val_loss: 0.2152\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7485 - val_loss: 0.2835\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6967 - val_loss: 0.1775\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6308 - val_loss: 0.1779\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7342 - val_loss: 0.1633\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6507 - val_loss: 0.1550\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6344 - val_loss: 0.1487\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6017 - val_loss: 0.1391\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6190 - val_loss: 0.1427\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6536 - val_loss: 0.1336\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5997 - val_loss: 0.1234\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5844 - val_loss: 0.1839\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5938 - val_loss: 0.1124\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5028 - val_loss: 0.1132\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6087 - val_loss: 0.1031\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5605 - val_loss: 0.1458\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6567 - val_loss: 0.0988\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5747 - val_loss: 0.1187\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5530 - val_loss: 0.0900\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5235 - val_loss: 0.0884\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5368 - val_loss: 0.1183\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4852 - val_loss: 0.1107\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5053 - val_loss: 0.0840\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5126 - val_loss: 0.0777\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4431 - val_loss: 0.0764\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4928 - val_loss: 0.1074\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4825 - val_loss: 0.0847\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4892 - val_loss: 0.0833\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5300 - val_loss: 0.0687\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4776 - val_loss: 0.0706\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5031 - val_loss: 0.0875\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4395 - val_loss: 0.0679\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5159 - val_loss: 0.0734\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4318 - val_loss: 0.1450\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4854 - val_loss: 0.0988\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3742 - val_loss: 0.0627\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4275 - val_loss: 0.0593\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4763 - val_loss: 0.0687\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4052 - val_loss: 0.1131\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4516 - val_loss: 0.0566\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4067 - val_loss: 0.0612\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3831 - val_loss: 0.0605\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4342 - val_loss: 0.0661\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4676 - val_loss: 0.0734\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5070 - val_loss: 0.0522\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4499 - val_loss: 0.0558\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4337 - val_loss: 0.0662\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3879 - val_loss: 0.0955\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.3933 - val_loss: 0.0538\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.4742 - val_loss: 0.0515\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3967 - val_loss: 0.0587\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3448 - val_loss: 0.0478\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.4236 - val_loss: 0.0492\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4153 - val_loss: 0.1035\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4946 - val_loss: 0.0599\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3876 - val_loss: 0.0407\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3589 - val_loss: 0.0540\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4106 - val_loss: 0.0535\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4045 - val_loss: 0.0551\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4232 - val_loss: 0.0413\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3899 - val_loss: 0.0520\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3798 - val_loss: 0.0786\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4162 - val_loss: 0.0377\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.4055 - val_loss: 0.0774\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3889 - val_loss: 0.0389\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3398 - val_loss: 0.0487\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3800 - val_loss: 0.0582\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3518 - val_loss: 0.0392\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3661 - val_loss: 0.0826\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3585 - val_loss: 0.0381\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3403 - val_loss: 0.0375\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3516 - val_loss: 0.0449\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3753 - val_loss: 0.0395\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3378 - val_loss: 0.0512\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3540 - val_loss: 0.0979\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3398 - val_loss: 0.0409\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3560 - val_loss: 0.0312\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3515 - val_loss: 0.0381\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3667 - val_loss: 0.0630\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3666 - val_loss: 0.0809\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3660 - val_loss: 0.0552\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3146 - val_loss: 0.0718\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3481 - val_loss: 0.0494\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3364 - val_loss: 0.0280\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3403 - val_loss: 0.0372\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4061 - val_loss: 0.0384\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3212 - val_loss: 0.0352\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3225 - val_loss: 0.0301\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3026 - val_loss: 0.0405\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3283 - val_loss: 0.0323\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3536 - val_loss: 0.0283\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3114 - val_loss: 0.0247\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3067 - val_loss: 0.0395\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3131 - val_loss: 0.0334\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3132 - val_loss: 0.0257\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3348 - val_loss: 0.0358\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3225 - val_loss: 0.0302\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3499 - val_loss: 0.0212\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3052 - val_loss: 0.0402\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3400 - val_loss: 0.0371\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2925 - val_loss: 0.0255\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3278 - val_loss: 0.0233\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3165 - val_loss: 0.0380\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3429 - val_loss: 0.0280\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3658 - val_loss: 0.0424\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2713 - val_loss: 0.0215\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3081 - val_loss: 0.0346\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3438 - val_loss: 0.0461\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2952 - val_loss: 0.0234\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2952 - val_loss: 0.0337\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3359 - val_loss: 0.0722\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3036 - val_loss: 0.0306\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3277 - val_loss: 0.0473\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.2843 - val_loss: 0.0379\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3086 - val_loss: 0.0435\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3179 - val_loss: 0.0646\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2871 - val_loss: 0.0329\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3305 - val_loss: 0.0988\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3377 - val_loss: 0.0206\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3214 - val_loss: 0.0433\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3225 - val_loss: 0.0249\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3113 - val_loss: 0.0317\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2838 - val_loss: 0.0609\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3375 - val_loss: 0.1392\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3841 - val_loss: 0.0282\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3076 - val_loss: 0.0262\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3635 - val_loss: 0.0192\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3468 - val_loss: 0.0306\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3197 - val_loss: 0.0281\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3239 - val_loss: 0.0278\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3116 - val_loss: 0.0350\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3249 - val_loss: 0.0677\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.06771956500324286\n",
      "Mean Absolute Error: 0.23751057617699922\n",
      "R-squared: 0.9918254658258789\n",
      "\n",
      "Fold 5:\n",
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 14s 103ms/step - loss: 39.6735 - val_loss: 28.1396\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 17.4725 - val_loss: 5.6569\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 7.5379 - val_loss: 4.4610\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.8390 - val_loss: 3.0321\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 3.6826 - val_loss: 1.3605\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 2.0976 - val_loss: 0.4113\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.4453 - val_loss: 0.2998\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.1900 - val_loss: 0.2171\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.0241 - val_loss: 0.1784\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.1023 - val_loss: 0.1978\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.9569 - val_loss: 0.1381\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.9528 - val_loss: 0.1190\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8143 - val_loss: 0.1121\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8799 - val_loss: 0.0947\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7836 - val_loss: 0.1054\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7805 - val_loss: 0.0855\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7972 - val_loss: 0.0837\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8038 - val_loss: 0.0913\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7584 - val_loss: 0.0856\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7177 - val_loss: 0.0662\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6377 - val_loss: 0.0501\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6333 - val_loss: 0.0923\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6626 - val_loss: 0.0475\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6720 - val_loss: 0.0405\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7498 - val_loss: 0.0911\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5940 - val_loss: 0.0497\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5997 - val_loss: 0.0448\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6126 - val_loss: 0.0375\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5990 - val_loss: 0.0334\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6027 - val_loss: 0.0423\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4971 - val_loss: 0.0326\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5653 - val_loss: 0.0312\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4720 - val_loss: 0.0590\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4235 - val_loss: 0.0283\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4955 - val_loss: 0.0373\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4905 - val_loss: 0.0408\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4940 - val_loss: 0.0384\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5274 - val_loss: 0.0414\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4349 - val_loss: 0.0703\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4731 - val_loss: 0.0301\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4914 - val_loss: 0.0891\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4822 - val_loss: 0.0612\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5127 - val_loss: 0.0846\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4639 - val_loss: 0.0826\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4308 - val_loss: 0.0302\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5399 - val_loss: 0.0454\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4237 - val_loss: 0.0300\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4811 - val_loss: 0.0295\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4699 - val_loss: 0.0464\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4463 - val_loss: 0.0337\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4072 - val_loss: 0.0359\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4459 - val_loss: 0.0269\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4398 - val_loss: 0.0491\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5064 - val_loss: 0.1569\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4304 - val_loss: 0.0267\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4026 - val_loss: 0.0375\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4683 - val_loss: 0.0275\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3980 - val_loss: 0.0694\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3822 - val_loss: 0.0298\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3954 - val_loss: 0.0366\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4425 - val_loss: 0.0527\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4181 - val_loss: 0.0283\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3886 - val_loss: 0.0321\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4041 - val_loss: 0.0294\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3455 - val_loss: 0.0236\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3744 - val_loss: 0.0489\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3788 - val_loss: 0.0220\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3341 - val_loss: 0.0213\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3446 - val_loss: 0.0377\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4091 - val_loss: 0.0591\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4353 - val_loss: 0.0292\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4072 - val_loss: 0.0234\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4576 - val_loss: 0.0271\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3521 - val_loss: 0.0646\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3731 - val_loss: 0.0187\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4141 - val_loss: 0.1319\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4261 - val_loss: 0.0304\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4152 - val_loss: 0.0233\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3625 - val_loss: 0.0285\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4432 - val_loss: 0.0541\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3219 - val_loss: 0.0316\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3761 - val_loss: 0.0486\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3423 - val_loss: 0.0344\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3478 - val_loss: 0.0477\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3685 - val_loss: 0.0274\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3962 - val_loss: 0.0303\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3459 - val_loss: 0.0245\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3569 - val_loss: 0.0184\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3644 - val_loss: 0.0184\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.3582 - val_loss: 0.0281\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3464 - val_loss: 0.0541\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3929 - val_loss: 0.0368\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3229 - val_loss: 0.0186\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4097 - val_loss: 0.0193\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3533 - val_loss: 0.0236\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3901 - val_loss: 0.0366\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3677 - val_loss: 0.0183\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3595 - val_loss: 0.0253\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3352 - val_loss: 0.0211\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3484 - val_loss: 0.0244\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4001 - val_loss: 0.0381\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3871 - val_loss: 0.0234\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3195 - val_loss: 0.0171\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3760 - val_loss: 0.0459\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3278 - val_loss: 0.0177\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3517 - val_loss: 0.0376\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3456 - val_loss: 0.0244\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3223 - val_loss: 0.0680\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3521 - val_loss: 0.0147\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3545 - val_loss: 0.0366\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3343 - val_loss: 0.0097\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3458 - val_loss: 0.0125\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3193 - val_loss: 0.0115\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3451 - val_loss: 0.0186\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3213 - val_loss: 0.0124\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3219 - val_loss: 0.0227\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3476 - val_loss: 0.0233\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3245 - val_loss: 0.0403\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2891 - val_loss: 0.0176\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3462 - val_loss: 0.0294\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3476 - val_loss: 0.0333\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3909 - val_loss: 0.0240\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3975 - val_loss: 0.0277\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3311 - val_loss: 0.0135\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3307 - val_loss: 0.0222\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3539 - val_loss: 0.0137\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3331 - val_loss: 0.0758\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3911 - val_loss: 0.0340\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2922 - val_loss: 0.0122\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2943 - val_loss: 0.0451\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3736 - val_loss: 0.0190\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3383 - val_loss: 0.0356\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3430 - val_loss: 0.0696\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3620 - val_loss: 0.0162\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.3162 - val_loss: 0.0106\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2934 - val_loss: 0.0090\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2476 - val_loss: 0.0105\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3188 - val_loss: 0.0135\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2843 - val_loss: 0.0703\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.2625 - val_loss: 0.0112\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 19ms/step - loss: 0.3131 - val_loss: 0.0147\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3630 - val_loss: 0.0136\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2984 - val_loss: 0.0106\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3611 - val_loss: 0.0295\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.3376 - val_loss: 0.0231\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 1s 19ms/step - loss: 0.3318 - val_loss: 0.0163\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2638 - val_loss: 0.0237\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2878 - val_loss: 0.0160\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.2998 - val_loss: 0.0087\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.3079 - val_loss: 0.0223\n",
      "7/7 [==============================] - 2s 4ms/step\n",
      "Mean Squared Error: 0.022295607135968138\n",
      "Mean Absolute Error: 0.11887249958455859\n",
      "R-squared: 0.9968986806400677\n",
      "\n",
      "Average scores for ticker CLNE:\n",
      "Mean Squared Error: 0.04332487225458179\n",
      "Mean Absolute Error: 0.16303069069610898\n",
      "R-squared: 0.9951985120638025\n",
      "\n",
      "Cross-validation for ticker: LAZR\n",
      "Fold 1:\n",
      "Epoch 1/150\n",
      "24/24 [==============================] - 16s 112ms/step - loss: 204.6373 - val_loss: 192.4082\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 141.7604 - val_loss: 88.0880\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 63.9970 - val_loss: 56.2517\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 51.9495 - val_loss: 54.7743\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 51.1631 - val_loss: 52.2004\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 48.2498 - val_loss: 47.8645\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 42.6633 - val_loss: 40.3616\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 34.6218 - val_loss: 29.5582\n",
      "Epoch 9/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 18ms/step - loss: 26.8041 - val_loss: 20.9930\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 20.6397 - val_loss: 16.9806\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 18.0432 - val_loss: 14.4626\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 16.5019 - val_loss: 12.8393\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 14.6804 - val_loss: 11.2202\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 13.3617 - val_loss: 10.0392\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 12.3964 - val_loss: 9.0279\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 11.3681 - val_loss: 8.1346\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 10.7277 - val_loss: 7.3926\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 9.0647 - val_loss: 6.9697\n",
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 9.0494 - val_loss: 6.3599\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 8.7889 - val_loss: 5.5941\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 8.3678 - val_loss: 5.1526\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 7.3768 - val_loss: 4.7156\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 7.3097 - val_loss: 4.3431\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 7.0627 - val_loss: 4.1707\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 6.6271 - val_loss: 3.7788\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 6.3933 - val_loss: 3.3936\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.3093 - val_loss: 3.1543\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.9114 - val_loss: 2.9404\n",
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.4217 - val_loss: 2.7238\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.8103 - val_loss: 2.5882\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.8248 - val_loss: 2.4259\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.8001 - val_loss: 2.2275\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.4399 - val_loss: 2.0962\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.3162 - val_loss: 2.0046\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 3.8459 - val_loss: 1.9952\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 4.0753 - val_loss: 1.8702\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 4.1406 - val_loss: 1.6998\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 4.0270 - val_loss: 1.6280\n",
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.4998 - val_loss: 1.5227\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.6911 - val_loss: 1.4848\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.0790 - val_loss: 1.4082\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.1815 - val_loss: 1.3775\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.1213 - val_loss: 1.4599\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.5844 - val_loss: 1.4623\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.1903 - val_loss: 1.2316\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.8695 - val_loss: 1.3755\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.3521 - val_loss: 1.1436\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.7672 - val_loss: 1.2658\n",
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.7903 - val_loss: 1.1555\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6425 - val_loss: 1.1694\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.8710 - val_loss: 1.0698\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.7347 - val_loss: 1.0632\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4557 - val_loss: 0.9936\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5163 - val_loss: 0.9397\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4003 - val_loss: 0.9542\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.4298 - val_loss: 1.0853\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4129 - val_loss: 0.9013\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4030 - val_loss: 1.1260\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6411 - val_loss: 0.8543\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.8175 - val_loss: 0.8590\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5944 - val_loss: 0.8283\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2500 - val_loss: 0.7700\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6808 - val_loss: 0.7923\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2315 - val_loss: 0.8083\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9297 - val_loss: 0.7500\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4025 - val_loss: 0.9608\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9763 - val_loss: 0.8528\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2628 - val_loss: 0.7400\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.5841 - val_loss: 0.9437\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3395 - val_loss: 0.9081\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0546 - val_loss: 0.8686\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0004 - val_loss: 0.7679\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2557 - val_loss: 0.8209\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2244 - val_loss: 0.6643\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9975 - val_loss: 0.6481\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8359 - val_loss: 0.6154\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2003 - val_loss: 0.6563\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2600 - val_loss: 0.6604\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1128 - val_loss: 0.6403\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9552 - val_loss: 0.6311\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2459 - val_loss: 0.6334\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0046 - val_loss: 0.7243\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3448 - val_loss: 0.7283\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1799 - val_loss: 0.6491\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9743 - val_loss: 0.5402\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0696 - val_loss: 0.5519\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8843 - val_loss: 0.5286\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4464 - val_loss: 0.8105\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0599 - val_loss: 0.7276\n",
      "Epoch 90/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9081 - val_loss: 0.6373\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0251 - val_loss: 0.5837\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 1s 23ms/step - loss: 1.8931 - val_loss: 0.5148\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8374 - val_loss: 0.4756\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0515 - val_loss: 0.5283\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.6976 - val_loss: 0.4706\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.7022 - val_loss: 0.4595\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.9056 - val_loss: 0.6079\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8203 - val_loss: 0.4495\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 12ms/step - loss: 1.9766 - val_loss: 0.5202\n",
      "Epoch 100/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 2.0072 - val_loss: 0.4454\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 13ms/step - loss: 1.8308 - val_loss: 0.4136\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7975 - val_loss: 0.4699\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6018 - val_loss: 0.4411\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9985 - val_loss: 0.6816\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7700 - val_loss: 0.4234\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.8944 - val_loss: 0.4113\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6711 - val_loss: 0.5097\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8872 - val_loss: 0.4356\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7309 - val_loss: 0.4367\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7985 - val_loss: 0.4078\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7957 - val_loss: 0.3754\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6295 - val_loss: 0.3676\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0465 - val_loss: 0.4934\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6906 - val_loss: 0.4860\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7662 - val_loss: 0.4575\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8408 - val_loss: 0.4071\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5620 - val_loss: 0.4282\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6290 - val_loss: 0.3700\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5860 - val_loss: 0.4780\n",
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7692 - val_loss: 0.4342\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6936 - val_loss: 0.3558\n",
      "Epoch 122/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3344 - val_loss: 0.3103\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.5488 - val_loss: 0.3518\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8650 - val_loss: 0.3353\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8297 - val_loss: 0.6293\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7881 - val_loss: 0.4081\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7318 - val_loss: 0.2971\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8196 - val_loss: 0.3584\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6497 - val_loss: 0.3655\n",
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8003 - val_loss: 0.4249\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6648 - val_loss: 0.3703\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8186 - val_loss: 0.3178\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7868 - val_loss: 0.2985\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7671 - val_loss: 0.3152\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7141 - val_loss: 0.3425\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7288 - val_loss: 0.3054\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6806 - val_loss: 0.2658\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7599 - val_loss: 0.3032\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.4921 - val_loss: 0.3358\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8545 - val_loss: 0.3327\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5833 - val_loss: 0.4484\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0505 - val_loss: 0.3212\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5194 - val_loss: 0.2643\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7908 - val_loss: 0.2961\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6833 - val_loss: 0.3154\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5503 - val_loss: 0.4542\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5831 - val_loss: 0.2720\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.3248 - val_loss: 0.2729\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5907 - val_loss: 0.3195\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7127 - val_loss: 0.2989\n",
      "6/6 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.2988976592291636\n",
      "Mean Absolute Error: 0.3570815213024617\n",
      "R-squared: 0.9950845813683676\n",
      "\n",
      "Fold 2:\n",
      "Epoch 1/150\n",
      "24/24 [==============================] - 14s 109ms/step - loss: 203.7823 - val_loss: 187.8398\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 140.7468 - val_loss: 84.2413\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 64.8712 - val_loss: 49.7198\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 53.8600 - val_loss: 47.4817\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 52.6663 - val_loss: 45.3759\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 50.8211 - val_loss: 42.0403\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 44.6412 - val_loss: 36.2398\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 37.3134 - val_loss: 27.8109\n",
      "Epoch 9/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 27.7325 - val_loss: 20.2179\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 21.5075 - val_loss: 16.2713\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 18.2292 - val_loss: 13.8989\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 15.9718 - val_loss: 12.1955\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 14.3106 - val_loss: 10.8684\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 13.6737 - val_loss: 9.9442\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 12.0206 - val_loss: 8.8861\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 10.6621 - val_loss: 8.1492\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 10.0295 - val_loss: 7.3519\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 9.5830 - val_loss: 6.7418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 8.6250 - val_loss: 6.2088\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 8.9421 - val_loss: 5.6885\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 8.2432 - val_loss: 5.2258\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 7.7876 - val_loss: 4.9779\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 7.5311 - val_loss: 4.4433\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 6.9008 - val_loss: 4.1359\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 6.3461 - val_loss: 3.8073\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 6.2374 - val_loss: 3.5290\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.7709 - val_loss: 3.2995\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 5.5882 - val_loss: 3.1810\n",
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.4045 - val_loss: 2.9385\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 4.5807 - val_loss: 2.6681\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 4.5444 - val_loss: 2.4900\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.4706 - val_loss: 2.3103\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.2151 - val_loss: 2.1671\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.0685 - val_loss: 2.0288\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.7965 - val_loss: 1.9219\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.1669 - val_loss: 1.8330\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.7792 - val_loss: 1.7875\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.7085 - val_loss: 1.6790\n",
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.7174 - val_loss: 1.5484\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.4298 - val_loss: 1.4050\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.6602 - val_loss: 1.3321\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.4617 - val_loss: 1.2686\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.2459 - val_loss: 1.2507\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.9127 - val_loss: 1.4041\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.8113 - val_loss: 1.0865\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.0434 - val_loss: 1.3201\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.9722 - val_loss: 1.1202\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.0641 - val_loss: 1.0064\n",
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.7369 - val_loss: 0.9400\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.5545 - val_loss: 0.8942\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.6661 - val_loss: 0.9247\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.6673 - val_loss: 0.8350\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.0606 - val_loss: 0.8497\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3877 - val_loss: 0.8279\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3415 - val_loss: 0.8898\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.7597 - val_loss: 0.7756\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.6058 - val_loss: 0.7111\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2675 - val_loss: 0.7157\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.5384 - val_loss: 0.6410\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.5411 - val_loss: 0.6076\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0299 - val_loss: 0.5974\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.4715 - val_loss: 0.5935\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2442 - val_loss: 0.7418\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.4065 - val_loss: 0.6110\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.6309 - val_loss: 0.6440\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.4589 - val_loss: 0.6210\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3196 - val_loss: 0.7195\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.7228 - val_loss: 0.7742\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2834 - val_loss: 0.5463\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.2681 - val_loss: 0.5633\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2839 - val_loss: 0.4873\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0489 - val_loss: 0.4482\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.2848 - val_loss: 0.4319\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2557 - val_loss: 0.4607\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0117 - val_loss: 0.4708\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.3012 - val_loss: 0.4055\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0426 - val_loss: 0.4012\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.6662 - val_loss: 0.3828\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.4796 - val_loss: 0.4611\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9603 - val_loss: 0.4784\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0783 - val_loss: 0.4072\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0084 - val_loss: 0.3573\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0508 - val_loss: 0.5704\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.2705 - val_loss: 0.3432\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2242 - val_loss: 0.4207\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.0645 - val_loss: 0.5691\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.4628 - val_loss: 0.3035\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0008 - val_loss: 0.3750\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0211 - val_loss: 0.3503\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.1507 - val_loss: 0.2795\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0404 - val_loss: 0.4501\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1644 - val_loss: 0.3163\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3007 - val_loss: 0.2781\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9925 - val_loss: 0.3035\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9536 - val_loss: 0.4227\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3496 - val_loss: 0.3010\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6976 - val_loss: 0.2489\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9952 - val_loss: 0.2329\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0519 - val_loss: 0.2678\n",
      "Epoch 100/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1209 - val_loss: 0.2531\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9808 - val_loss: 0.3008\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9347 - val_loss: 0.2749\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0445 - val_loss: 0.3386\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9580 - val_loss: 0.2401\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9894 - val_loss: 0.2421\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8988 - val_loss: 0.2558\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9203 - val_loss: 0.2524\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0045 - val_loss: 0.3089\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9400 - val_loss: 0.2446\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0461 - val_loss: 0.2262\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7723 - val_loss: 0.2655\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.7560 - val_loss: 0.1486\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9651 - val_loss: 0.1744\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7291 - val_loss: 0.1577\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8143 - val_loss: 0.2100\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9330 - val_loss: 0.2170\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7949 - val_loss: 0.2276\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.7423 - val_loss: 0.1385\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7693 - val_loss: 0.3335\n",
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6469 - val_loss: 0.3785\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8834 - val_loss: 0.1542\n",
      "Epoch 122/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7080 - val_loss: 0.3460\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8294 - val_loss: 0.2733\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6635 - val_loss: 0.1685\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7901 - val_loss: 0.1402\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.7664 - val_loss: 0.1515\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6245 - val_loss: 0.1641\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6057 - val_loss: 0.1197\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.3769 - val_loss: 0.1665\n",
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5601 - val_loss: 0.1717\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6670 - val_loss: 0.1075\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.9183 - val_loss: 0.1292\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.4851 - val_loss: 0.2691\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8593 - val_loss: 0.1442\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6720 - val_loss: 0.2497\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6447 - val_loss: 0.1197\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5610 - val_loss: 0.1332\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5184 - val_loss: 0.1058\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6948 - val_loss: 0.2148\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6668 - val_loss: 0.1119\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7690 - val_loss: 0.1296\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6540 - val_loss: 0.1111\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6074 - val_loss: 0.1120\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6336 - val_loss: 0.0992\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6023 - val_loss: 0.1968\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6016 - val_loss: 0.0930\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6041 - val_loss: 0.1472\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7068 - val_loss: 0.1115\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8202 - val_loss: 0.3619\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8082 - val_loss: 0.0800\n",
      "6/6 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.08003344028604183\n",
      "Mean Absolute Error: 0.19349924681698463\n",
      "R-squared: 0.9984622140674881\n",
      "\n",
      "Fold 3:\n",
      "Epoch 1/150\n",
      "24/24 [==============================] - 16s 111ms/step - loss: 208.9297 - val_loss: 191.0685\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 156.5039 - val_loss: 93.0736\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 70.6532 - val_loss: 48.5546\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 56.1161 - val_loss: 45.8523\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 54.5040 - val_loss: 43.9343\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 52.0782 - val_loss: 40.3132\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 46.3378 - val_loss: 34.4665\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 37.8061 - val_loss: 25.5830\n",
      "Epoch 9/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 28.8449 - val_loss: 18.3966\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 22.5408 - val_loss: 14.9387\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 20.4847 - val_loss: 12.8607\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 17.0919 - val_loss: 11.3944\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 15.1149 - val_loss: 10.0951\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 14.3119 - val_loss: 9.1317\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 13.3702 - val_loss: 8.1831\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 11.6716 - val_loss: 7.4446\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 11.4915 - val_loss: 6.7493\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 10.7467 - val_loss: 6.1999\n",
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 10.0794 - val_loss: 5.6161\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 10.0059 - val_loss: 5.1942\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 8.7433 - val_loss: 4.8128\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 7.9680 - val_loss: 4.4060\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 7.7281 - val_loss: 4.0673\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 21ms/step - loss: 7.0161 - val_loss: 3.8294\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 6.3256 - val_loss: 3.4641\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 6.6388 - val_loss: 3.2373\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 6.0555 - val_loss: 3.0096\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.3991 - val_loss: 2.9334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.4652 - val_loss: 2.7290\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.6133 - val_loss: 2.4312\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.8412 - val_loss: 2.3041\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 5.0256 - val_loss: 2.1535\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.5558 - val_loss: 1.9817\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.6603 - val_loss: 1.9823\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.2266 - val_loss: 1.7539\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.4409 - val_loss: 1.7161\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.7197 - val_loss: 1.5746\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.1943 - val_loss: 1.4738\n",
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.7832 - val_loss: 1.3797\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.3584 - val_loss: 1.3520\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.1750 - val_loss: 1.2135\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.5254 - val_loss: 1.2589\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.7265 - val_loss: 1.1058\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.7140 - val_loss: 1.1082\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.2856 - val_loss: 1.2143\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.1237 - val_loss: 0.9911\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.1635 - val_loss: 0.9437\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.9792 - val_loss: 0.9440\n",
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.8600 - val_loss: 0.8164\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.1221 - val_loss: 0.8136\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.8940 - val_loss: 0.7890\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.6851 - val_loss: 0.7343\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.9318 - val_loss: 0.7788\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.5641 - val_loss: 0.7535\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.8330 - val_loss: 0.7090\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.8444 - val_loss: 0.6575\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3153 - val_loss: 0.6755\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.5670 - val_loss: 0.6913\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.5132 - val_loss: 0.6376\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.5009 - val_loss: 0.6012\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3250 - val_loss: 0.5765\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3884 - val_loss: 0.6006\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.3419 - val_loss: 0.5767\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3709 - val_loss: 0.5302\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2511 - val_loss: 0.5003\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.8534 - val_loss: 0.4782\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2032 - val_loss: 0.5340\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.2720 - val_loss: 0.4559\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.4537 - val_loss: 0.4582\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4259 - val_loss: 0.4915\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4212 - val_loss: 0.7852\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3599 - val_loss: 0.5085\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.6528 - val_loss: 0.5717\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.2061 - val_loss: 0.4507\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0257 - val_loss: 0.4751\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0460 - val_loss: 0.4153\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0578 - val_loss: 0.3805\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.4892 - val_loss: 0.4577\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0526 - val_loss: 0.3595\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2323 - val_loss: 0.4899\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1745 - val_loss: 0.3535\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3409 - val_loss: 0.6325\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.4157 - val_loss: 0.4851\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1647 - val_loss: 0.3576\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1272 - val_loss: 0.3550\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3433 - val_loss: 0.3432\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0243 - val_loss: 0.3888\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2770 - val_loss: 0.3195\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7746 - val_loss: 0.3069\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0275 - val_loss: 0.2955\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1574 - val_loss: 0.4845\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0499 - val_loss: 0.2876\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0303 - val_loss: 0.4125\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0475 - val_loss: 0.2530\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8659 - val_loss: 0.2710\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9363 - val_loss: 0.2622\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2851 - val_loss: 0.2703\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7283 - val_loss: 0.2480\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0699 - val_loss: 0.2849\n",
      "Epoch 100/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2270 - val_loss: 0.3725\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9271 - val_loss: 0.3284\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.0776 - val_loss: 0.2298\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8988 - val_loss: 0.2319\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8162 - val_loss: 0.2501\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9938 - val_loss: 0.2160\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9398 - val_loss: 0.2275\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8238 - val_loss: 0.3832\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7254 - val_loss: 0.2768\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 1.6555 - val_loss: 0.2419\n",
      "Epoch 110/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8460 - val_loss: 0.1968\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1256 - val_loss: 0.2445\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9920 - val_loss: 0.2908\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1978 - val_loss: 0.4620\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9750 - val_loss: 0.1851\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5238 - val_loss: 0.1828\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9705 - val_loss: 0.5130\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9737 - val_loss: 0.3736\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7409 - val_loss: 0.1984\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7651 - val_loss: 0.2024\n",
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5672 - val_loss: 0.1961\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5465 - val_loss: 0.2520\n",
      "Epoch 122/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8127 - val_loss: 0.1610\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8915 - val_loss: 0.3211\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6612 - val_loss: 0.1761\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6232 - val_loss: 0.1616\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8160 - val_loss: 0.2722\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5561 - val_loss: 0.1437\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7456 - val_loss: 0.1780\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7641 - val_loss: 0.1733\n",
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8235 - val_loss: 0.1473\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6231 - val_loss: 0.1757\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7218 - val_loss: 0.2405\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7605 - val_loss: 0.1743\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9382 - val_loss: 0.1862\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8002 - val_loss: 0.1553\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8080 - val_loss: 0.1809\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7149 - val_loss: 0.2051\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0188 - val_loss: 0.1577\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6669 - val_loss: 0.1392\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5227 - val_loss: 0.1807\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.7658 - val_loss: 0.1798\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7963 - val_loss: 0.1502\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6311 - val_loss: 0.1859\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6462 - val_loss: 0.1491\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7197 - val_loss: 0.1666\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7099 - val_loss: 0.1605\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6449 - val_loss: 0.1284\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5334 - val_loss: 0.2168\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7426 - val_loss: 0.1556\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7859 - val_loss: 0.1813\n",
      "6/6 [==============================] - 2s 4ms/step\n",
      "Mean Squared Error: 0.18131841479790053\n",
      "Mean Absolute Error: 0.3322652172667819\n",
      "R-squared: 0.9963386110467882\n",
      "\n",
      "Fold 4:\n",
      "Epoch 1/150\n",
      "24/24 [==============================] - 14s 108ms/step - loss: 205.3045 - val_loss: 187.3269\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 142.9918 - val_loss: 94.2677\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 67.9665 - val_loss: 66.2919\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 54.3063 - val_loss: 64.8722\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 53.3257 - val_loss: 64.3599\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 53.3860 - val_loss: 62.8268\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 49.8207 - val_loss: 59.8720\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 47.6738 - val_loss: 54.0111\n",
      "Epoch 9/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 41.6227 - val_loss: 42.9566\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 32.0504 - val_loss: 32.4636\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 24.9823 - val_loss: 26.1474\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 20.3642 - val_loss: 22.7391\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 17.9320 - val_loss: 20.3709\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 16.5705 - val_loss: 18.5915\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 13.7270 - val_loss: 16.7680\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 12.5085 - val_loss: 15.3876\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 13.2010 - val_loss: 14.0504\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 10.8941 - val_loss: 13.0219\n",
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 10.2076 - val_loss: 12.0442\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 9.7005 - val_loss: 11.1432\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 9.0492 - val_loss: 10.4534\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 8.5322 - val_loss: 9.6711\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 7.6416 - val_loss: 8.9593\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 7.3651 - val_loss: 8.4198\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 7.8216 - val_loss: 7.9093\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 6.4560 - val_loss: 7.4261\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 6.3748 - val_loss: 6.9178\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.5076 - val_loss: 6.4875\n",
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.5715 - val_loss: 6.1632\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.9638 - val_loss: 5.7870\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.9986 - val_loss: 5.5665\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.0172 - val_loss: 5.1946\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 5.0013 - val_loss: 4.9798\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.0776 - val_loss: 4.7079\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.3484 - val_loss: 4.4972\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.5110 - val_loss: 4.2492\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.6532 - val_loss: 4.0468\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.8034 - val_loss: 3.8867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.8154 - val_loss: 3.7121\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.8585 - val_loss: 3.5846\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.5574 - val_loss: 3.4459\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.4605 - val_loss: 3.2612\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.2217 - val_loss: 3.1792\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.5409 - val_loss: 3.0394\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.2222 - val_loss: 2.9281\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.2198 - val_loss: 2.8927\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.3778 - val_loss: 2.8013\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 1s 52ms/step - loss: 3.2782 - val_loss: 2.6440\n",
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.9984 - val_loss: 2.7227\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.7281 - val_loss: 2.5858\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.9611 - val_loss: 2.8026\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 3.1160 - val_loss: 2.6984\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5941 - val_loss: 2.4965\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.9948 - val_loss: 2.4425\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3513 - val_loss: 2.2111\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.5876 - val_loss: 2.1327\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.3391 - val_loss: 2.1150\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 3.1359 - val_loss: 2.0066\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.3800 - val_loss: 1.9282\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.2103 - val_loss: 1.8847\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.5089 - val_loss: 1.8231\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 0s 20ms/step - loss: 2.3515 - val_loss: 1.8438\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1556 - val_loss: 1.7987\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3086 - val_loss: 1.7447\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3440 - val_loss: 1.7886\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3349 - val_loss: 1.6396\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1717 - val_loss: 1.5851\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3284 - val_loss: 1.5533\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1224 - val_loss: 1.5506\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3018 - val_loss: 1.5596\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1429 - val_loss: 1.5141\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1716 - val_loss: 1.4743\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.5290 - val_loss: 1.5224\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8508 - val_loss: 1.4363\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.0723 - val_loss: 1.4198\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.4329 - val_loss: 1.3612\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1524 - val_loss: 1.3026\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2132 - val_loss: 1.4606\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1025 - val_loss: 1.2617\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1431 - val_loss: 1.2420\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.2904 - val_loss: 1.2430\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0329 - val_loss: 1.3185\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9594 - val_loss: 1.3497\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1551 - val_loss: 1.3462\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8259 - val_loss: 1.1937\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8982 - val_loss: 1.4223\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8987 - val_loss: 1.1064\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7551 - val_loss: 1.1089\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7501 - val_loss: 1.2328\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0912 - val_loss: 1.0706\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2442 - val_loss: 1.0793\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7880 - val_loss: 1.0427\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9590 - val_loss: 1.0031\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7423 - val_loss: 1.0080\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8676 - val_loss: 0.9721\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9630 - val_loss: 1.0022\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7969 - val_loss: 0.9715\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7617 - val_loss: 1.0176\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9623 - val_loss: 0.8861\n",
      "Epoch 100/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6492 - val_loss: 0.9054\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5444 - val_loss: 0.9584\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8372 - val_loss: 0.9810\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.9100 - val_loss: 1.0347\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9370 - val_loss: 0.8500\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8998 - val_loss: 1.0543\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0045 - val_loss: 0.8194\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9910 - val_loss: 1.0082\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9015 - val_loss: 0.8564\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5344 - val_loss: 0.8837\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9911 - val_loss: 0.8047\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7476 - val_loss: 0.8409\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0885 - val_loss: 0.7948\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7916 - val_loss: 0.7170\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8463 - val_loss: 0.8303\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5574 - val_loss: 0.7693\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8168 - val_loss: 0.7594\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7104 - val_loss: 0.7355\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7975 - val_loss: 0.7103\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6927 - val_loss: 0.6700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6110 - val_loss: 0.7100\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7684 - val_loss: 0.6538\n",
      "Epoch 122/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8477 - val_loss: 0.7807\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7339 - val_loss: 0.7371\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7315 - val_loss: 0.6576\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5225 - val_loss: 0.7442\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8649 - val_loss: 0.6046\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7522 - val_loss: 0.6712\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6295 - val_loss: 0.5762\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7618 - val_loss: 0.5908\n",
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8311 - val_loss: 0.5787\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7980 - val_loss: 0.5600\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.4706 - val_loss: 0.6358\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7495 - val_loss: 0.5692\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6405 - val_loss: 0.5872\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.7297 - val_loss: 0.5185\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.4682 - val_loss: 0.5747\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5757 - val_loss: 0.5024\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.5731 - val_loss: 0.5115\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7919 - val_loss: 0.8019\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7243 - val_loss: 0.5313\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7541 - val_loss: 0.6670\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.4924 - val_loss: 0.6072\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6137 - val_loss: 0.5384\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.6897 - val_loss: 0.5465\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8531 - val_loss: 0.5118\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6336 - val_loss: 0.4520\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.5697 - val_loss: 0.5595\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6349 - val_loss: 0.4668\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.5965 - val_loss: 0.6504\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9197 - val_loss: 0.6525\n",
      "6/6 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.6524712707496546\n",
      "Mean Absolute Error: 0.4852105472724475\n",
      "R-squared: 0.9903549713366419\n",
      "\n",
      "Fold 5:\n",
      "Epoch 1/150\n",
      "24/24 [==============================] - 15s 113ms/step - loss: 208.1940 - val_loss: 188.9564\n",
      "Epoch 2/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 157.2496 - val_loss: 99.9331\n",
      "Epoch 3/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 76.8502 - val_loss: 57.1857\n",
      "Epoch 4/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 58.2044 - val_loss: 52.8317\n",
      "Epoch 5/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 55.7976 - val_loss: 51.5713\n",
      "Epoch 6/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 53.0672 - val_loss: 49.6687\n",
      "Epoch 7/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 50.9242 - val_loss: 45.7150\n",
      "Epoch 8/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 44.8561 - val_loss: 38.7809\n",
      "Epoch 9/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 35.9621 - val_loss: 28.9807\n",
      "Epoch 10/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 26.6448 - val_loss: 22.4370\n",
      "Epoch 11/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 22.0412 - val_loss: 19.0541\n",
      "Epoch 12/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 19.2550 - val_loss: 16.7528\n",
      "Epoch 13/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 17.0413 - val_loss: 15.2144\n",
      "Epoch 14/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 15.3208 - val_loss: 13.5782\n",
      "Epoch 15/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 14.0871 - val_loss: 12.1960\n",
      "Epoch 16/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 12.8813 - val_loss: 11.1474\n",
      "Epoch 17/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 11.4714 - val_loss: 10.2292\n",
      "Epoch 18/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 11.9792 - val_loss: 9.2906\n",
      "Epoch 19/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 10.4110 - val_loss: 8.6336\n",
      "Epoch 20/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 9.8850 - val_loss: 7.7959\n",
      "Epoch 21/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 9.2279 - val_loss: 7.2048\n",
      "Epoch 22/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 8.0811 - val_loss: 6.6352\n",
      "Epoch 23/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 7.9583 - val_loss: 6.1277\n",
      "Epoch 24/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 6.9657 - val_loss: 5.6633\n",
      "Epoch 25/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 6.9721 - val_loss: 5.3214\n",
      "Epoch 26/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 6.5709 - val_loss: 4.8693\n",
      "Epoch 27/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 6.3491 - val_loss: 4.4888\n",
      "Epoch 28/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.8318 - val_loss: 4.2575\n",
      "Epoch 29/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.4144 - val_loss: 3.9229\n",
      "Epoch 30/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 5.2359 - val_loss: 3.6913\n",
      "Epoch 31/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 4.8275 - val_loss: 3.4522\n",
      "Epoch 32/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.4642 - val_loss: 3.2205\n",
      "Epoch 33/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 5.2179 - val_loss: 3.1472\n",
      "Epoch 34/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 5.1642 - val_loss: 2.8406\n",
      "Epoch 35/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.4056 - val_loss: 2.6357\n",
      "Epoch 36/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 4.4215 - val_loss: 2.6318\n",
      "Epoch 37/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 4.7424 - val_loss: 2.3546\n",
      "Epoch 38/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.8300 - val_loss: 2.3035\n",
      "Epoch 39/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.8863 - val_loss: 2.1426\n",
      "Epoch 40/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 4.1481 - val_loss: 1.9802\n",
      "Epoch 41/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.6575 - val_loss: 1.9085\n",
      "Epoch 42/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.5875 - val_loss: 1.8237\n",
      "Epoch 43/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.6876 - val_loss: 1.6828\n",
      "Epoch 44/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.3830 - val_loss: 1.6876\n",
      "Epoch 45/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.7305 - val_loss: 1.8134\n",
      "Epoch 46/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.2766 - val_loss: 1.5764\n",
      "Epoch 47/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 3.4499 - val_loss: 1.5326\n",
      "Epoch 48/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.4828 - val_loss: 1.4779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.8475 - val_loss: 1.3353\n",
      "Epoch 50/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.8216 - val_loss: 1.2279\n",
      "Epoch 51/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.9624 - val_loss: 1.2590\n",
      "Epoch 52/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.1641 - val_loss: 1.3189\n",
      "Epoch 53/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.8124 - val_loss: 1.3203\n",
      "Epoch 54/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.0976 - val_loss: 1.0968\n",
      "Epoch 55/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.7176 - val_loss: 1.2692\n",
      "Epoch 56/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.7258 - val_loss: 1.0876\n",
      "Epoch 57/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.8366 - val_loss: 1.0081\n",
      "Epoch 58/150\n",
      "24/24 [==============================] - 0s 15ms/step - loss: 2.3591 - val_loss: 0.9563\n",
      "Epoch 59/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 3.0067 - val_loss: 1.1158\n",
      "Epoch 60/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.4614 - val_loss: 0.9017\n",
      "Epoch 61/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.4174 - val_loss: 0.8593\n",
      "Epoch 62/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 3.0072 - val_loss: 0.8878\n",
      "Epoch 63/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.5400 - val_loss: 0.8589\n",
      "Epoch 64/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3260 - val_loss: 0.8500\n",
      "Epoch 65/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 2.3437 - val_loss: 0.7897\n",
      "Epoch 66/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.1718 - val_loss: 0.7674\n",
      "Epoch 67/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.3766 - val_loss: 0.8459\n",
      "Epoch 68/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 2.7576 - val_loss: 0.7712\n",
      "Epoch 69/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.3665 - val_loss: 0.7283\n",
      "Epoch 70/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3462 - val_loss: 0.6889\n",
      "Epoch 71/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.5355 - val_loss: 0.6774\n",
      "Epoch 72/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.6664 - val_loss: 0.7123\n",
      "Epoch 73/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2351 - val_loss: 0.7004\n",
      "Epoch 74/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0381 - val_loss: 0.6446\n",
      "Epoch 75/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1235 - val_loss: 0.9787\n",
      "Epoch 76/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1556 - val_loss: 0.6443\n",
      "Epoch 77/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1986 - val_loss: 0.6580\n",
      "Epoch 78/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9856 - val_loss: 0.6276\n",
      "Epoch 79/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9638 - val_loss: 0.9041\n",
      "Epoch 80/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2089 - val_loss: 0.5638\n",
      "Epoch 81/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3679 - val_loss: 0.5693\n",
      "Epoch 82/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1875 - val_loss: 0.5641\n",
      "Epoch 83/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.2906 - val_loss: 0.5451\n",
      "Epoch 84/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8039 - val_loss: 0.5511\n",
      "Epoch 85/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.3465 - val_loss: 0.5427\n",
      "Epoch 86/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9451 - val_loss: 0.6197\n",
      "Epoch 87/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9523 - val_loss: 0.5364\n",
      "Epoch 88/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.5703 - val_loss: 0.6935\n",
      "Epoch 89/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9678 - val_loss: 0.5740\n",
      "Epoch 90/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8395 - val_loss: 0.5473\n",
      "Epoch 91/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9947 - val_loss: 0.6411\n",
      "Epoch 92/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0137 - val_loss: 0.5582\n",
      "Epoch 93/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9757 - val_loss: 0.5226\n",
      "Epoch 94/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9945 - val_loss: 0.4969\n",
      "Epoch 95/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9523 - val_loss: 0.4733\n",
      "Epoch 96/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0765 - val_loss: 0.5008\n",
      "Epoch 97/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0032 - val_loss: 0.4471\n",
      "Epoch 98/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1278 - val_loss: 0.4403\n",
      "Epoch 99/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7857 - val_loss: 0.4249\n",
      "Epoch 100/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.0247 - val_loss: 0.4897\n",
      "Epoch 101/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9599 - val_loss: 0.4922\n",
      "Epoch 102/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1864 - val_loss: 0.4541\n",
      "Epoch 103/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6138 - val_loss: 0.4716\n",
      "Epoch 104/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 2.1064 - val_loss: 0.3998\n",
      "Epoch 105/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7422 - val_loss: 0.3761\n",
      "Epoch 106/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 2.1043 - val_loss: 0.3925\n",
      "Epoch 107/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6394 - val_loss: 0.6224\n",
      "Epoch 108/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9136 - val_loss: 0.4242\n",
      "Epoch 109/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9987 - val_loss: 0.4631\n",
      "Epoch 110/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8181 - val_loss: 0.3484\n",
      "Epoch 111/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7436 - val_loss: 0.3781\n",
      "Epoch 112/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8285 - val_loss: 0.3358\n",
      "Epoch 113/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8877 - val_loss: 0.3360\n",
      "Epoch 114/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7087 - val_loss: 0.4256\n",
      "Epoch 115/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7279 - val_loss: 0.3228\n",
      "Epoch 116/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8352 - val_loss: 0.5129\n",
      "Epoch 117/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9122 - val_loss: 0.3224\n",
      "Epoch 118/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8777 - val_loss: 0.3279\n",
      "Epoch 119/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6633 - val_loss: 0.3128\n",
      "Epoch 120/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8293 - val_loss: 0.3378\n",
      "Epoch 121/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9057 - val_loss: 0.3231\n",
      "Epoch 122/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8773 - val_loss: 0.3266\n",
      "Epoch 123/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7806 - val_loss: 0.3275\n",
      "Epoch 124/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.8970 - val_loss: 0.2984\n",
      "Epoch 125/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.5411 - val_loss: 0.4197\n",
      "Epoch 126/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7423 - val_loss: 0.4262\n",
      "Epoch 127/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6989 - val_loss: 0.2754\n",
      "Epoch 128/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.5892 - val_loss: 0.3068\n",
      "Epoch 129/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9407 - val_loss: 0.2808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7161 - val_loss: 0.2714\n",
      "Epoch 131/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.9475 - val_loss: 0.3213\n",
      "Epoch 132/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.5345 - val_loss: 0.3466\n",
      "Epoch 133/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.4050 - val_loss: 0.4737\n",
      "Epoch 134/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.6504 - val_loss: 0.3341\n",
      "Epoch 135/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.4979 - val_loss: 0.2476\n",
      "Epoch 136/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.4610 - val_loss: 0.3020\n",
      "Epoch 137/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6338 - val_loss: 0.2839\n",
      "Epoch 138/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7873 - val_loss: 0.2865\n",
      "Epoch 139/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.9673 - val_loss: 0.5476\n",
      "Epoch 140/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.7882 - val_loss: 0.2541\n",
      "Epoch 141/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6783 - val_loss: 0.3052\n",
      "Epoch 142/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.6144 - val_loss: 0.2530\n",
      "Epoch 143/150\n",
      "24/24 [==============================] - 0s 17ms/step - loss: 1.8634 - val_loss: 0.3685\n",
      "Epoch 144/150\n",
      "24/24 [==============================] - 0s 16ms/step - loss: 1.7727 - val_loss: 0.3081\n",
      "Epoch 145/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.4349 - val_loss: 0.2354\n",
      "Epoch 146/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.5633 - val_loss: 0.2755\n",
      "Epoch 147/150\n",
      "24/24 [==============================] - 0s 19ms/step - loss: 1.5621 - val_loss: 0.3012\n",
      "Epoch 148/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.6879 - val_loss: 0.3196\n",
      "Epoch 149/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.8632 - val_loss: 0.3736\n",
      "Epoch 150/150\n",
      "24/24 [==============================] - 0s 18ms/step - loss: 1.7131 - val_loss: 0.2258\n",
      "6/6 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.22581932460406814\n",
      "Mean Absolute Error: 0.25452393511827076\n",
      "R-squared: 0.995883970289152\n",
      "\n",
      "Average scores for ticker LAZR:\n",
      "Mean Squared Error: 0.28770802193336575\n",
      "Mean Absolute Error: 0.32451609355538935\n",
      "R-squared: 0.9952248696216875\n",
      "\n",
      "Cross-validation for ticker: AMWL\n",
      "Fold 1:\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 15s 126ms/step - loss: 161.4246 - val_loss: 154.4100\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 128.7657 - val_loss: 100.5243\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 87.8728 - val_loss: 78.7852\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 76.7459 - val_loss: 71.2518\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 65.5811 - val_loss: 57.6189\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 51.3491 - val_loss: 41.4439\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 37.8430 - val_loss: 30.4391\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 30.1403 - val_loss: 25.2110\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 26.2838 - val_loss: 21.8029\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 22.9907 - val_loss: 19.0343\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 22.0886 - val_loss: 16.4763\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 19.1547 - val_loss: 14.5951\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 16.6628 - val_loss: 12.7317\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 15.2576 - val_loss: 11.0596\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 14.7154 - val_loss: 9.7270\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 12.8007 - val_loss: 8.4987\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 12.0274 - val_loss: 7.4494\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 11.0629 - val_loss: 6.4390\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 9.8501 - val_loss: 5.8427\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 9.6151 - val_loss: 5.0045\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 8.3443 - val_loss: 4.3511\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 8.1183 - val_loss: 3.7642\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 6.4894 - val_loss: 3.3320\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 7.0232 - val_loss: 3.0985\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 5.6572 - val_loss: 2.8163\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 6.0888 - val_loss: 2.2839\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 5.6833 - val_loss: 2.2078\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 5.9326 - val_loss: 1.8874\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 5.2170 - val_loss: 1.8783\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 4.6419 - val_loss: 1.5980\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 4.6566 - val_loss: 1.3763\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 4.2030 - val_loss: 1.2720\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 3.7182 - val_loss: 1.1824\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.9047 - val_loss: 1.3584\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.4806 - val_loss: 1.0821\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.5345 - val_loss: 1.0281\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.6625 - val_loss: 0.9759\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.0764 - val_loss: 0.9978\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.2377 - val_loss: 0.9214\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.0273 - val_loss: 0.9092\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.4429 - val_loss: 0.9512\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6870 - val_loss: 0.9339\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.5310 - val_loss: 0.8650\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.1083 - val_loss: 0.8104\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.1979 - val_loss: 0.8029\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8310 - val_loss: 0.8109\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.0004 - val_loss: 1.0393\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.7930 - val_loss: 0.8500\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4421 - val_loss: 0.8233\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.1617 - val_loss: 0.7386\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8278 - val_loss: 0.8099\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4513 - val_loss: 0.7057\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8005 - val_loss: 0.7517\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4720 - val_loss: 0.7814\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.6902 - val_loss: 0.8920\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 2.6022 - val_loss: 0.7596\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.8376 - val_loss: 0.8503\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.6890 - val_loss: 0.7094\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4091 - val_loss: 0.7709\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.7410 - val_loss: 0.7031\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0514 - val_loss: 0.6125\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3654 - val_loss: 0.7229\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4856 - val_loss: 0.7255\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5679 - val_loss: 0.5794\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1290 - val_loss: 0.6220\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9802 - val_loss: 0.7096\n",
      "Epoch 67/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3311 - val_loss: 0.5838\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4255 - val_loss: 0.5632\n",
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6303 - val_loss: 0.6070\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0300 - val_loss: 0.5793\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0702 - val_loss: 0.7001\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7523 - val_loss: 0.6997\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.8787 - val_loss: 0.4917\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0949 - val_loss: 0.4981\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7550 - val_loss: 0.4925\n",
      "Epoch 76/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1847 - val_loss: 0.4479\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1246 - val_loss: 0.4860\n",
      "Epoch 78/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2991 - val_loss: 0.4541\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1156 - val_loss: 0.5454\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8361 - val_loss: 0.5459\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7208 - val_loss: 0.5876\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4787 - val_loss: 0.6426\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9436 - val_loss: 0.3712\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.3254 - val_loss: 0.6024\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8841 - val_loss: 0.4769\n",
      "Epoch 86/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8371 - val_loss: 0.5856\n",
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1566 - val_loss: 0.4257\n",
      "Epoch 88/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0919 - val_loss: 0.4379\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1955 - val_loss: 0.4175\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3695 - val_loss: 0.3753\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2140 - val_loss: 0.3565\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8937 - val_loss: 0.4424\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1128 - val_loss: 0.4696\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9970 - val_loss: 0.3403\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0719 - val_loss: 0.3234\n",
      "Epoch 96/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9727 - val_loss: 0.4672\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9138 - val_loss: 0.4028\n",
      "Epoch 98/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7508 - val_loss: 0.3328\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7759 - val_loss: 0.3083\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2809 - val_loss: 0.3301\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9927 - val_loss: 0.2826\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5223 - val_loss: 0.3049\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7877 - val_loss: 0.4436\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7491 - val_loss: 0.5024\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7748 - val_loss: 0.3166\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8535 - val_loss: 0.4171\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6423 - val_loss: 0.5382\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0695 - val_loss: 0.3772\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5826 - val_loss: 0.3859\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6130 - val_loss: 0.3123\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5705 - val_loss: 0.3323\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8850 - val_loss: 0.6053\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8694 - val_loss: 0.3130\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6739 - val_loss: 0.3252\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4841 - val_loss: 0.5160\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1103 - val_loss: 0.2893\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2634 - val_loss: 0.3573\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5703 - val_loss: 0.4210\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8174 - val_loss: 0.3616\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9314 - val_loss: 0.2494\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6557 - val_loss: 0.3821\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9432 - val_loss: 0.3243\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.4471 - val_loss: 0.2255\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8891 - val_loss: 0.2431\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9090 - val_loss: 0.5570\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9633 - val_loss: 0.2392\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0356 - val_loss: 0.2453\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8435 - val_loss: 0.6358\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5568 - val_loss: 0.2010\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8568 - val_loss: 0.2129\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.4949 - val_loss: 0.2226\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4189 - val_loss: 0.2054\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7564 - val_loss: 0.2827\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6517 - val_loss: 0.2367\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4795 - val_loss: 0.4414\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1298 - val_loss: 0.2396\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7394 - val_loss: 0.2607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9506 - val_loss: 0.2546\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6284 - val_loss: 0.2032\n",
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6032 - val_loss: 0.2468\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5574 - val_loss: 0.3448\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7187 - val_loss: 0.2940\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5741 - val_loss: 0.2944\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8997 - val_loss: 0.2912\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4920 - val_loss: 0.3343\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.3781 - val_loss: 0.4585\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6786 - val_loss: 0.6138\n",
      "Epoch 148/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6055 - val_loss: 0.1939\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6505 - val_loss: 0.3198\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6811 - val_loss: 0.3896\n",
      "6/6 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.3896081970255231\n",
      "Mean Absolute Error: 0.5009134261004896\n",
      "R-squared: 0.9955784835190684\n",
      "\n",
      "Fold 2:\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 14s 126ms/step - loss: 158.8875 - val_loss: 168.4564\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 129.2794 - val_loss: 115.1098\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 87.9521 - val_loss: 88.9876\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 78.2353 - val_loss: 83.3694\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 70.6281 - val_loss: 72.0748\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 57.4227 - val_loss: 54.9134\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 42.2158 - val_loss: 40.6147\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 31.5832 - val_loss: 33.8850\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 28.3622 - val_loss: 29.8431\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 24.8610 - val_loss: 26.3151\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 21.6850 - val_loss: 23.6302\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 19.9533 - val_loss: 21.2519\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 17.8481 - val_loss: 19.0941\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 15.6449 - val_loss: 17.1511\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 13.7168 - val_loss: 15.5729\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 13.3201 - val_loss: 14.0713\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 11.5796 - val_loss: 12.7316\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 10.1392 - val_loss: 11.5814\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 10.3143 - val_loss: 10.5342\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 8.9488 - val_loss: 9.5752\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 8.7120 - val_loss: 8.6985\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 7.3796 - val_loss: 7.9950\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 6.6555 - val_loss: 7.3732\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 6.3090 - val_loss: 6.7806\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 5.5304 - val_loss: 6.2662\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 5.4543 - val_loss: 5.8967\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 4.8742 - val_loss: 5.4243\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 4.8335 - val_loss: 5.1909\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 5.3397 - val_loss: 4.7711\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 4.3798 - val_loss: 4.5166\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 4.0903 - val_loss: 4.2623\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 3.1622 - val_loss: 4.0347\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 3.8397 - val_loss: 3.8587\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 3.2140 - val_loss: 3.7144\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.9194 - val_loss: 3.5802\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 3.3442 - val_loss: 3.3981\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 3.1890 - val_loss: 3.2950\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 3.0972 - val_loss: 3.2512\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.6000 - val_loss: 3.1000\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.8579 - val_loss: 3.0134\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.9618 - val_loss: 2.9554\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 3.0111 - val_loss: 2.8891\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.2321 - val_loss: 2.8117\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.4453 - val_loss: 2.7357\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.8162 - val_loss: 2.6346\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.8712 - val_loss: 2.6530\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4906 - val_loss: 2.5332\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.6602 - val_loss: 2.5004\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.7043 - val_loss: 2.4568\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1239 - val_loss: 2.3647\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.6652 - val_loss: 2.4062\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.8543 - val_loss: 2.2860\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.3281 - val_loss: 2.2436\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8228 - val_loss: 2.1731\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.2029 - val_loss: 2.2412\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.3170 - val_loss: 2.0991\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1115 - val_loss: 2.1017\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0603 - val_loss: 2.0411\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3375 - val_loss: 2.0545\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.6638 - val_loss: 2.3224\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.7751 - val_loss: 1.9548\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2271 - val_loss: 1.9158\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.0853 - val_loss: 1.9059\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 2.3290 - val_loss: 1.8096\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9504 - val_loss: 1.7797\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1712 - val_loss: 1.8169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.3650 - val_loss: 1.7143\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1410 - val_loss: 1.7042\n",
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0408 - val_loss: 1.7468\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2707 - val_loss: 1.6558\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7925 - val_loss: 1.6847\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7443 - val_loss: 1.6408\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5906 - val_loss: 1.6084\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6809 - val_loss: 1.5960\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9372 - val_loss: 1.5813\n",
      "Epoch 76/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9309 - val_loss: 1.5142\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8586 - val_loss: 1.5162\n",
      "Epoch 78/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8430 - val_loss: 1.6666\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7639 - val_loss: 1.5122\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9637 - val_loss: 1.4839\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0217 - val_loss: 1.4370\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8101 - val_loss: 1.3999\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7906 - val_loss: 1.3958\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9188 - val_loss: 1.4098\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6107 - val_loss: 1.4138\n",
      "Epoch 86/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6714 - val_loss: 1.3488\n",
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7783 - val_loss: 1.3447\n",
      "Epoch 88/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6961 - val_loss: 1.3410\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7017 - val_loss: 1.3529\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0657 - val_loss: 1.2676\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8203 - val_loss: 1.5950\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5995 - val_loss: 1.2660\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4959 - val_loss: 1.2085\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8366 - val_loss: 1.2360\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8791 - val_loss: 1.2975\n",
      "Epoch 96/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.5715 - val_loss: 1.1809\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0526 - val_loss: 1.1998\n",
      "Epoch 98/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0136 - val_loss: 1.3262\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7765 - val_loss: 1.4330\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0377 - val_loss: 1.2427\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7233 - val_loss: 1.1253\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4798 - val_loss: 1.1383\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5294 - val_loss: 1.1442\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6190 - val_loss: 1.0869\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6952 - val_loss: 1.1034\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6824 - val_loss: 1.1220\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5711 - val_loss: 1.0982\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6424 - val_loss: 1.1182\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6472 - val_loss: 1.0949\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7766 - val_loss: 1.0715\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8054 - val_loss: 1.0758\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5850 - val_loss: 1.1038\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9370 - val_loss: 1.1033\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5307 - val_loss: 1.0081\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5940 - val_loss: 1.0080\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8165 - val_loss: 0.9634\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6365 - val_loss: 0.9547\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7319 - val_loss: 0.9293\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5911 - val_loss: 0.9767\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4748 - val_loss: 1.1496\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.6586 - val_loss: 0.9268\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.1109 - val_loss: 0.9022\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7566 - val_loss: 0.9138\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4996 - val_loss: 1.0348\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.3961 - val_loss: 1.0646\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7400 - val_loss: 1.1065\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8350 - val_loss: 0.9803\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.4456 - val_loss: 0.8936\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.6440 - val_loss: 0.8477\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6884 - val_loss: 0.8766\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5025 - val_loss: 0.9435\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4306 - val_loss: 0.9600\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4322 - val_loss: 0.8414\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7854 - val_loss: 1.0015\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4796 - val_loss: 1.0538\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9759 - val_loss: 0.8783\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6631 - val_loss: 0.7984\n",
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.4184 - val_loss: 0.8759\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.2642 - val_loss: 0.8707\n",
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6578 - val_loss: 0.8103\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.2521 - val_loss: 0.7616\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.1271 - val_loss: 0.7568\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5609 - val_loss: 0.8744\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.3880 - val_loss: 0.7621\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7381 - val_loss: 0.7614\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8220 - val_loss: 0.8021\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4769 - val_loss: 0.7485\n",
      "Epoch 148/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.2794 - val_loss: 0.7410\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5175 - val_loss: 0.7648\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4978 - val_loss: 0.7719\n",
      "6/6 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.7719415126820794\n",
      "Mean Absolute Error: 0.3933554360360811\n",
      "R-squared: 0.991935504044184\n",
      "\n",
      "Fold 3:\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 15s 125ms/step - loss: 163.4319 - val_loss: 148.5789\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 133.1311 - val_loss: 97.1641\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 86.1023 - val_loss: 75.0912\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 76.7792 - val_loss: 67.2569\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 64.3729 - val_loss: 51.8500\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 47.8070 - val_loss: 36.3254\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 34.1038 - val_loss: 27.9409\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 28.4053 - val_loss: 24.0372\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 25.2553 - val_loss: 21.1894\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 22.7801 - val_loss: 18.7766\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 20.0786 - val_loss: 16.6234\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 17.1960 - val_loss: 14.7829\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 15.4015 - val_loss: 13.1994\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 13.9064 - val_loss: 11.8532\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 12.7348 - val_loss: 10.7493\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 11.4342 - val_loss: 9.6427\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 10.7854 - val_loss: 8.6099\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 9.0632 - val_loss: 7.8592\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 8.4124 - val_loss: 7.0909\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 8.0943 - val_loss: 6.4099\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 6.9042 - val_loss: 5.8772\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 6.8674 - val_loss: 5.3899\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 6.8638 - val_loss: 4.8939\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 5.5818 - val_loss: 4.4968\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 5.7713 - val_loss: 4.1391\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 5.3584 - val_loss: 3.7634\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.3863 - val_loss: 3.5657\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.8183 - val_loss: 3.2824\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 4.3438 - val_loss: 3.1966\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.9438 - val_loss: 2.8527\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.0720 - val_loss: 2.7251\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 3.1674 - val_loss: 2.5539\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.5113 - val_loss: 2.4169\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.4339 - val_loss: 2.3296\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.5739 - val_loss: 2.3235\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.4383 - val_loss: 2.3049\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.9524 - val_loss: 2.0093\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.1264 - val_loss: 1.9467\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.8741 - val_loss: 1.9954\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.9277 - val_loss: 1.8923\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8564 - val_loss: 1.7317\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.0027 - val_loss: 1.6776\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6835 - val_loss: 1.7006\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6181 - val_loss: 1.6924\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5418 - val_loss: 1.5850\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5684 - val_loss: 1.4790\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6314 - val_loss: 1.4735\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6069 - val_loss: 1.3852\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.7126 - val_loss: 1.3316\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5872 - val_loss: 1.4762\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6102 - val_loss: 1.3330\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5465 - val_loss: 1.2574\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.5355 - val_loss: 1.2994\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5022 - val_loss: 1.1728\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5929 - val_loss: 1.2130\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4274 - val_loss: 1.1004\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4624 - val_loss: 1.1099\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0926 - val_loss: 1.1544\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5707 - val_loss: 1.0749\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2707 - val_loss: 1.0012\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5600 - val_loss: 1.0955\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0849 - val_loss: 0.9238\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4012 - val_loss: 0.9199\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.5699 - val_loss: 0.9449\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4559 - val_loss: 0.8813\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4247 - val_loss: 0.9370\n",
      "Epoch 67/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5166 - val_loss: 0.8975\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9646 - val_loss: 0.8369\n",
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8325 - val_loss: 0.8258\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4585 - val_loss: 1.1062\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1244 - val_loss: 0.9203\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2797 - val_loss: 0.7844\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0769 - val_loss: 0.7231\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9347 - val_loss: 0.7190\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0689 - val_loss: 0.8130\n",
      "Epoch 76/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9900 - val_loss: 0.7220\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4631 - val_loss: 0.6717\n",
      "Epoch 78/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9539 - val_loss: 0.6774\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3225 - val_loss: 0.9036\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8952 - val_loss: 0.7466\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1889 - val_loss: 0.6297\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3381 - val_loss: 0.6184\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8255 - val_loss: 0.6478\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0192 - val_loss: 0.7856\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1359 - val_loss: 0.6598\n",
      "Epoch 86/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2294 - val_loss: 0.6145\n",
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1960 - val_loss: 0.5656\n",
      "Epoch 88/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8896 - val_loss: 0.5409\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2554 - val_loss: 0.5488\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1405 - val_loss: 0.6029\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1407 - val_loss: 0.5159\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0354 - val_loss: 0.5154\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1587 - val_loss: 0.4728\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0998 - val_loss: 0.6532\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1013 - val_loss: 0.4769\n",
      "Epoch 96/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9063 - val_loss: 0.4475\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1662 - val_loss: 0.4679\n",
      "Epoch 98/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2110 - val_loss: 0.4431\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8054 - val_loss: 0.4792\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8095 - val_loss: 0.4448\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6557 - val_loss: 0.4480\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6712 - val_loss: 0.5050\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8039 - val_loss: 0.4191\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8045 - val_loss: 0.4111\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7404 - val_loss: 0.6281\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6369 - val_loss: 0.4108\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1254 - val_loss: 0.5027\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9504 - val_loss: 0.3964\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0177 - val_loss: 0.3847\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0174 - val_loss: 0.4950\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0651 - val_loss: 0.3651\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7894 - val_loss: 0.3971\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0959 - val_loss: 0.5054\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8088 - val_loss: 0.4298\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7542 - val_loss: 0.3651\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7702 - val_loss: 0.3621\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7231 - val_loss: 0.3523\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7413 - val_loss: 0.6229\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7815 - val_loss: 0.3687\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8739 - val_loss: 0.3292\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0178 - val_loss: 0.5099\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1810 - val_loss: 0.5268\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9787 - val_loss: 0.3311\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7154 - val_loss: 0.3949\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8443 - val_loss: 0.2999\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6968 - val_loss: 0.3842\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8093 - val_loss: 0.4466\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9904 - val_loss: 0.3925\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0335 - val_loss: 0.4329\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7649 - val_loss: 0.3278\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2809 - val_loss: 0.3189\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7575 - val_loss: 0.3303\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6979 - val_loss: 0.5616\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7493 - val_loss: 0.2969\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5430 - val_loss: 0.2860\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.4386 - val_loss: 0.2873\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5148 - val_loss: 0.4292\n",
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6608 - val_loss: 0.2846\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9795 - val_loss: 0.2521\n",
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7590 - val_loss: 0.2960\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7426 - val_loss: 0.2554\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7326 - val_loss: 0.2383\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9730 - val_loss: 0.2536\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8452 - val_loss: 0.3200\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.7587 - val_loss: 0.3164\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 1.8626 - val_loss: 0.2741\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.8896 - val_loss: 0.4058\n",
      "Epoch 148/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6887 - val_loss: 0.4517\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0215 - val_loss: 0.2488\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7970 - val_loss: 0.4546\n",
      "6/6 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.4545916501741223\n",
      "Mean Absolute Error: 0.5825053944732203\n",
      "R-squared: 0.9945919611557206\n",
      "\n",
      "Fold 4:\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 16s 136ms/step - loss: 173.5914 - val_loss: 113.3740\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 146.0013 - val_loss: 76.2779\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 97.4039 - val_loss: 60.8356\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 85.7009 - val_loss: 59.7400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 79.3888 - val_loss: 48.0329\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 64.3925 - val_loss: 33.4240\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 48.7827 - val_loss: 22.2868\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 37.4607 - val_loss: 17.4263\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 32.7065 - val_loss: 15.0003\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 27.2918 - val_loss: 13.2794\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 25.7915 - val_loss: 11.4417\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 22.6402 - val_loss: 10.0464\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 19.5681 - val_loss: 8.8223\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 17.6463 - val_loss: 7.9937\n",
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 16.5667 - val_loss: 7.0934\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 13.9704 - val_loss: 6.1400\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 12.5269 - val_loss: 5.5662\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 12.0716 - val_loss: 4.9799\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 10.2356 - val_loss: 4.3329\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 10.0695 - val_loss: 3.9305\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 9.3642 - val_loss: 3.5451\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 8.3726 - val_loss: 3.1540\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 7.4757 - val_loss: 2.8598\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 6.5608 - val_loss: 2.7513\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 6.2020 - val_loss: 2.4567\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 5.8323 - val_loss: 2.2321\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.7436 - val_loss: 2.0509\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 5.3671 - val_loss: 2.1458\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.8295 - val_loss: 1.9747\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 4.7990 - val_loss: 1.6845\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.1028 - val_loss: 1.7053\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 4.4190 - val_loss: 1.5972\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 4.1236 - val_loss: 1.4893\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 3.9266 - val_loss: 1.4281\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.8001 - val_loss: 1.4444\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 3.6615 - val_loss: 1.3385\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 9ms/step - loss: 4.2332 - val_loss: 1.3789\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 3.7733 - val_loss: 1.2543\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 13ms/step - loss: 3.4434 - val_loss: 1.2428\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.3802 - val_loss: 1.1776\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 12ms/step - loss: 3.3941 - val_loss: 1.1813\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.4643 - val_loss: 1.0868\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 3.1620 - val_loss: 1.1973\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 10ms/step - loss: 3.2233 - val_loss: 1.0545\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 2.8012 - val_loss: 1.0628\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 11ms/step - loss: 3.4121 - val_loss: 1.0207\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.0952 - val_loss: 1.0852\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.9490 - val_loss: 1.1053\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.6813 - val_loss: 0.9608\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.7719 - val_loss: 0.9606\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.0879 - val_loss: 0.8889\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.9231 - val_loss: 0.8872\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.5317 - val_loss: 0.8467\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.9596 - val_loss: 0.8282\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.4427 - val_loss: 0.7557\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5847 - val_loss: 0.7566\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.3907 - val_loss: 0.8240\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1641 - val_loss: 0.7365\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2725 - val_loss: 0.6732\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.3057 - val_loss: 0.7714\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.2537 - val_loss: 0.6433\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.5173 - val_loss: 0.6126\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.5576 - val_loss: 0.5981\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.3443 - val_loss: 0.6873\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.6611 - val_loss: 0.6034\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.4593 - val_loss: 0.6032\n",
      "Epoch 67/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.5253 - val_loss: 0.5672\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2313 - val_loss: 0.5655\n",
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1817 - val_loss: 0.6387\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.5563 - val_loss: 0.5504\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1977 - val_loss: 0.5500\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0235 - val_loss: 0.5247\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2886 - val_loss: 0.5742\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2082 - val_loss: 0.4792\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1620 - val_loss: 0.5933\n",
      "Epoch 76/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.2943 - val_loss: 0.4684\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1135 - val_loss: 0.5082\n",
      "Epoch 78/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.3715 - val_loss: 0.5378\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2947 - val_loss: 0.4573\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9576 - val_loss: 0.4930\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1790 - val_loss: 0.4305\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.6333 - val_loss: 0.4048\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.2269 - val_loss: 0.4880\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1959 - val_loss: 0.5449\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0283 - val_loss: 0.4230\n",
      "Epoch 86/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9003 - val_loss: 0.4365\n",
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.4564 - val_loss: 0.4571\n",
      "Epoch 88/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8214 - val_loss: 0.3858\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9245 - val_loss: 0.5877\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8411 - val_loss: 0.3504\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9683 - val_loss: 0.3438\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3146 - val_loss: 0.4690\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9547 - val_loss: 0.3295\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1406 - val_loss: 0.5217\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0216 - val_loss: 0.3824\n",
      "Epoch 96/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8304 - val_loss: 0.3714\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9306 - val_loss: 0.5618\n",
      "Epoch 98/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0412 - val_loss: 0.3487\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.0882 - val_loss: 0.3359\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 2.1674 - val_loss: 0.3393\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.9858 - val_loss: 0.3963\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.9126 - val_loss: 0.3250\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1393 - val_loss: 0.4111\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1494 - val_loss: 0.3174\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8300 - val_loss: 0.3251\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0481 - val_loss: 0.2893\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.7637 - val_loss: 0.3025\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 22ms/step - loss: 1.9516 - val_loss: 0.2993\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9023 - val_loss: 0.2779\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7361 - val_loss: 0.3405\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8968 - val_loss: 0.3522\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9971 - val_loss: 0.4413\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1756 - val_loss: 0.3672\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8186 - val_loss: 0.3161\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8942 - val_loss: 0.2553\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9581 - val_loss: 0.3724\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0122 - val_loss: 0.3389\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6837 - val_loss: 0.3536\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 0s 15ms/step - loss: 1.7291 - val_loss: 0.3909\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5941 - val_loss: 0.2408\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0503 - val_loss: 0.2376\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 14ms/step - loss: 1.8664 - val_loss: 0.2623\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.1063 - val_loss: 0.2870\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.2657 - val_loss: 0.5693\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1732 - val_loss: 0.2186\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1627 - val_loss: 0.4024\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6904 - val_loss: 0.2557\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 2.0665 - val_loss: 0.3107\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7417 - val_loss: 0.2454\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1485 - val_loss: 0.2190\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7760 - val_loss: 0.2755\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1548 - val_loss: 0.2358\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0245 - val_loss: 0.2736\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7625 - val_loss: 0.2270\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0247 - val_loss: 0.3122\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7020 - val_loss: 0.2245\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9713 - val_loss: 0.2355\n",
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7157 - val_loss: 0.1965\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7078 - val_loss: 0.2638\n",
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6437 - val_loss: 0.2094\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0387 - val_loss: 0.2355\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.4527 - val_loss: 0.2294\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.8129 - val_loss: 0.1908\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.9264 - val_loss: 0.2004\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8141 - val_loss: 0.2356\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.6566 - val_loss: 0.1841\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8539 - val_loss: 0.2055\n",
      "Epoch 148/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8378 - val_loss: 0.3200\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.9458 - val_loss: 0.2598\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 1.8617 - val_loss: 0.2479\n",
      "6/6 [==============================] - 2s 6ms/step\n",
      "Mean Squared Error: 0.24794088893054736\n",
      "Mean Absolute Error: 0.3235376647024444\n",
      "R-squared: 0.9962307943872158\n",
      "\n",
      "Fold 5:\n",
      "Epoch 1/150\n",
      "21/21 [==============================] - 15s 131ms/step - loss: 155.9375 - val_loss: 181.4666\n",
      "Epoch 2/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 129.6790 - val_loss: 126.1740\n",
      "Epoch 3/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 81.0296 - val_loss: 92.0513\n",
      "Epoch 4/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 71.4496 - val_loss: 82.6992\n",
      "Epoch 5/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 60.8234 - val_loss: 68.0399\n",
      "Epoch 6/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 45.8715 - val_loss: 50.1923\n",
      "Epoch 7/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 32.1581 - val_loss: 39.4623\n",
      "Epoch 8/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 25.2658 - val_loss: 34.1638\n",
      "Epoch 9/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 22.9669 - val_loss: 30.3026\n",
      "Epoch 10/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 19.6418 - val_loss: 27.1192\n",
      "Epoch 11/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 17.8059 - val_loss: 24.4517\n",
      "Epoch 12/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 16.6707 - val_loss: 21.8676\n",
      "Epoch 13/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 14.3045 - val_loss: 19.6515\n",
      "Epoch 14/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 13.0873 - val_loss: 17.6978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 11.0187 - val_loss: 15.9810\n",
      "Epoch 16/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 10.1836 - val_loss: 14.6148\n",
      "Epoch 17/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 9.8588 - val_loss: 13.2084\n",
      "Epoch 18/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 8.5073 - val_loss: 11.8937\n",
      "Epoch 19/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 8.0515 - val_loss: 10.7852\n",
      "Epoch 20/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 7.1662 - val_loss: 9.9550\n",
      "Epoch 21/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 7.4367 - val_loss: 8.8881\n",
      "Epoch 22/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 6.0662 - val_loss: 8.2977\n",
      "Epoch 23/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 5.3306 - val_loss: 7.5418\n",
      "Epoch 24/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 5.4317 - val_loss: 7.0930\n",
      "Epoch 25/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 5.0882 - val_loss: 6.4376\n",
      "Epoch 26/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.5803 - val_loss: 5.9870\n",
      "Epoch 27/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.6885 - val_loss: 5.4312\n",
      "Epoch 28/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.4241 - val_loss: 5.0613\n",
      "Epoch 29/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 4.2217 - val_loss: 4.7005\n",
      "Epoch 30/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 4.3028 - val_loss: 4.3861\n",
      "Epoch 31/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.6845 - val_loss: 4.0568\n",
      "Epoch 32/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.3060 - val_loss: 3.8420\n",
      "Epoch 33/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.0774 - val_loss: 3.6169\n",
      "Epoch 34/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.1302 - val_loss: 3.6004\n",
      "Epoch 35/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.4428 - val_loss: 3.2218\n",
      "Epoch 36/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8773 - val_loss: 3.0732\n",
      "Epoch 37/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.2892 - val_loss: 3.1483\n",
      "Epoch 38/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.0119 - val_loss: 2.8783\n",
      "Epoch 39/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.3890 - val_loss: 2.7699\n",
      "Epoch 40/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 3.2837 - val_loss: 2.5793\n",
      "Epoch 41/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 3.1269 - val_loss: 2.5260\n",
      "Epoch 42/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8606 - val_loss: 2.4409\n",
      "Epoch 43/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.8718 - val_loss: 2.4717\n",
      "Epoch 44/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5009 - val_loss: 2.2067\n",
      "Epoch 45/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.7941 - val_loss: 2.3086\n",
      "Epoch 46/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.7485 - val_loss: 2.0752\n",
      "Epoch 47/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.7539 - val_loss: 2.0231\n",
      "Epoch 48/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4574 - val_loss: 1.9621\n",
      "Epoch 49/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.4007 - val_loss: 1.9537\n",
      "Epoch 50/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.7551 - val_loss: 1.8506\n",
      "Epoch 51/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 3.0818 - val_loss: 1.9653\n",
      "Epoch 52/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.3543 - val_loss: 1.7626\n",
      "Epoch 53/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.6084 - val_loss: 1.7519\n",
      "Epoch 54/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2106 - val_loss: 1.6862\n",
      "Epoch 55/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2854 - val_loss: 1.5995\n",
      "Epoch 56/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2790 - val_loss: 1.6944\n",
      "Epoch 57/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.4766 - val_loss: 1.5580\n",
      "Epoch 58/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9814 - val_loss: 1.6704\n",
      "Epoch 59/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1180 - val_loss: 1.4359\n",
      "Epoch 60/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.4156 - val_loss: 1.4385\n",
      "Epoch 61/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2293 - val_loss: 1.8602\n",
      "Epoch 62/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2070 - val_loss: 1.4721\n",
      "Epoch 63/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.3934 - val_loss: 1.3606\n",
      "Epoch 64/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1049 - val_loss: 1.4657\n",
      "Epoch 65/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0339 - val_loss: 1.3425\n",
      "Epoch 66/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.3111 - val_loss: 1.3553\n",
      "Epoch 67/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.4413 - val_loss: 1.2797\n",
      "Epoch 68/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.3149 - val_loss: 1.3183\n",
      "Epoch 69/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1100 - val_loss: 1.1493\n",
      "Epoch 70/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0102 - val_loss: 1.2323\n",
      "Epoch 71/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9483 - val_loss: 1.1347\n",
      "Epoch 72/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0194 - val_loss: 1.2522\n",
      "Epoch 73/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.3555 - val_loss: 1.0820\n",
      "Epoch 74/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.1150 - val_loss: 1.0540\n",
      "Epoch 75/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2225 - val_loss: 1.0369\n",
      "Epoch 76/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.8911 - val_loss: 1.0318\n",
      "Epoch 77/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.2338 - val_loss: 0.9890\n",
      "Epoch 78/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0128 - val_loss: 0.9402\n",
      "Epoch 79/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.7368 - val_loss: 1.2177\n",
      "Epoch 80/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7465 - val_loss: 0.9170\n",
      "Epoch 81/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.0484 - val_loss: 0.9663\n",
      "Epoch 82/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5806 - val_loss: 0.9447\n",
      "Epoch 83/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 2.2021 - val_loss: 0.8931\n",
      "Epoch 84/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7556 - val_loss: 0.8520\n",
      "Epoch 85/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9702 - val_loss: 1.0637\n",
      "Epoch 86/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.0809 - val_loss: 0.9735\n",
      "Epoch 87/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.9897 - val_loss: 1.0938\n",
      "Epoch 88/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8214 - val_loss: 0.8800\n",
      "Epoch 89/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7671 - val_loss: 0.9445\n",
      "Epoch 90/150\n",
      "21/21 [==============================] - 0s 16ms/step - loss: 1.9828 - val_loss: 0.8249\n",
      "Epoch 91/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6052 - val_loss: 0.7489\n",
      "Epoch 92/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7157 - val_loss: 0.7908\n",
      "Epoch 93/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.2347 - val_loss: 0.9155\n",
      "Epoch 94/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.5428 - val_loss: 0.7301\n",
      "Epoch 95/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7782 - val_loss: 0.7072\n",
      "Epoch 96/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 0s 17ms/step - loss: 1.7495 - val_loss: 0.8444\n",
      "Epoch 97/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7107 - val_loss: 0.9055\n",
      "Epoch 98/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.5189 - val_loss: 0.7797\n",
      "Epoch 99/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7051 - val_loss: 0.7418\n",
      "Epoch 100/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5718 - val_loss: 0.6696\n",
      "Epoch 101/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9205 - val_loss: 0.8218\n",
      "Epoch 102/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0181 - val_loss: 0.6437\n",
      "Epoch 103/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7997 - val_loss: 0.6819\n",
      "Epoch 104/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.8988 - val_loss: 0.9185\n",
      "Epoch 105/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.4763 - val_loss: 0.6251\n",
      "Epoch 106/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6151 - val_loss: 0.6501\n",
      "Epoch 107/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 2.0244 - val_loss: 0.7223\n",
      "Epoch 108/150\n",
      "21/21 [==============================] - 0s 17ms/step - loss: 1.6871 - val_loss: 0.5786\n",
      "Epoch 109/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6899 - val_loss: 0.8659\n",
      "Epoch 110/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 2.1841 - val_loss: 0.6563\n",
      "Epoch 111/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.9534 - val_loss: 1.0513\n",
      "Epoch 112/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.7020 - val_loss: 0.5694\n",
      "Epoch 113/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.6183 - val_loss: 0.6343\n",
      "Epoch 114/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9226 - val_loss: 0.5703\n",
      "Epoch 115/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6350 - val_loss: 0.6047\n",
      "Epoch 116/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5957 - val_loss: 0.5974\n",
      "Epoch 117/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8878 - val_loss: 0.5856\n",
      "Epoch 118/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9028 - val_loss: 0.6547\n",
      "Epoch 119/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6013 - val_loss: 0.6205\n",
      "Epoch 120/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.6335 - val_loss: 0.6565\n",
      "Epoch 121/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6867 - val_loss: 0.6052\n",
      "Epoch 122/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8506 - val_loss: 0.5246\n",
      "Epoch 123/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.9221 - val_loss: 0.5167\n",
      "Epoch 124/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.4877 - val_loss: 0.5312\n",
      "Epoch 125/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.6102 - val_loss: 0.6124\n",
      "Epoch 126/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8658 - val_loss: 0.5124\n",
      "Epoch 127/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8102 - val_loss: 0.5054\n",
      "Epoch 128/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.6606 - val_loss: 0.4489\n",
      "Epoch 129/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5353 - val_loss: 0.4179\n",
      "Epoch 130/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.3547 - val_loss: 0.4777\n",
      "Epoch 131/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.4400 - val_loss: 0.4219\n",
      "Epoch 132/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5334 - val_loss: 0.4552\n",
      "Epoch 133/150\n",
      "21/21 [==============================] - 0s 20ms/step - loss: 1.7478 - val_loss: 0.6712\n",
      "Epoch 134/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 1.3828 - val_loss: 0.4751\n",
      "Epoch 135/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.6346 - val_loss: 0.3940\n",
      "Epoch 136/150\n",
      "21/21 [==============================] - 0s 21ms/step - loss: 1.8629 - val_loss: 0.3886\n",
      "Epoch 137/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.4909 - val_loss: 0.4698\n",
      "Epoch 138/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.4195 - val_loss: 0.4788\n",
      "Epoch 139/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6042 - val_loss: 0.4990\n",
      "Epoch 140/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.5941 - val_loss: 0.4384\n",
      "Epoch 141/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.8756 - val_loss: 0.4598\n",
      "Epoch 142/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7406 - val_loss: 0.7273\n",
      "Epoch 143/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 2.1944 - val_loss: 0.5088\n",
      "Epoch 144/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.7357 - val_loss: 0.5138\n",
      "Epoch 145/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.4389 - val_loss: 0.4481\n",
      "Epoch 146/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.7655 - val_loss: 0.4296\n",
      "Epoch 147/150\n",
      "21/21 [==============================] - 0s 19ms/step - loss: 1.5007 - val_loss: 0.7240\n",
      "Epoch 148/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6279 - val_loss: 0.4287\n",
      "Epoch 149/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.9279 - val_loss: 0.4518\n",
      "Epoch 150/150\n",
      "21/21 [==============================] - 0s 18ms/step - loss: 1.6436 - val_loss: 0.5523\n",
      "6/6 [==============================] - 2s 6ms/step\n",
      "Mean Squared Error: 0.5522689081830264\n",
      "Mean Absolute Error: 0.4133758956735784\n",
      "R-squared: 0.994741563706186\n",
      "\n",
      "Average scores for ticker AMWL:\n",
      "Mean Squared Error: 0.4832702313990597\n",
      "Mean Absolute Error: 0.44273756339716275\n",
      "R-squared: 0.9946156613624749\n",
      "\n",
      "Cross-validation for ticker: GEO\n",
      "Fold 1:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 107ms/step - loss: 79.8809 - val_loss: 57.9091\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 35.0142 - val_loss: 5.2282\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.8051 - val_loss: 5.0619\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 5.3151 - val_loss: 3.8496\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.1076 - val_loss: 3.5557\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.4927 - val_loss: 3.0548\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.9447 - val_loss: 2.1303\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 2.9212 - val_loss: 1.2763\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 2.3184 - val_loss: 0.6947\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.8131 - val_loss: 0.5772\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.5425 - val_loss: 0.5495\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.6001 - val_loss: 0.5334\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.5108 - val_loss: 0.5674\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.5951 - val_loss: 0.4609\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.4978 - val_loss: 0.3856\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.4075 - val_loss: 0.3607\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.3599 - val_loss: 0.3245\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.3620 - val_loss: 0.3121\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.3037 - val_loss: 0.2812\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.2013 - val_loss: 0.3635\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.2287 - val_loss: 0.2953\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1875 - val_loss: 0.2373\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1949 - val_loss: 0.2287\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1723 - val_loss: 0.2005\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1327 - val_loss: 0.1939\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 1.1373 - val_loss: 0.1703\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0894 - val_loss: 0.1603\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.0479 - val_loss: 0.1518\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0709 - val_loss: 0.1527\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9634 - val_loss: 0.1652\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.0016 - val_loss: 0.1183\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9243 - val_loss: 0.1445\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9454 - val_loss: 0.1457\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9744 - val_loss: 0.1876\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8735 - val_loss: 0.0994\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8451 - val_loss: 0.1023\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8620 - val_loss: 0.0831\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8202 - val_loss: 0.1101\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8330 - val_loss: 0.1025\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8114 - val_loss: 0.0820\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7845 - val_loss: 0.0773\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8113 - val_loss: 0.0674\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8282 - val_loss: 0.0748\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8140 - val_loss: 0.0639\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7584 - val_loss: 0.0604\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.8402 - val_loss: 0.0515\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7757 - val_loss: 0.0692\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9031 - val_loss: 0.0612\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7777 - val_loss: 0.0510\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7556 - val_loss: 0.0479\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8321 - val_loss: 0.0528\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7928 - val_loss: 0.0463\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8045 - val_loss: 0.0410\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7041 - val_loss: 0.0402\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7561 - val_loss: 0.0529\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.7896 - val_loss: 0.0476\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7118 - val_loss: 0.0377\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7052 - val_loss: 0.0367\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7068 - val_loss: 0.0513\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6923 - val_loss: 0.0386\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7168 - val_loss: 0.0325\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7076 - val_loss: 0.0322\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6470 - val_loss: 0.0433\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6449 - val_loss: 0.0352\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7310 - val_loss: 0.0343\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6591 - val_loss: 0.0279\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6294 - val_loss: 0.0300\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5758 - val_loss: 0.0572\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6741 - val_loss: 0.0409\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6925 - val_loss: 0.1104\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6874 - val_loss: 0.0255\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7234 - val_loss: 0.0282\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6835 - val_loss: 0.1606\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6579 - val_loss: 0.0271\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7002 - val_loss: 0.0257\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6567 - val_loss: 0.0257\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6699 - val_loss: 0.0233\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6160 - val_loss: 0.0263\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5883 - val_loss: 0.0278\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6095 - val_loss: 0.0240\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6504 - val_loss: 0.0256\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6441 - val_loss: 0.0237\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6855 - val_loss: 0.0236\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5960 - val_loss: 0.0203\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5747 - val_loss: 0.0408\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6185 - val_loss: 0.0394\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6666 - val_loss: 0.0195\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5534 - val_loss: 0.0458\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6741 - val_loss: 0.0319\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6303 - val_loss: 0.0345\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5709 - val_loss: 0.0216\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5660 - val_loss: 0.0182\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5614 - val_loss: 0.0237\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5683 - val_loss: 0.0177\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5556 - val_loss: 0.0341\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6236 - val_loss: 0.0178\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5892 - val_loss: 0.0238\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5961 - val_loss: 0.0360\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5669 - val_loss: 0.0235\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5847 - val_loss: 0.0341\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5713 - val_loss: 0.0185\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5777 - val_loss: 0.0150\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5898 - val_loss: 0.0180\n",
      "Epoch 104/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4971 - val_loss: 0.0550\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5710 - val_loss: 0.0179\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5672 - val_loss: 0.0235\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5367 - val_loss: 0.0159\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5131 - val_loss: 0.0221\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5386 - val_loss: 0.0226\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5727 - val_loss: 0.0179\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5866 - val_loss: 0.0143\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5979 - val_loss: 0.0159\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6366 - val_loss: 0.0400\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5688 - val_loss: 0.0464\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5221 - val_loss: 0.0358\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5551 - val_loss: 0.0151\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5434 - val_loss: 0.0245\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6243 - val_loss: 0.0466\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5107 - val_loss: 0.0248\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6036 - val_loss: 0.0507\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6005 - val_loss: 0.0189\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5199 - val_loss: 0.0366\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6333 - val_loss: 0.0306\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5524 - val_loss: 0.0174\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5170 - val_loss: 0.0206\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5515 - val_loss: 0.0733\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5851 - val_loss: 0.1129\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5723 - val_loss: 0.0181\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5701 - val_loss: 0.0204\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4753 - val_loss: 0.0175\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4880 - val_loss: 0.0137\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5470 - val_loss: 0.0152\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5177 - val_loss: 0.0287\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5734 - val_loss: 0.0190\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.4941 - val_loss: 0.0291\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5339 - val_loss: 0.0150\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5029 - val_loss: 0.0325\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5192 - val_loss: 0.0160\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5263 - val_loss: 0.0479\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5406 - val_loss: 0.0413\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.5723 - val_loss: 0.0423\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5552 - val_loss: 0.0238\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5196 - val_loss: 0.0175\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5611 - val_loss: 0.0252\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5038 - val_loss: 0.0187\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5442 - val_loss: 0.0262\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5722 - val_loss: 0.0144\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5111 - val_loss: 0.0423\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5132 - val_loss: 0.0185\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5704 - val_loss: 0.0350\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.035033398126715465\n",
      "Mean Absolute Error: 0.16611407882538604\n",
      "R-squared: 0.9936501408711352\n",
      "\n",
      "Fold 2:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 15s 103ms/step - loss: 76.8189 - val_loss: 63.0358\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 28.8241 - val_loss: 5.3175\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 5.6791 - val_loss: 4.9875\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.7820 - val_loss: 4.6872\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 4.7728 - val_loss: 4.1232\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 4.1427 - val_loss: 3.5059\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 3.3889 - val_loss: 2.6576\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 2.6361 - val_loss: 1.8129\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 2.0605 - val_loss: 1.2302\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.6589 - val_loss: 0.9842\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.5281 - val_loss: 0.8844\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.5603 - val_loss: 0.8010\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.4147 - val_loss: 0.7590\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.2954 - val_loss: 0.7043\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.3575 - val_loss: 0.6478\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.4213 - val_loss: 0.6486\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.2797 - val_loss: 0.5761\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.3488 - val_loss: 0.5185\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1680 - val_loss: 0.4989\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1497 - val_loss: 0.4605\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.1961 - val_loss: 0.4292\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0896 - val_loss: 0.4002\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0816 - val_loss: 0.3880\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0014 - val_loss: 0.3720\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0674 - val_loss: 0.3912\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9375 - val_loss: 0.3310\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 1.0592 - val_loss: 0.2943\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9724 - val_loss: 0.2728\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9876 - val_loss: 0.2447\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9959 - val_loss: 0.2446\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9231 - val_loss: 0.2182\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9599 - val_loss: 0.2118\n",
      "Epoch 33/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9482 - val_loss: 0.2313\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9287 - val_loss: 0.2180\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9085 - val_loss: 0.1771\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8913 - val_loss: 0.1831\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.9511 - val_loss: 0.2154\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8661 - val_loss: 0.1470\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8402 - val_loss: 0.1287\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8554 - val_loss: 0.1441\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8566 - val_loss: 0.1210\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8987 - val_loss: 0.1340\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7689 - val_loss: 0.1155\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8624 - val_loss: 0.2271\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8439 - val_loss: 0.1007\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7778 - val_loss: 0.0904\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8116 - val_loss: 0.1038\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7623 - val_loss: 0.0771\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8349 - val_loss: 0.0838\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7186 - val_loss: 0.0763\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6485 - val_loss: 0.0968\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7053 - val_loss: 0.0767\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7125 - val_loss: 0.0771\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7414 - val_loss: 0.0733\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7279 - val_loss: 0.0628\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7470 - val_loss: 0.0550\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6956 - val_loss: 0.0615\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6525 - val_loss: 0.0573\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6781 - val_loss: 0.0757\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6582 - val_loss: 0.0593\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6824 - val_loss: 0.0504\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7625 - val_loss: 0.0739\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.7016 - val_loss: 0.0533\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6368 - val_loss: 0.0767\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6995 - val_loss: 0.0376\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6479 - val_loss: 0.0402\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6733 - val_loss: 0.0839\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 1s 20ms/step - loss: 0.7314 - val_loss: 0.0529\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 18ms/step - loss: 0.6239 - val_loss: 0.0404\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5757 - val_loss: 0.0821\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6393 - val_loss: 0.0411\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.6475 - val_loss: 0.0478\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.6429 - val_loss: 0.0383\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6843 - val_loss: 0.0368\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5950 - val_loss: 0.0731\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.6111 - val_loss: 0.0357\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7022 - val_loss: 0.0595\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.6110 - val_loss: 0.0433\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.5809 - val_loss: 0.0692\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.6609 - val_loss: 0.0534\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6244 - val_loss: 0.0359\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.6106 - val_loss: 0.0368\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5253 - val_loss: 0.0461\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.6199 - val_loss: 0.0546\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5737 - val_loss: 0.0396\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.6426 - val_loss: 0.0715\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.5450 - val_loss: 0.0399\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5751 - val_loss: 0.0413\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5474 - val_loss: 0.0419\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 1s 22ms/step - loss: 0.6427 - val_loss: 0.0565\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6191 - val_loss: 0.0389\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.5729 - val_loss: 0.0578\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.5526 - val_loss: 0.0442\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.5657 - val_loss: 0.1129\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.5492 - val_loss: 0.0542\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5167 - val_loss: 0.0632\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.5525 - val_loss: 0.0470\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5424 - val_loss: 0.0706\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.5648 - val_loss: 0.0308\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5620 - val_loss: 0.0611\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5470 - val_loss: 0.0671\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.6178 - val_loss: 0.0718\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5614 - val_loss: 0.0348\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5483 - val_loss: 0.0436\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5210 - val_loss: 0.0348\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5475 - val_loss: 0.0372\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.4974 - val_loss: 0.0388\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.5715 - val_loss: 0.0600\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5871 - val_loss: 0.0712\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5473 - val_loss: 0.0508\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.5613 - val_loss: 0.0450\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.5054 - val_loss: 0.0510\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5160 - val_loss: 0.0394\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5617 - val_loss: 0.0420\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5592 - val_loss: 0.0627\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.5169 - val_loss: 0.0437\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.5432 - val_loss: 0.0435\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5274 - val_loss: 0.0509\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.4869 - val_loss: 0.0297\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.5402 - val_loss: 0.0408\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4796 - val_loss: 0.0401\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5226 - val_loss: 0.0466\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4756 - val_loss: 0.0335\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5204 - val_loss: 0.0980\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4689 - val_loss: 0.0250\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4912 - val_loss: 0.0245\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5831 - val_loss: 0.0400\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5075 - val_loss: 0.0280\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6304 - val_loss: 0.0443\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4822 - val_loss: 0.0649\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4938 - val_loss: 0.0317\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4834 - val_loss: 0.0296\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5236 - val_loss: 0.0429\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5385 - val_loss: 0.0375\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.5000 - val_loss: 0.0358\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4930 - val_loss: 0.0385\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4827 - val_loss: 0.0241\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4781 - val_loss: 0.0832\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.4982 - val_loss: 0.0251\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4870 - val_loss: 0.0235\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5352 - val_loss: 0.0329\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5067 - val_loss: 0.0308\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.4985 - val_loss: 0.0380\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4798 - val_loss: 0.0416\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4122 - val_loss: 0.0396\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4895 - val_loss: 0.0384\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5385 - val_loss: 0.0523\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5144 - val_loss: 0.0432\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.4721 - val_loss: 0.0406\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4592 - val_loss: 0.0494\n",
      "7/7 [==============================] - 1s 3ms/step\n",
      "Mean Squared Error: 0.0494114280607683\n",
      "Mean Absolute Error: 0.15092153454301369\n",
      "R-squared: 0.9930626940528883\n",
      "\n",
      "Fold 3:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 7s 61ms/step - loss: 78.7412 - val_loss: 64.1268\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 33.5022 - val_loss: 6.4848\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 5.4655 - val_loss: 5.5887\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 5.2182 - val_loss: 4.8875\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 4.3673 - val_loss: 4.4136\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.1350 - val_loss: 3.7194\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 3.4693 - val_loss: 2.9214\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 2.8578 - val_loss: 1.9497\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 2.1863 - val_loss: 1.2292\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.6273 - val_loss: 0.8423\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.5525 - val_loss: 0.7232\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.4430 - val_loss: 0.6848\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 1.5520 - val_loss: 0.6136\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.4454 - val_loss: 0.5665\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.4487 - val_loss: 0.5090\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3258 - val_loss: 0.4958\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.1890 - val_loss: 0.4420\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.1418 - val_loss: 0.4072\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3458 - val_loss: 0.3860\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.2275 - val_loss: 0.3662\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.1796 - val_loss: 0.3374\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.0184 - val_loss: 0.3088\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.1954 - val_loss: 0.2904\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.0169 - val_loss: 0.2646\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.0952 - val_loss: 0.2430\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.9281 - val_loss: 0.2338\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0259 - val_loss: 0.2117\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0222 - val_loss: 0.1951\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.0590 - val_loss: 0.1897\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 1.0428 - val_loss: 0.1835\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0442 - val_loss: 0.2212\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9662 - val_loss: 0.1508\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9118 - val_loss: 0.1485\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8949 - val_loss: 0.1381\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8577 - val_loss: 0.1852\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.9249 - val_loss: 0.1363\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8288 - val_loss: 0.1238\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.9022 - val_loss: 0.1027\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.8697 - val_loss: 0.1043\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7870 - val_loss: 0.1309\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8941 - val_loss: 0.0817\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8318 - val_loss: 0.0805\n",
      "Epoch 43/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9239 - val_loss: 0.0908\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8830 - val_loss: 0.0940\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.8097 - val_loss: 0.0625\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.7476 - val_loss: 0.0588\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7254 - val_loss: 0.1099\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6442 - val_loss: 0.0567\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7481 - val_loss: 0.0523\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.7620 - val_loss: 0.0692\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7102 - val_loss: 0.0469\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7114 - val_loss: 0.0499\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7163 - val_loss: 0.0812\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7520 - val_loss: 0.0440\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6816 - val_loss: 0.0452\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7301 - val_loss: 0.1008\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7480 - val_loss: 0.0483\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6639 - val_loss: 0.0462\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6753 - val_loss: 0.0528\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7065 - val_loss: 0.0351\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7519 - val_loss: 0.0669\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7083 - val_loss: 0.0536\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6500 - val_loss: 0.0579\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6864 - val_loss: 0.0330\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6987 - val_loss: 0.0647\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7450 - val_loss: 0.0401\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6417 - val_loss: 0.0593\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6624 - val_loss: 0.0365\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6286 - val_loss: 0.0333\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6439 - val_loss: 0.0255\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6258 - val_loss: 0.1263\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6844 - val_loss: 0.0809\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6414 - val_loss: 0.0392\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6686 - val_loss: 0.0316\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6280 - val_loss: 0.0910\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7006 - val_loss: 0.0837\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6362 - val_loss: 0.0564\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6174 - val_loss: 0.0258\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5917 - val_loss: 0.0453\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6222 - val_loss: 0.0587\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6474 - val_loss: 0.0373\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5913 - val_loss: 0.0232\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5522 - val_loss: 0.0288\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5877 - val_loss: 0.0253\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5653 - val_loss: 0.0353\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6289 - val_loss: 0.0305\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5877 - val_loss: 0.0391\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6914 - val_loss: 0.0275\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5869 - val_loss: 0.1014\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 8ms/step - loss: 0.5721 - val_loss: 0.0817\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6469 - val_loss: 0.0382\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5317 - val_loss: 0.0243\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5514 - val_loss: 0.0432\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5571 - val_loss: 0.0562\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6246 - val_loss: 0.0338\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5805 - val_loss: 0.0380\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5856 - val_loss: 0.0287\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6043 - val_loss: 0.0731\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5219 - val_loss: 0.0246\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5573 - val_loss: 0.0209\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6471 - val_loss: 0.0493\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5699 - val_loss: 0.0192\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5850 - val_loss: 0.0231\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5807 - val_loss: 0.0215\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5110 - val_loss: 0.0237\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5878 - val_loss: 0.0218\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5414 - val_loss: 0.0236\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5325 - val_loss: 0.0313\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5951 - val_loss: 0.0260\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5725 - val_loss: 0.0198\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5644 - val_loss: 0.0201\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5872 - val_loss: 0.0353\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6103 - val_loss: 0.0466\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5334 - val_loss: 0.0186\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5978 - val_loss: 0.0241\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 7ms/step - loss: 0.5246 - val_loss: 0.0180\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5282 - val_loss: 0.1262\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5381 - val_loss: 0.0336\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4693 - val_loss: 0.0358\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5175 - val_loss: 0.0275\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5844 - val_loss: 0.0256\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5552 - val_loss: 0.0330\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5118 - val_loss: 0.0245\n",
      "Epoch 124/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5385 - val_loss: 0.0294\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5151 - val_loss: 0.0253\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5206 - val_loss: 0.0200\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5311 - val_loss: 0.0304\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5503 - val_loss: 0.0384\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 9ms/step - loss: 0.5891 - val_loss: 0.0287\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5607 - val_loss: 0.0336\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5119 - val_loss: 0.0202\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4746 - val_loss: 0.0248\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5036 - val_loss: 0.0172\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5691 - val_loss: 0.0536\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5223 - val_loss: 0.0221\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5102 - val_loss: 0.0249\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5276 - val_loss: 0.0181\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5418 - val_loss: 0.0265\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5613 - val_loss: 0.0239\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4730 - val_loss: 0.0263\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4592 - val_loss: 0.0587\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5197 - val_loss: 0.0515\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5077 - val_loss: 0.0208\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5207 - val_loss: 0.1272\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5323 - val_loss: 0.0201\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5076 - val_loss: 0.0181\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4659 - val_loss: 0.0202\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4937 - val_loss: 0.0200\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5033 - val_loss: 0.0794\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4970 - val_loss: 0.0222\n",
      "7/7 [==============================] - 2s 5ms/step\n",
      "Mean Squared Error: 0.022153084447037955\n",
      "Mean Absolute Error: 0.11334257457979868\n",
      "R-squared: 0.9968326776364571\n",
      "\n",
      "Fold 4:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 9s 75ms/step - loss: 81.1152 - val_loss: 65.0015\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 40.7484 - val_loss: 7.8239\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.7223 - val_loss: 4.0466\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 5.5939 - val_loss: 3.3484\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.1318 - val_loss: 3.0853\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 4.7594 - val_loss: 2.6855\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.2786 - val_loss: 2.0452\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 3.5658 - val_loss: 1.3300\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 2.3672 - val_loss: 0.7986\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.9878 - val_loss: 0.7331\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.8275 - val_loss: 0.6380\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.7240 - val_loss: 0.5453\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.5382 - val_loss: 0.4691\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.5156 - val_loss: 0.5434\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.4072 - val_loss: 0.3938\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.4480 - val_loss: 0.3740\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.3955 - val_loss: 0.3526\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.2811 - val_loss: 0.3339\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.1897 - val_loss: 0.2849\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.2749 - val_loss: 0.2773\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0967 - val_loss: 0.2492\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.0679 - val_loss: 0.2472\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.1246 - val_loss: 0.2046\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.1526 - val_loss: 0.1894\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.0362 - val_loss: 0.2422\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0887 - val_loss: 0.1621\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0097 - val_loss: 0.1651\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9792 - val_loss: 0.1517\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.0081 - val_loss: 0.1412\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.0555 - val_loss: 0.1167\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.9376 - val_loss: 0.1919\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9458 - val_loss: 0.1113\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.9567 - val_loss: 0.1012\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8384 - val_loss: 0.1067\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.9065 - val_loss: 0.1027\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8267 - val_loss: 0.1145\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7912 - val_loss: 0.1004\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8650 - val_loss: 0.0744\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8649 - val_loss: 0.0880\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8366 - val_loss: 0.1162\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7321 - val_loss: 0.0982\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.9062 - val_loss: 0.0733\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7775 - val_loss: 0.0611\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8557 - val_loss: 0.0637\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7950 - val_loss: 0.0604\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7324 - val_loss: 0.0639\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8053 - val_loss: 0.0620\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7420 - val_loss: 0.0483\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.8481 - val_loss: 0.0517\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7522 - val_loss: 0.0718\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6506 - val_loss: 0.0471\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7647 - val_loss: 0.0463\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.8078 - val_loss: 0.0406\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7220 - val_loss: 0.0490\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6931 - val_loss: 0.0351\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.6801 - val_loss: 0.0478\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6304 - val_loss: 0.0399\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6401 - val_loss: 0.0284\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6413 - val_loss: 0.0288\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6188 - val_loss: 0.0337\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5889 - val_loss: 0.0403\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6149 - val_loss: 0.0489\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6328 - val_loss: 0.0353\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6156 - val_loss: 0.0325\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6379 - val_loss: 0.0357\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6873 - val_loss: 0.0610\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.7101 - val_loss: 0.0526\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6309 - val_loss: 0.0675\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6048 - val_loss: 0.0259\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6787 - val_loss: 0.0838\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6021 - val_loss: 0.0437\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6028 - val_loss: 0.0274\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5779 - val_loss: 0.0213\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6285 - val_loss: 0.0334\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6518 - val_loss: 0.0294\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7082 - val_loss: 0.0241\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6008 - val_loss: 0.0552\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6224 - val_loss: 0.0683\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6440 - val_loss: 0.0439\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6331 - val_loss: 0.0232\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6093 - val_loss: 0.0270\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5811 - val_loss: 0.0278\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6327 - val_loss: 0.0306\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6552 - val_loss: 0.0544\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5795 - val_loss: 0.0206\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5640 - val_loss: 0.0291\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5551 - val_loss: 0.0240\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5868 - val_loss: 0.0285\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5800 - val_loss: 0.0318\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5250 - val_loss: 0.0304\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6136 - val_loss: 0.0209\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5670 - val_loss: 0.0509\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5201 - val_loss: 0.0222\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6501 - val_loss: 0.0718\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6439 - val_loss: 0.0194\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6227 - val_loss: 0.0624\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5347 - val_loss: 0.0234\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5651 - val_loss: 0.0302\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5890 - val_loss: 0.0204\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6181 - val_loss: 0.0377\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5219 - val_loss: 0.0251\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4847 - val_loss: 0.0314\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5345 - val_loss: 0.0183\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4889 - val_loss: 0.0184\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5258 - val_loss: 0.0718\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5583 - val_loss: 0.0206\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5018 - val_loss: 0.0465\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5852 - val_loss: 0.0177\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5669 - val_loss: 0.0186\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6207 - val_loss: 0.0264\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5437 - val_loss: 0.0334\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5477 - val_loss: 0.0260\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5306 - val_loss: 0.0337\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5062 - val_loss: 0.0473\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5473 - val_loss: 0.0199\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5807 - val_loss: 0.0216\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5629 - val_loss: 0.0252\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5234 - val_loss: 0.0195\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5891 - val_loss: 0.0256\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5139 - val_loss: 0.0632\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4933 - val_loss: 0.0169\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5202 - val_loss: 0.0252\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.6011 - val_loss: 0.0169\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4830 - val_loss: 0.0344\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5443 - val_loss: 0.0157\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5071 - val_loss: 0.0147\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5467 - val_loss: 0.0174\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5721 - val_loss: 0.0153\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4793 - val_loss: 0.0185\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5803 - val_loss: 0.0301\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4977 - val_loss: 0.0150\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5638 - val_loss: 0.0133\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5475 - val_loss: 0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5454 - val_loss: 0.0178\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5689 - val_loss: 0.0361\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5349 - val_loss: 0.0328\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5584 - val_loss: 0.0168\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5074 - val_loss: 0.0451\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5500 - val_loss: 0.0208\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4925 - val_loss: 0.0329\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5464 - val_loss: 0.0425\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5169 - val_loss: 0.0333\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5251 - val_loss: 0.0268\n",
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4921 - val_loss: 0.0214\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5392 - val_loss: 0.0133\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4920 - val_loss: 0.0120\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5369 - val_loss: 0.0162\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4364 - val_loss: 0.0558\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4790 - val_loss: 0.0196\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5244 - val_loss: 0.0212\n",
      "7/7 [==============================] - 2s 3ms/step\n",
      "Mean Squared Error: 0.021241273099615023\n",
      "Mean Absolute Error: 0.1182135230866237\n",
      "R-squared: 0.9954218761015484\n",
      "\n",
      "Fold 5:\n",
      "Epoch 1/150\n",
      "26/26 [==============================] - 9s 78ms/step - loss: 78.7551 - val_loss: 68.9466\n",
      "Epoch 2/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 36.6922 - val_loss: 9.0717\n",
      "Epoch 3/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 6.2026 - val_loss: 5.7214\n",
      "Epoch 4/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 5.4950 - val_loss: 5.3205\n",
      "Epoch 5/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 5.0745 - val_loss: 4.9797\n",
      "Epoch 6/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 4.8070 - val_loss: 4.4875\n",
      "Epoch 7/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 4.3286 - val_loss: 3.8021\n",
      "Epoch 8/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 3.6728 - val_loss: 2.8562\n",
      "Epoch 9/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 2.8981 - val_loss: 1.8857\n",
      "Epoch 10/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 2.0207 - val_loss: 1.2639\n",
      "Epoch 11/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.8107 - val_loss: 1.0406\n",
      "Epoch 12/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.5443 - val_loss: 0.9949\n",
      "Epoch 13/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.6262 - val_loss: 0.9205\n",
      "Epoch 14/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.7071 - val_loss: 0.8195\n",
      "Epoch 15/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.4523 - val_loss: 0.7372\n",
      "Epoch 16/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.5017 - val_loss: 0.7373\n",
      "Epoch 17/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.4218 - val_loss: 0.6493\n",
      "Epoch 18/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.4015 - val_loss: 0.6413\n",
      "Epoch 19/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 1.2936 - val_loss: 0.5357\n",
      "Epoch 20/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.1145 - val_loss: 0.5167\n",
      "Epoch 21/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.2749 - val_loss: 0.4780\n",
      "Epoch 22/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.2019 - val_loss: 0.4441\n",
      "Epoch 23/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.1165 - val_loss: 0.4164\n",
      "Epoch 24/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.1006 - val_loss: 0.4718\n",
      "Epoch 25/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.1034 - val_loss: 0.3769\n",
      "Epoch 26/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.0281 - val_loss: 0.3866\n",
      "Epoch 27/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.1294 - val_loss: 0.3853\n",
      "Epoch 28/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0831 - val_loss: 0.3364\n",
      "Epoch 29/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0692 - val_loss: 0.2925\n",
      "Epoch 30/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 1.1046 - val_loss: 0.2770\n",
      "Epoch 31/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 1.0172 - val_loss: 0.2389\n",
      "Epoch 32/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.9460 - val_loss: 0.2321\n",
      "Epoch 33/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.9528 - val_loss: 0.2226\n",
      "Epoch 34/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8680 - val_loss: 0.2171\n",
      "Epoch 35/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 1.0078 - val_loss: 0.2183\n",
      "Epoch 36/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.9964 - val_loss: 0.1787\n",
      "Epoch 37/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7733 - val_loss: 0.1768\n",
      "Epoch 38/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8079 - val_loss: 0.1746\n",
      "Epoch 39/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7874 - val_loss: 0.1742\n",
      "Epoch 40/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8986 - val_loss: 0.1670\n",
      "Epoch 41/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8065 - val_loss: 0.1464\n",
      "Epoch 42/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6845 - val_loss: 0.1257\n",
      "Epoch 43/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7956 - val_loss: 0.1177\n",
      "Epoch 44/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8215 - val_loss: 0.1247\n",
      "Epoch 45/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.8123 - val_loss: 0.1127\n",
      "Epoch 46/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7571 - val_loss: 0.1465\n",
      "Epoch 47/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.8137 - val_loss: 0.1366\n",
      "Epoch 48/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.8075 - val_loss: 0.1105\n",
      "Epoch 49/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7651 - val_loss: 0.0956\n",
      "Epoch 50/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8261 - val_loss: 0.0870\n",
      "Epoch 51/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7649 - val_loss: 0.0886\n",
      "Epoch 52/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7882 - val_loss: 0.0821\n",
      "Epoch 53/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7163 - val_loss: 0.0888\n",
      "Epoch 54/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.8166 - val_loss: 0.0837\n",
      "Epoch 55/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7572 - val_loss: 0.1446\n",
      "Epoch 56/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6913 - val_loss: 0.0963\n",
      "Epoch 57/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6845 - val_loss: 0.0750\n",
      "Epoch 58/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7110 - val_loss: 0.0751\n",
      "Epoch 59/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.7104 - val_loss: 0.0848\n",
      "Epoch 60/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7284 - val_loss: 0.0759\n",
      "Epoch 61/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6752 - val_loss: 0.0635\n",
      "Epoch 62/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6539 - val_loss: 0.0662\n",
      "Epoch 63/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.6357 - val_loss: 0.0643\n",
      "Epoch 64/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5967 - val_loss: 0.0896\n",
      "Epoch 65/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6469 - val_loss: 0.0624\n",
      "Epoch 66/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6136 - val_loss: 0.0757\n",
      "Epoch 67/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6562 - val_loss: 0.0641\n",
      "Epoch 68/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6374 - val_loss: 0.0643\n",
      "Epoch 69/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.6950 - val_loss: 0.0808\n",
      "Epoch 70/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5423 - val_loss: 0.0915\n",
      "Epoch 71/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.7132 - val_loss: 0.0724\n",
      "Epoch 72/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.7026 - val_loss: 0.0584\n",
      "Epoch 73/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6922 - val_loss: 0.0623\n",
      "Epoch 74/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6180 - val_loss: 0.0584\n",
      "Epoch 75/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6390 - val_loss: 0.1812\n",
      "Epoch 76/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5601 - val_loss: 0.0534\n",
      "Epoch 77/150\n",
      "26/26 [==============================] - 0s 17ms/step - loss: 0.5612 - val_loss: 0.0580\n",
      "Epoch 78/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5528 - val_loss: 0.0607\n",
      "Epoch 79/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6304 - val_loss: 0.1509\n",
      "Epoch 80/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6600 - val_loss: 0.0520\n",
      "Epoch 81/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6640 - val_loss: 0.0586\n",
      "Epoch 82/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.6654 - val_loss: 0.0787\n",
      "Epoch 83/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.6083 - val_loss: 0.0454\n",
      "Epoch 84/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5863 - val_loss: 0.0555\n",
      "Epoch 85/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5958 - val_loss: 0.0482\n",
      "Epoch 86/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5568 - val_loss: 0.0464\n",
      "Epoch 87/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5974 - val_loss: 0.0457\n",
      "Epoch 88/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5728 - val_loss: 0.0443\n",
      "Epoch 89/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5986 - val_loss: 0.0672\n",
      "Epoch 90/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6032 - val_loss: 0.0519\n",
      "Epoch 91/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5569 - val_loss: 0.0554\n",
      "Epoch 92/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5621 - val_loss: 0.0703\n",
      "Epoch 93/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5397 - val_loss: 0.0435\n",
      "Epoch 94/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4716 - val_loss: 0.0475\n",
      "Epoch 95/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5626 - val_loss: 0.0429\n",
      "Epoch 96/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5933 - val_loss: 0.0746\n",
      "Epoch 97/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6098 - val_loss: 0.0655\n",
      "Epoch 98/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5496 - val_loss: 0.0428\n",
      "Epoch 99/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5687 - val_loss: 0.0433\n",
      "Epoch 100/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5851 - val_loss: 0.0487\n",
      "Epoch 101/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.5647 - val_loss: 0.0419\n",
      "Epoch 102/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5685 - val_loss: 0.0538\n",
      "Epoch 103/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5586 - val_loss: 0.0439\n",
      "Epoch 104/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5796 - val_loss: 0.0732\n",
      "Epoch 105/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5127 - val_loss: 0.0946\n",
      "Epoch 106/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.6288 - val_loss: 0.0613\n",
      "Epoch 107/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4988 - val_loss: 0.0480\n",
      "Epoch 108/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.6364 - val_loss: 0.0431\n",
      "Epoch 109/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5509 - val_loss: 0.0419\n",
      "Epoch 110/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.5774 - val_loss: 0.0879\n",
      "Epoch 111/150\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5443 - val_loss: 0.0597\n",
      "Epoch 112/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5496 - val_loss: 0.0443\n",
      "Epoch 113/150\n",
      "26/26 [==============================] - 0s 12ms/step - loss: 0.4887 - val_loss: 0.0484\n",
      "Epoch 114/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5021 - val_loss: 0.0517\n",
      "Epoch 115/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5562 - val_loss: 0.0776\n",
      "Epoch 116/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.6252 - val_loss: 0.0421\n",
      "Epoch 117/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4698 - val_loss: 0.0399\n",
      "Epoch 118/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5354 - val_loss: 0.0451\n",
      "Epoch 119/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4992 - val_loss: 0.0494\n",
      "Epoch 120/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5066 - val_loss: 0.0501\n",
      "Epoch 121/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5482 - val_loss: 0.0455\n",
      "Epoch 122/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5780 - val_loss: 0.0654\n",
      "Epoch 123/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5277 - val_loss: 0.0407\n",
      "Epoch 124/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5277 - val_loss: 0.0471\n",
      "Epoch 125/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5085 - val_loss: 0.0486\n",
      "Epoch 126/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5427 - val_loss: 0.0412\n",
      "Epoch 127/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4950 - val_loss: 0.0494\n",
      "Epoch 128/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5358 - val_loss: 0.0511\n",
      "Epoch 129/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5526 - val_loss: 0.0387\n",
      "Epoch 130/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5273 - val_loss: 0.0471\n",
      "Epoch 131/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5262 - val_loss: 0.0415\n",
      "Epoch 132/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4788 - val_loss: 0.1169\n",
      "Epoch 133/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5778 - val_loss: 0.0356\n",
      "Epoch 134/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5255 - val_loss: 0.0699\n",
      "Epoch 135/150\n",
      "26/26 [==============================] - 0s 16ms/step - loss: 0.4843 - val_loss: 0.0436\n",
      "Epoch 136/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.4878 - val_loss: 0.0441\n",
      "Epoch 137/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5196 - val_loss: 0.0616\n",
      "Epoch 138/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5620 - val_loss: 0.0356\n",
      "Epoch 139/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5526 - val_loss: 0.0373\n",
      "Epoch 140/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5297 - val_loss: 0.0326\n",
      "Epoch 141/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4757 - val_loss: 0.0617\n",
      "Epoch 142/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5143 - val_loss: 0.0386\n",
      "Epoch 143/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5174 - val_loss: 0.0341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.4567 - val_loss: 0.0368\n",
      "Epoch 145/150\n",
      "26/26 [==============================] - 0s 13ms/step - loss: 0.5003 - val_loss: 0.0365\n",
      "Epoch 146/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.5423 - val_loss: 0.0524\n",
      "Epoch 147/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4690 - val_loss: 0.0397\n",
      "Epoch 148/150\n",
      "26/26 [==============================] - 0s 15ms/step - loss: 0.4439 - val_loss: 0.1511\n",
      "Epoch 149/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5527 - val_loss: 0.0435\n",
      "Epoch 150/150\n",
      "26/26 [==============================] - 0s 14ms/step - loss: 0.5034 - val_loss: 0.0620\n",
      "7/7 [==============================] - 1s 4ms/step\n",
      "Mean Squared Error: 0.06195177921940559\n",
      "Mean Absolute Error: 0.17398894722781963\n",
      "R-squared: 0.99076492651166\n",
      "\n",
      "Average scores for ticker GEO:\n",
      "Mean Squared Error: 0.03795819259070847\n",
      "Mean Absolute Error: 0.14451613165252836\n",
      "R-squared: 0.9939464630347379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('dataset.csv').dropna()\n",
    "\n",
    "# Define K-fold cross-validation function for each ticker\n",
    "def kfold_cross_validation_per_ticker(df, n_splits=5):\n",
    "    tickers = df['level_0'].unique()\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        print(f\"Cross-validation for ticker: {ticker}\")\n",
    "        ticker_df = df[df['level_0'] == ticker]\n",
    "        \n",
    "        # Define features and target variable for this ticker\n",
    "        X = ticker_df[['Open', 'High', 'Low', 'Volume','Daily Returns','Volatility','RSI', '%K', '%D','Sentiment Score','Movement','PreviousDayClose']].values\n",
    "        y = ticker_df['Close'].values\n",
    "\n",
    "        # Perform K-Fold cross-validation\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        fold = 1\n",
    "        mse_scores, mae_scores, r2_scores = [], [], []\n",
    "\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            print(f'Fold {fold}:')\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "            # Normalize features\n",
    "            scaler = MinMaxScaler()\n",
    "            X_train = scaler.fit_transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "            # Reshape input data for GRU (samples, time steps, features)\n",
    "            X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "            X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "            # Create and train GRU model\n",
    "            model = Sequential()\n",
    "            model.add(GRU(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(GRU(units=50, return_sequences=True))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(GRU(units=50))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Dense(units=1))\n",
    "            model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "            history = model.fit(X_train, y_train, epochs=150, batch_size=32, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "            # Evaluate model\n",
    "            predictions = model.predict(X_test)\n",
    "            mse = mean_squared_error(y_test, predictions)\n",
    "            mae = mean_absolute_error(y_test, predictions)\n",
    "            r2 = r2_score(y_test, predictions)\n",
    "\n",
    "            print(f'Mean Squared Error: {mse}')\n",
    "            print(f'Mean Absolute Error: {mae}')\n",
    "            print(f'R-squared: {r2}\\n')\n",
    "\n",
    "            mse_scores.append(mse)\n",
    "            mae_scores.append(mae)\n",
    "            r2_scores.append(r2)\n",
    "\n",
    "            fold += 1\n",
    "\n",
    "        # Print average scores for the current ticker\n",
    "        print('Average scores for ticker {}:'.format(ticker))\n",
    "        print(f'Mean Squared Error: {np.mean(mse_scores)}')\n",
    "        print(f'Mean Absolute Error: {np.mean(mae_scores)}')\n",
    "        print(f'R-squared: {np.mean(r2_scores)}\\n')\n",
    "\n",
    "# Perform K-fold cross-validation per ticker\n",
    "kfold_cross_validation_per_ticker(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7d75b9",
   "metadata": {},
   "source": [
    "Plots comparing Null Model or Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c679a33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x576 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract evaluation results for GRU model\n",
    "gru_mse = [evaluation_results_nextday[ticker]['Mean Squared Error'] for ticker in tickers]\n",
    "gru_mae = [evaluation_results_nextday[ticker]['Mean Absolute Error'] for ticker in tickers]\n",
    "gru_r2 = [evaluation_results_nextday[ticker]['R-squared'] for ticker in tickers]\n",
    "\n",
    "# Extract evaluation results for Decision Tree Regression and KNN\n",
    "dt_mse = [result[0] for result in evaluation_results_nextdaycomp['Decision Tree Regression']]\n",
    "dt_mae = [result[1] for result in evaluation_results_nextdaycomp['Decision Tree Regression']]\n",
    "dt_r2 = [result[2] for result in evaluation_results_nextdaycomp['Decision Tree Regression']]\n",
    "\n",
    "knn_mse = [result[0] for result in evaluation_results_nextdaycomp['KNN']]\n",
    "knn_mae = [result[1] for result in evaluation_results_nextdaycomp['KNN']]\n",
    "knn_r2 = [result[2] for result in evaluation_results_nextdaycomp['KNN']]\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(3, 1, figsize=(5, 8))\n",
    "\n",
    "# Mean Squared Error comparison\n",
    "axes[0].bar(tickers, gru_mse, width=0.4, align='center', label='GRU', color='blue')\n",
    "axes[0].bar(tickers, dt_mse, width=0.2, align='edge', label='Decision Tree', color='green', alpha=0.7)\n",
    "axes[0].bar(tickers, knn_mse, width=-0.2, align='edge', label='KNN', color='red', alpha=0.7)\n",
    "axes[0].set_title('Mean Squared Error Comparison')\n",
    "axes[0].set_ylabel('Mean Squared Error')\n",
    "axes[0].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# Mean Absolute Error comparison\n",
    "axes[1].bar(tickers, gru_mae, width=0.4, align='center', label='GRU', color='blue')\n",
    "axes[1].bar(tickers, dt_mae, width=0.2, align='edge', label='Decision Tree', color='green', alpha=0.7)\n",
    "axes[1].bar(tickers, knn_mae, width=-0.2, align='edge', label='KNN', color='red', alpha=0.7)\n",
    "axes[1].set_title('Mean Absolute Error Comparison')\n",
    "axes[1].set_ylabel('Mean Absolute Error')\n",
    "axes[1].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "# R-squared comparison\n",
    "axes[2].bar(tickers, gru_r2, width=0.4, align='center', label='GRU', color='blue')\n",
    "axes[2].bar(tickers, dt_r2, width=0.2, align='edge', label='Decision Tree', color='green', alpha=0.7)\n",
    "axes[2].bar(tickers, knn_r2, width=-0.2, align='edge', label='KNN', color='red', alpha=0.7)\n",
    "axes[2].set_title('R-squared Comparison')\n",
    "axes[2].set_ylabel('R-squared')\n",
    "\n",
    "# Add legend outside the plot\n",
    "axes[2].legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
